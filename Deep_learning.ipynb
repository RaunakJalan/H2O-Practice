{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_171\"; Java(TM) SE Runtime Environment (build 1.8.0_171-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode)\n",
      "  Starting server from /Users/raj/anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/gl/wb7rqfgd3v708q5m0ydj3pkc0000gq/T/tmplw5dqjxt\n",
      "  JVM stdout: /var/folders/gl/wb7rqfgd3v708q5m0ydj3pkc0000gq/T/tmplw5dqjxt/h2o_raj_started_from_python.out\n",
      "  JVM stderr: /var/folders/gl/wb7rqfgd3v708q5m0ydj3pkc0000gq/T/tmplw5dqjxt/h2o_raj_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Asia/Kolkata</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>9 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_raj_o4us49</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster timezone:       Asia/Kolkata\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.2\n",
       "H2O cluster version age:    9 days\n",
       "H2O cluster name:           H2O_from_python_raj_o4us49\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "url =  \"http://h2o-public-test-data.s3.amazonaws.com/smalldata/airlines/allyears2k_headers.zip\"\n",
    "data=h2o.import_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid,test=data.split_frame([0.8,0.1],seed=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35255/4272/4451\n"
     ]
    }
   ],
   "source": [
    "print(\"%d/%d/%d\" %(train.nrows,valid.nrows,test.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y='IsArrDelayed' # binomial Classification\n",
    "ignoreFields=['ArrDelay',\n",
    " 'DepDelay','CarrierDelay',\n",
    " 'WeatherDelay',\n",
    " 'NASDelay',\n",
    " 'SecurityDelay',\n",
    " 'LateAircraftDelay','IsArrDelayed',\n",
    " 'IsDepDelayed','ActualElapsedTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAll=[i for i in train.names if i not in ignoreFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 870 ms, sys: 133 ms, total: 1 s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "m_def= H2ODeepLearningEstimator()\n",
    "%time m_def.train(xAll,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Building Time: 1min 25 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.09340848812038584\n",
      "RMSE: 0.30562802247239346\n",
      "LogLoss: 0.289199594335423\n",
      "Mean Per-Class Error: 0.12834661007391923\n",
      "AUC: 0.9478331744225387\n",
      "Gini: 0.8956663488450773\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3722098466262854: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1629.0</td>\n",
       "<td>321.0</td>\n",
       "<td>0.1646</td>\n",
       "<td> (321.0/1950.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>259.0</td>\n",
       "<td>2242.0</td>\n",
       "<td>0.1036</td>\n",
       "<td> (259.0/2501.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1888.0</td>\n",
       "<td>2563.0</td>\n",
       "<td>0.1303</td>\n",
       "<td> (580.0/4451.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1629  321    0.1646   (321.0/1950.0)\n",
       "YES    259   2242   0.1036   (259.0/2501.0)\n",
       "Total  1888  2563   0.1303   (580.0/4451.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3722098</td>\n",
       "<td>0.8854660</td>\n",
       "<td>228.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1336366</td>\n",
       "<td>0.9228163</td>\n",
       "<td>324.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6568810</td>\n",
       "<td>0.9038697</td>\n",
       "<td>130.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4538744</td>\n",
       "<td>0.8703662</td>\n",
       "<td>198.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999637</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0075042</td>\n",
       "<td>1.0</td>\n",
       "<td>391.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999637</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4538744</td>\n",
       "<td>0.7394671</td>\n",
       "<td>198.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4321551</td>\n",
       "<td>0.8692308</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4538744</td>\n",
       "<td>0.8716534</td>\n",
       "<td>198.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.37221      0.885466  228\n",
       "max f2                       0.133637     0.922816  324\n",
       "max f0point5                 0.656881     0.90387   130\n",
       "max accuracy                 0.453874     0.870366  198\n",
       "max precision                0.999964     1         0\n",
       "max recall                   0.00750423   1         391\n",
       "max specificity              0.999964     1         0\n",
       "max absolute_mcc             0.453874     0.739467  198\n",
       "max min_per_class_accuracy   0.432155     0.869231  206\n",
       "max mean_per_class_accuracy  0.453874     0.871653  198"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 56.19 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0199955</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0355858</td>\n",
       "<td>0.0355858</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0204448</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007997</td>\n",
       "<td>0.0363854</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301056</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0171931</td>\n",
       "<td>0.0535786</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0402157</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0179928</td>\n",
       "<td>0.0715714</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0501011</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0891643</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002022</td>\n",
       "<td>0.9999828</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.1783287</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500786</td>\n",
       "<td>0.9995522</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.2670932</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001797</td>\n",
       "<td>0.9970156</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.3562575</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3001573</td>\n",
       "<td>0.9597240</td>\n",
       "<td>1.7596916</td>\n",
       "<td>1.7730276</td>\n",
       "<td>0.9887640</td>\n",
       "<td>0.9962575</td>\n",
       "<td>0.1759296</td>\n",
       "<td>0.5321871</td>\n",
       "<td>75.9691629</td>\n",
       "<td>77.3027615</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4001348</td>\n",
       "<td>0.8100843</td>\n",
       "<td>1.5797232</td>\n",
       "<td>1.7247286</td>\n",
       "<td>0.8876404</td>\n",
       "<td>0.9691185</td>\n",
       "<td>0.1579368</td>\n",
       "<td>0.6901240</td>\n",
       "<td>57.9723167</td>\n",
       "<td>72.4728637</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5001123</td>\n",
       "<td>0.5398852</td>\n",
       "<td>1.3157694</td>\n",
       "<td>1.6429735</td>\n",
       "<td>0.7393258</td>\n",
       "<td>0.9231806</td>\n",
       "<td>0.1315474</td>\n",
       "<td>0.8216713</td>\n",
       "<td>31.5769423</td>\n",
       "<td>64.2973538</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000899</td>\n",
       "<td>0.3288637</td>\n",
       "<td>0.9118402</td>\n",
       "<td>1.5211636</td>\n",
       "<td>0.5123596</td>\n",
       "<td>0.8547361</td>\n",
       "<td>0.0911635</td>\n",
       "<td>0.9128349</td>\n",
       "<td>-8.8159792</td>\n",
       "<td>52.1163605</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000674</td>\n",
       "<td>0.1734375</td>\n",
       "<td>0.5319068</td>\n",
       "<td>1.3798866</td>\n",
       "<td>0.2988764</td>\n",
       "<td>0.7753530</td>\n",
       "<td>0.0531787</td>\n",
       "<td>0.9660136</td>\n",
       "<td>-46.8093212</td>\n",
       "<td>37.9886556</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000449</td>\n",
       "<td>0.0673211</td>\n",
       "<td>0.2639537</td>\n",
       "<td>1.2404341</td>\n",
       "<td>0.1483146</td>\n",
       "<td>0.6969952</td>\n",
       "<td>0.0263894</td>\n",
       "<td>0.9924030</td>\n",
       "<td>-73.6046256</td>\n",
       "<td>24.0434127</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000225</td>\n",
       "<td>0.0140318</td>\n",
       "<td>0.0719874</td>\n",
       "<td>1.1106391</td>\n",
       "<td>0.0404494</td>\n",
       "<td>0.6240639</td>\n",
       "<td>0.0071971</td>\n",
       "<td>0.9996002</td>\n",
       "<td>-92.8012615</td>\n",
       "<td>11.0639119</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000922</td>\n",
       "<td>0.0039993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0022472</td>\n",
       "<td>0.5618962</td>\n",
       "<td>0.0003998</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.6000701</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0199955                   1                  1.77969    1.77969            1                1                           0.0355858       0.0355858                  77.9688   77.9688\n",
       "    2        0.0204448                   1                  1.77969    1.77969            1                1                           0.00079968      0.0363854                  77.9688   77.9688\n",
       "    3        0.0301056                   1                  1.77969    1.77969            1                1                           0.0171931       0.0535786                  77.9688   77.9688\n",
       "    4        0.0402157                   1                  1.77969    1.77969            1                1                           0.0179928       0.0715714                  77.9688   77.9688\n",
       "    5        0.0501011                   1                  1.77969    1.77969            1                1                           0.017593        0.0891643                  77.9688   77.9688\n",
       "    6        0.100202                    0.999983           1.77969    1.77969            1                1                           0.0891643       0.178329                   77.9688   77.9688\n",
       "    7        0.150079                    0.999552           1.77969    1.77969            1                1                           0.0887645       0.267093                   77.9688   77.9688\n",
       "    8        0.20018                     0.997016           1.77969    1.77969            1                1                           0.0891643       0.356257                   77.9688   77.9688\n",
       "    9        0.300157                    0.959724           1.75969    1.77303            0.988764         0.996257                    0.17593         0.532187                   75.9692   77.3028\n",
       "    10       0.400135                    0.810084           1.57972    1.72473            0.88764          0.969118                    0.157937        0.690124                   57.9723   72.4729\n",
       "    11       0.500112                    0.539885           1.31577    1.64297            0.739326         0.923181                    0.131547        0.821671                   31.5769   64.2974\n",
       "    12       0.60009                     0.328864           0.91184    1.52116            0.51236          0.854736                    0.0911635       0.912835                   -8.81598  52.1164\n",
       "    13       0.700067                    0.173437           0.531907   1.37989            0.298876         0.775353                    0.0531787       0.966014                   -46.8093  37.9887\n",
       "    14       0.800045                    0.0673211          0.263954   1.24043            0.148315         0.696995                    0.0263894       0.992403                   -73.6046  24.0434\n",
       "    15       0.900022                    0.0140318          0.0719874  1.11064            0.0404494        0.624064                    0.00719712      0.9996                     -92.8013  11.0639\n",
       "    16       1                           9.22169e-05        0.0039993  1                  0.00224719       0.561896                    0.00039984      1                          -99.6001  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_def.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1529876519143_1\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.07171438946022714\n",
      "RMSE: 0.26779542464393813\n",
      "LogLoss: 0.22875645618083335\n",
      "Mean Per-Class Error: 0.09809306408788454\n",
      "AUC: 0.9687652377524013\n",
      "Gini: 0.9375304755048026\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3831301621884939: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>3954.0</td>\n",
       "<td>540.0</td>\n",
       "<td>0.1202</td>\n",
       "<td> (540.0/4494.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>462.0</td>\n",
       "<td>5016.0</td>\n",
       "<td>0.0843</td>\n",
       "<td> (462.0/5478.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4416.0</td>\n",
       "<td>5556.0</td>\n",
       "<td>0.1005</td>\n",
       "<td> (1002.0/9972.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  ---------------\n",
       "NO     3954  540    0.1202   (540.0/4494.0)\n",
       "YES    462   5016   0.0843   (462.0/5478.0)\n",
       "Total  4416  5556   0.1005   (1002.0/9972.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3831302</td>\n",
       "<td>0.9091898</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1785106</td>\n",
       "<td>0.9382526</td>\n",
       "<td>298.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6520562</td>\n",
       "<td>0.9302229</td>\n",
       "<td>133.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4536737</td>\n",
       "<td>0.9010229</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999612</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0114046</td>\n",
       "<td>1.0</td>\n",
       "<td>387.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999612</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4536737</td>\n",
       "<td>0.8013154</td>\n",
       "<td>196.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4277851</td>\n",
       "<td>0.8995984</td>\n",
       "<td>203.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4574320</td>\n",
       "<td>0.9019069</td>\n",
       "<td>195.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.38313      0.90919   219\n",
       "max f2                       0.178511     0.938253  298\n",
       "max f0point5                 0.652056     0.930223  133\n",
       "max accuracy                 0.453674     0.901023  196\n",
       "max precision                0.999961     1         0\n",
       "max recall                   0.0114046    1         387\n",
       "max specificity              0.999961     1         0\n",
       "max absolute_mcc             0.453674     0.801315  196\n",
       "max min_per_class_accuracy   0.427785     0.899598  203\n",
       "max mean_per_class_accuracy  0.457432     0.901907  195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.93 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0209587</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0381526</td>\n",
       "<td>0.0381526</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0300842</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0166119</td>\n",
       "<td>0.0547645</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400120</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0180723</td>\n",
       "<td>0.0728368</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500401</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0182548</td>\n",
       "<td>0.0910916</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1000802</td>\n",
       "<td>0.9999878</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0910916</td>\n",
       "<td>0.1821833</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500201</td>\n",
       "<td>0.9997316</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0909091</td>\n",
       "<td>0.2730924</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2000602</td>\n",
       "<td>0.9978067</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.8203724</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0910916</td>\n",
       "<td>0.3641840</td>\n",
       "<td>82.0372399</td>\n",
       "<td>82.0372399</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000401</td>\n",
       "<td>0.9707266</td>\n",
       "<td>1.8148948</td>\n",
       "<td>1.8185472</td>\n",
       "<td>0.9969910</td>\n",
       "<td>0.9989973</td>\n",
       "<td>0.1814531</td>\n",
       "<td>0.5456371</td>\n",
       "<td>81.4894849</td>\n",
       "<td>81.8547159</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000201</td>\n",
       "<td>0.8414012</td>\n",
       "<td>1.7327316</td>\n",
       "<td>1.7970986</td>\n",
       "<td>0.9518556</td>\n",
       "<td>0.9872148</td>\n",
       "<td>0.1732384</td>\n",
       "<td>0.7188755</td>\n",
       "<td>73.2731601</td>\n",
       "<td>79.7098648</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5296241</td>\n",
       "<td>1.4059045</td>\n",
       "<td>1.7188755</td>\n",
       "<td>0.7723170</td>\n",
       "<td>0.9442439</td>\n",
       "<td>0.1405622</td>\n",
       "<td>0.8594378</td>\n",
       "<td>40.5904460</td>\n",
       "<td>71.8875502</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5999799</td>\n",
       "<td>0.2935070</td>\n",
       "<td>0.8581495</td>\n",
       "<td>1.5754451</td>\n",
       "<td>0.4714142</td>\n",
       "<td>0.8654521</td>\n",
       "<td>0.0857977</td>\n",
       "<td>0.9452355</td>\n",
       "<td>-14.1850524</td>\n",
       "<td>57.5445141</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6999599</td>\n",
       "<td>0.1451673</td>\n",
       "<td>0.3998611</td>\n",
       "<td>1.4075286</td>\n",
       "<td>0.2196590</td>\n",
       "<td>0.7732092</td>\n",
       "<td>0.0399781</td>\n",
       "<td>0.9852136</td>\n",
       "<td>-60.0138861</td>\n",
       "<td>40.7528630</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7999398</td>\n",
       "<td>0.0568178</td>\n",
       "<td>0.1223319</td>\n",
       "<td>1.2468992</td>\n",
       "<td>0.0672016</td>\n",
       "<td>0.6849693</td>\n",
       "<td>0.0122307</td>\n",
       "<td>0.9974443</td>\n",
       "<td>-87.7668053</td>\n",
       "<td>24.6899183</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8999198</td>\n",
       "<td>0.0114559</td>\n",
       "<td>0.0255619</td>\n",
       "<td>1.1112102</td>\n",
       "<td>0.0140421</td>\n",
       "<td>0.6104301</td>\n",
       "<td>0.0025557</td>\n",
       "<td>1.0</td>\n",
       "<td>-97.4438101</td>\n",
       "<td>11.1210163</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000640</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5493381</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0209587                   1                  1.82037    1.82037            1                1                           0.0381526       0.0381526                  82.0372   82.0372\n",
       "    2        0.0300842                   1                  1.82037    1.82037            1                1                           0.0166119       0.0547645                  82.0372   82.0372\n",
       "    3        0.040012                    1                  1.82037    1.82037            1                1                           0.0180723       0.0728368                  82.0372   82.0372\n",
       "    4        0.0500401                   1                  1.82037    1.82037            1                1                           0.0182548       0.0910916                  82.0372   82.0372\n",
       "    5        0.10008                     0.999988           1.82037    1.82037            1                1                           0.0910916       0.182183                   82.0372   82.0372\n",
       "    6        0.15002                     0.999732           1.82037    1.82037            1                1                           0.0909091       0.273092                   82.0372   82.0372\n",
       "    7        0.20006                     0.997807           1.82037    1.82037            1                1                           0.0910916       0.364184                   82.0372   82.0372\n",
       "    8        0.30004                     0.970727           1.81489    1.81855            0.996991         0.998997                    0.181453        0.545637                   81.4895   81.8547\n",
       "    9        0.40002                     0.841401           1.73273    1.7971             0.951856         0.987215                    0.173238        0.718876                   73.2732   79.7099\n",
       "    10       0.5                         0.529624           1.4059     1.71888            0.772317         0.944244                    0.140562        0.859438                   40.5904   71.8876\n",
       "    11       0.59998                     0.293507           0.858149   1.57545            0.471414         0.865452                    0.0857977       0.945235                   -14.1851  57.5445\n",
       "    12       0.69996                     0.145167           0.399861   1.40753            0.219659         0.773209                    0.0399781       0.985214                   -60.0139  40.7529\n",
       "    13       0.79994                     0.0568178          0.122332   1.2469             0.0672016        0.684969                    0.0122307       0.997444                   -87.7668  24.6899\n",
       "    14       0.89992                     0.0114559          0.0255619  1.11121            0.0140421        0.61043                     0.00255568      1                          -97.4438  11.121\n",
       "    15       1                           6.39618e-05        0          1                  0                0.549338                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.09545731573014724\n",
      "RMSE: 0.30896167356186305\n",
      "LogLoss: 0.2989812119827052\n",
      "Mean Per-Class Error: 0.13146400571341743\n",
      "AUC: 0.9446647602773282\n",
      "Gini: 0.8893295205546563\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3820555273788458: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1636.0</td>\n",
       "<td>297.0</td>\n",
       "<td>0.1536</td>\n",
       "<td> (297.0/1933.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>268.0</td>\n",
       "<td>2071.0</td>\n",
       "<td>0.1146</td>\n",
       "<td> (268.0/2339.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1904.0</td>\n",
       "<td>2368.0</td>\n",
       "<td>0.1323</td>\n",
       "<td> (565.0/4272.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1636  297    0.1536   (297.0/1933.0)\n",
       "YES    268   2071   0.1146   (268.0/2339.0)\n",
       "Total  1904  2368   0.1323   (565.0/4272.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3820555</td>\n",
       "<td>0.8799660</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1649751</td>\n",
       "<td>0.9169101</td>\n",
       "<td>304.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7615170</td>\n",
       "<td>0.9024313</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4536868</td>\n",
       "<td>0.8677434</td>\n",
       "<td>194.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999606</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0170299</td>\n",
       "<td>1.0</td>\n",
       "<td>383.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999606</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4536868</td>\n",
       "<td>0.7347830</td>\n",
       "<td>194.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4288259</td>\n",
       "<td>0.8660114</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4536868</td>\n",
       "<td>0.8685360</td>\n",
       "<td>194.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.382056     0.879966  216\n",
       "max f2                       0.164975     0.91691   304\n",
       "max f0point5                 0.761517     0.902431  100\n",
       "max accuracy                 0.453687     0.867743  194\n",
       "max precision                0.999961     1         0\n",
       "max recall                   0.0170299    1         383\n",
       "max specificity              0.999961     1         0\n",
       "max absolute_mcc             0.453687     0.734783  194\n",
       "max min_per_class_accuracy   0.428826     0.866011  201\n",
       "max mean_per_class_accuracy  0.453687     0.868536  194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0215356</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0393330</td>\n",
       "<td>0.0393330</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0301966</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0158187</td>\n",
       "<td>0.0551518</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400281</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0179564</td>\n",
       "<td>0.0731082</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500936</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0183839</td>\n",
       "<td>0.0914921</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1001873</td>\n",
       "<td>0.9999891</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.1829842</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500468</td>\n",
       "<td>0.9997338</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.2740487</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2001404</td>\n",
       "<td>0.9974259</td>\n",
       "<td>1.8178869</td>\n",
       "<td>1.8242854</td>\n",
       "<td>0.9953271</td>\n",
       "<td>0.9988304</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.3651133</td>\n",
       "<td>81.7886868</td>\n",
       "<td>82.4285382</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000936</td>\n",
       "<td>0.9592906</td>\n",
       "<td>1.7793709</td>\n",
       "<td>1.8093256</td>\n",
       "<td>0.9742389</td>\n",
       "<td>0.9906396</td>\n",
       "<td>0.1778538</td>\n",
       "<td>0.5429671</td>\n",
       "<td>77.9370875</td>\n",
       "<td>80.9325558</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000468</td>\n",
       "<td>0.8045011</td>\n",
       "<td>1.6168322</td>\n",
       "<td>1.7612304</td>\n",
       "<td>0.8852459</td>\n",
       "<td>0.9643066</td>\n",
       "<td>0.1616075</td>\n",
       "<td>0.7045746</td>\n",
       "<td>61.6832190</td>\n",
       "<td>76.1230375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5217464</td>\n",
       "<td>1.2703681</td>\n",
       "<td>1.6631039</td>\n",
       "<td>0.6955504</td>\n",
       "<td>0.9105805</td>\n",
       "<td>0.1269773</td>\n",
       "<td>0.8315519</td>\n",
       "<td>27.0368149</td>\n",
       "<td>66.3103891</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5999532</td>\n",
       "<td>0.2958904</td>\n",
       "<td>0.8426348</td>\n",
       "<td>1.5264124</td>\n",
       "<td>0.4613583</td>\n",
       "<td>0.8357394</td>\n",
       "<td>0.0842240</td>\n",
       "<td>0.9157760</td>\n",
       "<td>-15.7365234</td>\n",
       "<td>52.6412390</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6999064</td>\n",
       "<td>0.1593064</td>\n",
       "<td>0.5132801</td>\n",
       "<td>1.3817276</td>\n",
       "<td>0.2810304</td>\n",
       "<td>0.7565217</td>\n",
       "<td>0.0513040</td>\n",
       "<td>0.9670799</td>\n",
       "<td>-48.6719940</td>\n",
       "<td>38.1727606</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7998596</td>\n",
       "<td>0.0671953</td>\n",
       "<td>0.2523627</td>\n",
       "<td>1.2405983</td>\n",
       "<td>0.1381733</td>\n",
       "<td>0.6792508</td>\n",
       "<td>0.0252245</td>\n",
       "<td>0.9923044</td>\n",
       "<td>-74.7637304</td>\n",
       "<td>24.0598306</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8998127</td>\n",
       "<td>0.0130180</td>\n",
       "<td>0.0769920</td>\n",
       "<td>1.1113424</td>\n",
       "<td>0.0421546</td>\n",
       "<td>0.6084807</td>\n",
       "<td>0.0076956</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.3007991</td>\n",
       "<td>11.1342352</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000300</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5475187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0215356                   1                  1.82642   1.82642            1                1                           0.039333        0.039333                   82.6422   82.6422\n",
       "    2        0.0301966                   1                  1.82642   1.82642            1                1                           0.0158187       0.0551518                  82.6422   82.6422\n",
       "    3        0.0400281                   1                  1.82642   1.82642            1                1                           0.0179564       0.0731082                  82.6422   82.6422\n",
       "    4        0.0500936                   1                  1.82642   1.82642            1                1                           0.0183839       0.0914921                  82.6422   82.6422\n",
       "    5        0.100187                    0.999989           1.82642   1.82642            1                1                           0.0914921       0.182984                   82.6422   82.6422\n",
       "    6        0.150047                    0.999734           1.82642   1.82642            1                1                           0.0910646       0.274049                   82.6422   82.6422\n",
       "    7        0.20014                     0.997426           1.81789   1.82429            0.995327         0.99883                     0.0910646       0.365113                   81.7887   82.4285\n",
       "    8        0.300094                    0.959291           1.77937   1.80933            0.974239         0.99064                     0.177854        0.542967                   77.9371   80.9326\n",
       "    9        0.400047                    0.804501           1.61683   1.76123            0.885246         0.964307                    0.161608        0.704575                   61.6832   76.123\n",
       "    10       0.5                         0.521746           1.27037   1.6631             0.69555          0.910581                    0.126977        0.831552                   27.0368   66.3104\n",
       "    11       0.599953                    0.29589            0.842635  1.52641            0.461358         0.835739                    0.084224        0.915776                   -15.7365  52.6412\n",
       "    12       0.699906                    0.159306           0.51328   1.38173            0.28103          0.756522                    0.051304        0.96708                    -48.672   38.1728\n",
       "    13       0.79986                     0.0671953          0.252363  1.2406             0.138173         0.679251                    0.0252245       0.992304                   -74.7637  24.0598\n",
       "    14       0.899813                    0.013018           0.076992  1.11134            0.0421546        0.608481                    0.0076956       1                          -92.3008  11.1342\n",
       "    15       1                           2.99588e-05        0         1                  0                0.547519                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_r2</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:12:07</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:12:12</td>\n",
       "<td>12.062 sec</td>\n",
       "<td>3744 obs/sec</td>\n",
       "<td>0.3517799</td>\n",
       "<td>1</td>\n",
       "<td>12402.0</td>\n",
       "<td>0.4590229</td>\n",
       "<td>0.6011396</td>\n",
       "<td>0.1489048</td>\n",
       "<td>0.7175109</td>\n",
       "<td>1.8203724</td>\n",
       "<td>0.3859807</td>\n",
       "<td>0.4663436</td>\n",
       "<td>0.6166705</td>\n",
       "<td>0.1221657</td>\n",
       "<td>0.6972407</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.3927903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:13:25</td>\n",
       "<td> 1 min 25.219 sec</td>\n",
       "<td>5223 obs/sec</td>\n",
       "<td>10.2997022</td>\n",
       "<td>29</td>\n",
       "<td>363116.0</td>\n",
       "<td>0.2677954</td>\n",
       "<td>0.2287565</td>\n",
       "<td>0.7103218</td>\n",
       "<td>0.9687652</td>\n",
       "<td>1.8203724</td>\n",
       "<td>0.1004813</td>\n",
       "<td>0.3089617</td>\n",
       "<td>0.2989812</td>\n",
       "<td>0.6146906</td>\n",
       "<td>0.9446648</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1322566</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -----------------  ---------------------------------\n",
       "    2018-06-25 03:12:07  0.000 sec                           0         0             0          nan              nan                 nan            nan             nan              nan                              nan                nan                   nan              nan               nan                nan\n",
       "    2018-06-25 03:12:12  12.062 sec        3744 obs/sec      0.35178   1             12402      0.459023         0.60114             0.148905       0.717511        1.82037          0.385981                         0.466344           0.61667               0.122166         0.697241          1.82642            0.39279\n",
       "    2018-06-25 03:13:25  1 min 25.219 sec  5223 obs/sec      10.2997   29            363116     0.267795         0.228756            0.710322       0.968765        1.82037          0.100481                         0.308962           0.298981              0.614691         0.944665          1.82642            0.132257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ArrTime</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0021607</td></tr>\n",
       "<tr><td>CRSArrTime</td>\n",
       "<td>0.8669832</td>\n",
       "<td>0.8669832</td>\n",
       "<td>0.0018733</td></tr>\n",
       "<tr><td>DepTime</td>\n",
       "<td>0.6730532</td>\n",
       "<td>0.6730532</td>\n",
       "<td>0.0014543</td></tr>\n",
       "<tr><td>CRSDepTime</td>\n",
       "<td>0.6551669</td>\n",
       "<td>0.6551669</td>\n",
       "<td>0.0014156</td></tr>\n",
       "<tr><td>TailNum.NA</td>\n",
       "<td>0.5224637</td>\n",
       "<td>0.5224637</td>\n",
       "<td>0.0011289</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>TailNum.N473WN</td>\n",
       "<td>0.1018542</td>\n",
       "<td>0.1018542</td>\n",
       "<td>0.0002201</td></tr>\n",
       "<tr><td>TailNum.N618A<0xE4></td>\n",
       "<td>0.0974431</td>\n",
       "<td>0.0974431</td>\n",
       "<td>0.0002105</td></tr>\n",
       "<tr><td>Dest.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>Origin.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>UniqueCarrier.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance    percentage\n",
       "-------------------------  ---------------------  -------------------  ---------------------\n",
       "ArrTime                    1.0                    1.0                  0.002160723259899837\n",
       "CRSArrTime                 0.8669832348823547     0.8669832348823547   0.0018733108415535079\n",
       "DepTime                    0.6730532050132751     0.6730532050132751   0.0014542817152223173\n",
       "CRSDepTime                 0.6551669239997864     0.6551669239997864   0.0014156344118033675\n",
       "TailNum.NA                 0.5224636793136597     0.5224636793136597   0.001128899424345874\n",
       "---                        ---                    ---                  ---\n",
       "TailNum.N473WN             0.10185416787862778    0.10185416787862778  0.0002200786696530939\n",
       "TailNum.N618A<0xE4>        0.097443126142025      0.097443126142025    0.0002105476291724273\n",
       "Dest.missing(NA)           0.0                    0.0                  0.0\n",
       "Origin.missing(NA)         0.0                    0.0                  0.0\n",
       "UniqueCarrier.missing(NA)  0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_def #on the data its seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_def.plot() #default epoch is 10 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tuning idea : Will more effort help ? (more epoch more time more effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 1.95 s, sys: 199 ms, total: 2.15 s\n",
      "Wall time: 8min 47s\n"
     ]
    }
   ],
   "source": [
    "m_200_epochs= H2ODeepLearningEstimator(epochs=200,stopping_rounds=5,stopping_tolerance=0,stopping_metric=\"logloss\")\n",
    "%time m_200_epochs.train(xAll,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Building Time: 8min 47 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.08917766216720131\n",
      "RMSE: 0.29862629182173717\n",
      "LogLoss: 0.27286599498117226\n",
      "Mean Per-Class Error: 0.12223162017244382\n",
      "AUC: 0.9552240642204656\n",
      "Gini: 0.9104481284409311\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.353727350358234: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1664.0</td>\n",
       "<td>286.0</td>\n",
       "<td>0.1467</td>\n",
       "<td> (286.0/1950.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>256.0</td>\n",
       "<td>2245.0</td>\n",
       "<td>0.1024</td>\n",
       "<td> (256.0/2501.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1920.0</td>\n",
       "<td>2531.0</td>\n",
       "<td>0.1218</td>\n",
       "<td> (542.0/4451.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1664  286    0.1467   (286.0/1950.0)\n",
       "YES    256   2245   0.1024   (256.0/2501.0)\n",
       "Total  1920  2531   0.1218   (542.0/4451.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3537274</td>\n",
       "<td>0.8922893</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1467005</td>\n",
       "<td>0.9276070</td>\n",
       "<td>319.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5844459</td>\n",
       "<td>0.9124526</td>\n",
       "<td>156.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3537274</td>\n",
       "<td>0.8782296</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999680</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0194562</td>\n",
       "<td>1.0</td>\n",
       "<td>381.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999680</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3988179</td>\n",
       "<td>0.7527865</td>\n",
       "<td>223.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3959729</td>\n",
       "<td>0.8774359</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3988179</td>\n",
       "<td>0.8777684</td>\n",
       "<td>223.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.353727     0.892289  239\n",
       "max f2                       0.146701     0.927607  319\n",
       "max f0point5                 0.584446     0.912453  156\n",
       "max accuracy                 0.353727     0.87823   239\n",
       "max precision                0.999968     1         0\n",
       "max recall                   0.0194562    1         381\n",
       "max specificity              0.999968     1         0\n",
       "max absolute_mcc             0.398818     0.752787  223\n",
       "max min_per_class_accuracy   0.395973     0.877436  224\n",
       "max mean_per_class_accuracy  0.398818     0.877768  223"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 56.19 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0211188</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0375850</td>\n",
       "<td>0.0375850</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0301056</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0159936</td>\n",
       "<td>0.0535786</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0402157</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0179928</td>\n",
       "<td>0.0715714</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0501011</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0891643</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1002022</td>\n",
       "<td>0.9999954</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.1783287</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500786</td>\n",
       "<td>0.9999366</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.2670932</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2001797</td>\n",
       "<td>0.9991137</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.3562575</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3001573</td>\n",
       "<td>0.9706806</td>\n",
       "<td>1.7716895</td>\n",
       "<td>1.7770239</td>\n",
       "<td>0.9955056</td>\n",
       "<td>0.9985030</td>\n",
       "<td>0.1771291</td>\n",
       "<td>0.5333866</td>\n",
       "<td>77.1689526</td>\n",
       "<td>77.7023921</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4001348</td>\n",
       "<td>0.7864668</td>\n",
       "<td>1.6117176</td>\n",
       "<td>1.7357205</td>\n",
       "<td>0.9056180</td>\n",
       "<td>0.9752948</td>\n",
       "<td>0.1611355</td>\n",
       "<td>0.6945222</td>\n",
       "<td>61.1717560</td>\n",
       "<td>73.5720535</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5001123</td>\n",
       "<td>0.5026747</td>\n",
       "<td>1.3237680</td>\n",
       "<td>1.6533670</td>\n",
       "<td>0.7438202</td>\n",
       "<td>0.9290207</td>\n",
       "<td>0.1323471</td>\n",
       "<td>0.8268693</td>\n",
       "<td>32.3768021</td>\n",
       "<td>65.3367045</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6000899</td>\n",
       "<td>0.2940701</td>\n",
       "<td>0.9198388</td>\n",
       "<td>1.5311581</td>\n",
       "<td>0.5168539</td>\n",
       "<td>0.8603519</td>\n",
       "<td>0.0919632</td>\n",
       "<td>0.9188325</td>\n",
       "<td>-8.0161194</td>\n",
       "<td>53.1158110</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7000674</td>\n",
       "<td>0.1422315</td>\n",
       "<td>0.5359061</td>\n",
       "<td>1.3890249</td>\n",
       "<td>0.3011236</td>\n",
       "<td>0.7804878</td>\n",
       "<td>0.0535786</td>\n",
       "<td>0.9724110</td>\n",
       "<td>-46.4093913</td>\n",
       "<td>38.9024878</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.8000449</td>\n",
       "<td>0.0477670</td>\n",
       "<td>0.2439572</td>\n",
       "<td>1.2459316</td>\n",
       "<td>0.1370787</td>\n",
       "<td>0.7000842</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.9968013</td>\n",
       "<td>-75.6042751</td>\n",
       "<td>24.5931619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.9000225</td>\n",
       "<td>0.0087112</td>\n",
       "<td>0.0319944</td>\n",
       "<td>1.1110834</td>\n",
       "<td>0.0179775</td>\n",
       "<td>0.6243135</td>\n",
       "<td>0.0031987</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.8005607</td>\n",
       "<td>11.1083375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000428</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5618962</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0211188                   1                  1.77969    1.77969            1                1                           0.037585        0.037585                   77.9688   77.9688\n",
       "    2        0.0301056                   1                  1.77969    1.77969            1                1                           0.0159936       0.0535786                  77.9688   77.9688\n",
       "    3        0.0402157                   1                  1.77969    1.77969            1                1                           0.0179928       0.0715714                  77.9688   77.9688\n",
       "    4        0.0501011                   1                  1.77969    1.77969            1                1                           0.017593        0.0891643                  77.9688   77.9688\n",
       "    5        0.100202                    0.999995           1.77969    1.77969            1                1                           0.0891643       0.178329                   77.9688   77.9688\n",
       "    6        0.150079                    0.999937           1.77969    1.77969            1                1                           0.0887645       0.267093                   77.9688   77.9688\n",
       "    7        0.20018                     0.999114           1.77969    1.77969            1                1                           0.0891643       0.356257                   77.9688   77.9688\n",
       "    8        0.300157                    0.970681           1.77169    1.77702            0.995506         0.998503                    0.177129        0.533387                   77.169    77.7024\n",
       "    9        0.400135                    0.786467           1.61172    1.73572            0.905618         0.975295                    0.161136        0.694522                   61.1718   73.5721\n",
       "    10       0.500112                    0.502675           1.32377    1.65337            0.74382          0.929021                    0.132347        0.826869                   32.3768   65.3367\n",
       "    11       0.60009                     0.29407            0.919839   1.53116            0.516854         0.860352                    0.0919632       0.918832                   -8.01612  53.1158\n",
       "    12       0.700067                    0.142231           0.535906   1.38902            0.301124         0.780488                    0.0535786       0.972411                   -46.4094  38.9025\n",
       "    13       0.800045                    0.047767           0.243957   1.24593            0.137079         0.700084                    0.0243902       0.996801                   -75.6043  24.5932\n",
       "    14       0.900022                    0.00871123         0.0319944  1.11108            0.0179775        0.624314                    0.00319872      1                          -96.8006  11.1083\n",
       "    15       1                           4.28181e-05        0          1                  0                0.561896                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_200_epochs.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1529876519143_7\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.06801733624736912\n",
      "RMSE: 0.2608013348266629\n",
      "LogLoss: 0.21648343715378993\n",
      "Mean Per-Class Error: 0.09102342137664587\n",
      "AUC: 0.9735486057520287\n",
      "Gini: 0.9470972115040575\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3280316462589536: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>4003.0</td>\n",
       "<td>579.0</td>\n",
       "<td>0.1264</td>\n",
       "<td> (579.0/4582.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>375.0</td>\n",
       "<td>5172.0</td>\n",
       "<td>0.0676</td>\n",
       "<td> (375.0/5547.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4378.0</td>\n",
       "<td>5751.0</td>\n",
       "<td>0.0942</td>\n",
       "<td> (954.0/10129.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  ---------------\n",
       "NO     4003  579    0.1264   (579.0/4582.0)\n",
       "YES    375   5172   0.0676   (375.0/5547.0)\n",
       "Total  4378  5751   0.0942   (954.0/10129.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3280316</td>\n",
       "<td>0.9155603</td>\n",
       "<td>241.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1911255</td>\n",
       "<td>0.9405198</td>\n",
       "<td>294.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5832442</td>\n",
       "<td>0.9376393</td>\n",
       "<td>154.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3803677</td>\n",
       "<td>0.9073946</td>\n",
       "<td>222.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999630</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0290930</td>\n",
       "<td>1.0</td>\n",
       "<td>374.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999630</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4647174</td>\n",
       "<td>0.8145551</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3948329</td>\n",
       "<td>0.9060754</td>\n",
       "<td>217.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4647174</td>\n",
       "<td>0.9089766</td>\n",
       "<td>195.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.328032     0.91556   241\n",
       "max f2                       0.191125     0.94052   294\n",
       "max f0point5                 0.583244     0.937639  154\n",
       "max accuracy                 0.380368     0.907395  222\n",
       "max precision                0.999963     1         0\n",
       "max recall                   0.029093     1         374\n",
       "max specificity              0.999963     1         0\n",
       "max absolute_mcc             0.464717     0.814555  195\n",
       "max min_per_class_accuracy   0.394833     0.906075  217\n",
       "max mean_per_class_accuracy  0.464717     0.908977  195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.76 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0199427</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0364161</td>\n",
       "<td>0.0364161</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200415</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001803</td>\n",
       "<td>0.0365964</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300128</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0182080</td>\n",
       "<td>0.0548044</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400829</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0183883</td>\n",
       "<td>0.0731927</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500543</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0182080</td>\n",
       "<td>0.0914008</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000099</td>\n",
       "<td>0.9999954</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0912205</td>\n",
       "<td>0.1826212</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500642</td>\n",
       "<td>0.9999362</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914008</td>\n",
       "<td>0.2740220</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000197</td>\n",
       "<td>0.9992276</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.8260321</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0912205</td>\n",
       "<td>0.3652425</td>\n",
       "<td>82.6032089</td>\n",
       "<td>82.6032089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000296</td>\n",
       "<td>0.9728382</td>\n",
       "<td>1.8170191</td>\n",
       "<td>1.8230278</td>\n",
       "<td>0.9950642</td>\n",
       "<td>0.9983547</td>\n",
       "<td>0.1817198</td>\n",
       "<td>0.5469623</td>\n",
       "<td>81.7019098</td>\n",
       "<td>82.3027759</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000395</td>\n",
       "<td>0.8047605</td>\n",
       "<td>1.7701515</td>\n",
       "<td>1.8098087</td>\n",
       "<td>0.9693978</td>\n",
       "<td>0.9911155</td>\n",
       "<td>0.1770326</td>\n",
       "<td>0.7239950</td>\n",
       "<td>77.0151542</td>\n",
       "<td>80.9808705</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000494</td>\n",
       "<td>0.5023898</td>\n",
       "<td>1.4510916</td>\n",
       "<td>1.7380653</td>\n",
       "<td>0.7946693</td>\n",
       "<td>0.9518263</td>\n",
       "<td>0.1451235</td>\n",
       "<td>0.8691184</td>\n",
       "<td>45.1091641</td>\n",
       "<td>73.8065292</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999605</td>\n",
       "<td>0.2540579</td>\n",
       "<td>0.8444496</td>\n",
       "<td>1.5892519</td>\n",
       "<td>0.4624506</td>\n",
       "<td>0.8703308</td>\n",
       "<td>0.0843699</td>\n",
       "<td>0.9534884</td>\n",
       "<td>-15.5550378</td>\n",
       "<td>58.9251888</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6999704</td>\n",
       "<td>0.1149439</td>\n",
       "<td>0.3533093</td>\n",
       "<td>1.4126638</td>\n",
       "<td>0.1934847</td>\n",
       "<td>0.7736248</td>\n",
       "<td>0.0353344</td>\n",
       "<td>0.9888228</td>\n",
       "<td>-64.6690731</td>\n",
       "<td>41.2663753</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999803</td>\n",
       "<td>0.0385063</td>\n",
       "<td>0.1045507</td>\n",
       "<td>1.2491294</td>\n",
       "<td>0.0572557</td>\n",
       "<td>0.6840676</td>\n",
       "<td>0.0104561</td>\n",
       "<td>0.9992789</td>\n",
       "<td>-89.5449298</td>\n",
       "<td>24.9129442</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999901</td>\n",
       "<td>0.0081771</td>\n",
       "<td>0.0072104</td>\n",
       "<td>1.1111233</td>\n",
       "<td>0.0039487</td>\n",
       "<td>0.6084906</td>\n",
       "<td>0.0007211</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.2789607</td>\n",
       "<td>11.1123300</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000647</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5476355</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0199427                   1                  1.82603     1.82603            1                1                           0.0364161       0.0364161                  82.6032   82.6032\n",
       "    2        0.0200415                   1                  1.82603     1.82603            1                1                           0.000180278     0.0365964                  82.6032   82.6032\n",
       "    3        0.0300128                   1                  1.82603     1.82603            1                1                           0.018208        0.0548044                  82.6032   82.6032\n",
       "    4        0.0400829                   1                  1.82603     1.82603            1                1                           0.0183883       0.0731927                  82.6032   82.6032\n",
       "    5        0.0500543                   1                  1.82603     1.82603            1                1                           0.018208        0.0914008                  82.6032   82.6032\n",
       "    6        0.10001                     0.999995           1.82603     1.82603            1                1                           0.0912205       0.182621                   82.6032   82.6032\n",
       "    7        0.150064                    0.999936           1.82603     1.82603            1                1                           0.0914008       0.274022                   82.6032   82.6032\n",
       "    8        0.20002                     0.999228           1.82603     1.82603            1                1                           0.0912205       0.365242                   82.6032   82.6032\n",
       "    9        0.30003                     0.972838           1.81702     1.82303            0.995064         0.998355                    0.18172         0.546962                   81.7019   82.3028\n",
       "    10       0.400039                    0.804761           1.77015     1.80981            0.969398         0.991115                    0.177033        0.723995                   77.0152   80.9809\n",
       "    11       0.500049                    0.50239            1.45109     1.73807            0.794669         0.951826                    0.145123        0.869118                   45.1092   73.8065\n",
       "    12       0.599961                    0.254058           0.84445     1.58925            0.462451         0.870331                    0.0843699       0.953488                   -15.555   58.9252\n",
       "    13       0.69997                     0.114944           0.353309    1.41266            0.193485         0.773625                    0.0353344       0.988823                   -64.6691  41.2664\n",
       "    14       0.79998                     0.0385063          0.104551    1.24913            0.0572557        0.684068                    0.0104561       0.999279                   -89.5449  24.9129\n",
       "    15       0.89999                     0.00817707         0.00721039  1.11112            0.00394867       0.608491                    0.000721111     1                          -99.279   11.1123\n",
       "    16       1                           6.46662e-05        0           1                  0                0.547636                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.0904372887318601\n",
      "RMSE: 0.3007279314128638\n",
      "LogLoss: 0.28021155387555136\n",
      "Mean Per-Class Error: 0.11885775001675403\n",
      "AUC: 0.9532455028844663\n",
      "Gini: 0.9064910057689326\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.28459720655547177: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1582.0</td>\n",
       "<td>351.0</td>\n",
       "<td>0.1816</td>\n",
       "<td> (351.0/1933.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>188.0</td>\n",
       "<td>2151.0</td>\n",
       "<td>0.0804</td>\n",
       "<td> (188.0/2339.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1770.0</td>\n",
       "<td>2502.0</td>\n",
       "<td>0.1262</td>\n",
       "<td> (539.0/4272.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1582  351    0.1816   (351.0/1933.0)\n",
       "YES    188   2151   0.0804   (188.0/2339.0)\n",
       "Total  1770  2502   0.1262   (539.0/4272.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2845972</td>\n",
       "<td>0.8886594</td>\n",
       "<td>256.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0972279</td>\n",
       "<td>0.9210421</td>\n",
       "<td>335.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5243182</td>\n",
       "<td>0.9093509</td>\n",
       "<td>169.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4215615</td>\n",
       "<td>0.8789794</td>\n",
       "<td>206.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999760</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0159271</td>\n",
       "<td>1.0</td>\n",
       "<td>381.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999760</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4435971</td>\n",
       "<td>0.7590179</td>\n",
       "<td>199.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3838118</td>\n",
       "<td>0.8773927</td>\n",
       "<td>220.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4435971</td>\n",
       "<td>0.8811422</td>\n",
       "<td>199.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.284597     0.888659  256\n",
       "max f2                       0.0972279    0.921042  335\n",
       "max f0point5                 0.524318     0.909351  169\n",
       "max accuracy                 0.421561     0.878979  206\n",
       "max precision                0.999976     1         0\n",
       "max recall                   0.0159271    1         381\n",
       "max specificity              0.999976     1         0\n",
       "max absolute_mcc             0.443597     0.759018  199\n",
       "max min_per_class_accuracy   0.383812     0.877393  220\n",
       "max mean_per_class_accuracy  0.443597     0.881142  199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0227060</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0414707</td>\n",
       "<td>0.0414707</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0301966</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0136811</td>\n",
       "<td>0.0551518</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400281</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0179564</td>\n",
       "<td>0.0731082</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500936</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0183839</td>\n",
       "<td>0.0914921</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1001873</td>\n",
       "<td>0.9999969</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.1829842</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500468</td>\n",
       "<td>0.9999594</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.2740487</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2001404</td>\n",
       "<td>0.9993049</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.3655408</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000936</td>\n",
       "<td>0.9695154</td>\n",
       "<td>1.8007575</td>\n",
       "<td>1.8178736</td>\n",
       "<td>0.9859485</td>\n",
       "<td>0.9953198</td>\n",
       "<td>0.1799914</td>\n",
       "<td>0.5455323</td>\n",
       "<td>80.0757545</td>\n",
       "<td>81.7873553</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000468</td>\n",
       "<td>0.7723356</td>\n",
       "<td>1.6296642</td>\n",
       "<td>1.7708487</td>\n",
       "<td>0.8922717</td>\n",
       "<td>0.9695728</td>\n",
       "<td>0.1628901</td>\n",
       "<td>0.7084224</td>\n",
       "<td>62.9664191</td>\n",
       "<td>77.0848745</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.4655726</td>\n",
       "<td>1.3259735</td>\n",
       "<td>1.6819153</td>\n",
       "<td>0.7259953</td>\n",
       "<td>0.9208801</td>\n",
       "<td>0.1325353</td>\n",
       "<td>0.8409577</td>\n",
       "<td>32.5973489</td>\n",
       "<td>68.1915348</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5999532</td>\n",
       "<td>0.2470085</td>\n",
       "<td>0.8554668</td>\n",
       "<td>1.5442277</td>\n",
       "<td>0.4683841</td>\n",
       "<td>0.8454936</td>\n",
       "<td>0.0855066</td>\n",
       "<td>0.9264643</td>\n",
       "<td>-14.4533233</td>\n",
       "<td>54.4227660</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6999064</td>\n",
       "<td>0.1213851</td>\n",
       "<td>0.4576747</td>\n",
       "<td>1.3890577</td>\n",
       "<td>0.2505855</td>\n",
       "<td>0.7605351</td>\n",
       "<td>0.0457460</td>\n",
       "<td>0.9722103</td>\n",
       "<td>-54.2325280</td>\n",
       "<td>38.9057726</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7998596</td>\n",
       "<td>0.0470283</td>\n",
       "<td>0.2309760</td>\n",
       "<td>1.2443399</td>\n",
       "<td>0.1264637</td>\n",
       "<td>0.6812994</td>\n",
       "<td>0.0230868</td>\n",
       "<td>0.9952971</td>\n",
       "<td>-76.9023973</td>\n",
       "<td>24.4339878</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8998127</td>\n",
       "<td>0.0091354</td>\n",
       "<td>0.0470507</td>\n",
       "<td>1.1113424</td>\n",
       "<td>0.0257611</td>\n",
       "<td>0.6084807</td>\n",
       "<td>0.0047029</td>\n",
       "<td>1.0</td>\n",
       "<td>-95.2949328</td>\n",
       "<td>11.1342352</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000786</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5475187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.022706                    1                  1.82642    1.82642            1                1                           0.0414707       0.0414707                  82.6422   82.6422\n",
       "    2        0.0301966                   1                  1.82642    1.82642            1                1                           0.0136811       0.0551518                  82.6422   82.6422\n",
       "    3        0.0400281                   1                  1.82642    1.82642            1                1                           0.0179564       0.0731082                  82.6422   82.6422\n",
       "    4        0.0500936                   1                  1.82642    1.82642            1                1                           0.0183839       0.0914921                  82.6422   82.6422\n",
       "    5        0.100187                    0.999997           1.82642    1.82642            1                1                           0.0914921       0.182984                   82.6422   82.6422\n",
       "    6        0.150047                    0.999959           1.82642    1.82642            1                1                           0.0910646       0.274049                   82.6422   82.6422\n",
       "    7        0.20014                     0.999305           1.82642    1.82642            1                1                           0.0914921       0.365541                   82.6422   82.6422\n",
       "    8        0.300094                    0.969515           1.80076    1.81787            0.985948         0.99532                     0.179991        0.545532                   80.0758   81.7874\n",
       "    9        0.400047                    0.772336           1.62966    1.77085            0.892272         0.969573                    0.16289         0.708422                   62.9664   77.0849\n",
       "    10       0.5                         0.465573           1.32597    1.68192            0.725995         0.92088                     0.132535        0.840958                   32.5973   68.1915\n",
       "    11       0.599953                    0.247009           0.855467   1.54423            0.468384         0.845494                    0.0855066       0.926464                   -14.4533  54.4228\n",
       "    12       0.699906                    0.121385           0.457675   1.38906            0.250585         0.760535                    0.045746        0.97221                    -54.2325  38.9058\n",
       "    13       0.79986                     0.0470283          0.230976   1.24434            0.126464         0.681299                    0.0230868       0.995297                   -76.9024  24.434\n",
       "    14       0.899813                    0.00913545         0.0470507  1.11134            0.0257611        0.608481                    0.00470286      1                          -95.2949  11.1342\n",
       "    15       1                           7.8617e-05         0          1                  0                0.547519                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_r2</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:13:36</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:13:38</td>\n",
       "<td> 8.960 sec</td>\n",
       "<td>3130 obs/sec</td>\n",
       "<td>0.2251028</td>\n",
       "<td>1</td>\n",
       "<td>7936.0</td>\n",
       "<td>0.4870113</td>\n",
       "<td>0.6656621</td>\n",
       "<td>0.0425899</td>\n",
       "<td>0.7207516</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.3745681</td>\n",
       "<td>0.4913102</td>\n",
       "<td>0.6764610</td>\n",
       "<td>0.0256569</td>\n",
       "<td>0.7057026</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.3862360</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:14:42</td>\n",
       "<td> 1 min 13.089 sec</td>\n",
       "<td>5552 obs/sec</td>\n",
       "<td>9.4215572</td>\n",
       "<td>42</td>\n",
       "<td>332157.0</td>\n",
       "<td>0.2608013</td>\n",
       "<td>0.2164834</td>\n",
       "<td>0.7254386</td>\n",
       "<td>0.9735486</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0941850</td>\n",
       "<td>0.3007279</td>\n",
       "<td>0.2802116</td>\n",
       "<td>0.6349537</td>\n",
       "<td>0.9532455</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1261704</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:15:51</td>\n",
       "<td> 2 min 20.030 sec</td>\n",
       "<td>5626 obs/sec</td>\n",
       "<td>19.5009219</td>\n",
       "<td>87</td>\n",
       "<td>687505.0</td>\n",
       "<td>0.2402027</td>\n",
       "<td>0.1789403</td>\n",
       "<td>0.7670966</td>\n",
       "<td>0.9893329</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0541021</td>\n",
       "<td>0.3100898</td>\n",
       "<td>0.3095592</td>\n",
       "<td>0.6118716</td>\n",
       "<td>0.9627931</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1055712</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:16:38</td>\n",
       "<td> 3 min  7.149 sec</td>\n",
       "<td>5616 obs/sec</td>\n",
       "<td>26.2301234</td>\n",
       "<td>117</td>\n",
       "<td>924743.0</td>\n",
       "<td>0.2076741</td>\n",
       "<td>0.1361477</td>\n",
       "<td>0.8259057</td>\n",
       "<td>0.9932308</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0425511</td>\n",
       "<td>0.3044612</td>\n",
       "<td>0.3372614</td>\n",
       "<td>0.6258340</td>\n",
       "<td>0.9607125</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1069757</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:17:26</td>\n",
       "<td> 3 min 54.848 sec</td>\n",
       "<td>5631 obs/sec</td>\n",
       "<td>33.1708127</td>\n",
       "<td>148</td>\n",
       "<td>1169437.0</td>\n",
       "<td>0.1954874</td>\n",
       "<td>0.1217299</td>\n",
       "<td>0.8457386</td>\n",
       "<td>0.9956329</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0349492</td>\n",
       "<td>0.3101265</td>\n",
       "<td>0.4025770</td>\n",
       "<td>0.6117799</td>\n",
       "<td>0.9589496</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1039326</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:18:14</td>\n",
       "<td> 4 min 42.766 sec</td>\n",
       "<td>5635 obs/sec</td>\n",
       "<td>40.1092895</td>\n",
       "<td>179</td>\n",
       "<td>1414053.0</td>\n",
       "<td>0.1459917</td>\n",
       "<td>0.0705546</td>\n",
       "<td>0.9139648</td>\n",
       "<td>0.9971435</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0279396</td>\n",
       "<td>0.2951825</td>\n",
       "<td>0.4426381</td>\n",
       "<td>0.6482926</td>\n",
       "<td>0.9544101</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1036985</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:19:01</td>\n",
       "<td> 5 min 30.441 sec</td>\n",
       "<td>5614 obs/sec</td>\n",
       "<td>46.8124805</td>\n",
       "<td>209</td>\n",
       "<td>1650374.0</td>\n",
       "<td>0.1408903</td>\n",
       "<td>0.0656799</td>\n",
       "<td>0.9198724</td>\n",
       "<td>0.9979528</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0231020</td>\n",
       "<td>0.2933162</td>\n",
       "<td>0.4595213</td>\n",
       "<td>0.6527258</td>\n",
       "<td>0.9536728</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1044007</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:19:48</td>\n",
       "<td> 6 min 17.346 sec</td>\n",
       "<td>5592 obs/sec</td>\n",
       "<td>53.3261381</td>\n",
       "<td>238</td>\n",
       "<td>1880013.0</td>\n",
       "<td>0.1286601</td>\n",
       "<td>0.0563776</td>\n",
       "<td>0.9331798</td>\n",
       "<td>0.9982646</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0193504</td>\n",
       "<td>0.2961646</td>\n",
       "<td>0.5356804</td>\n",
       "<td>0.6459483</td>\n",
       "<td>0.9504006</td>\n",
       "<td>1.8235408</td>\n",
       "<td>0.1036985</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:20:36</td>\n",
       "<td> 7 min  4.842 sec</td>\n",
       "<td>5568 obs/sec</td>\n",
       "<td>59.8222096</td>\n",
       "<td>267</td>\n",
       "<td>2109032.0</td>\n",
       "<td>0.1263827</td>\n",
       "<td>0.0535049</td>\n",
       "<td>0.9355245</td>\n",
       "<td>0.9984627</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0197453</td>\n",
       "<td>0.2976703</td>\n",
       "<td>0.5849173</td>\n",
       "<td>0.6423391</td>\n",
       "<td>0.9467777</td>\n",
       "<td>1.8238309</td>\n",
       "<td>0.1055712</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:21:25</td>\n",
       "<td> 7 min 54.304 sec</td>\n",
       "<td>5521 obs/sec</td>\n",
       "<td>66.3172032</td>\n",
       "<td>296</td>\n",
       "<td>2338013.0</td>\n",
       "<td>0.1240570</td>\n",
       "<td>0.0511289</td>\n",
       "<td>0.9378756</td>\n",
       "<td>0.9984119</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0204364</td>\n",
       "<td>0.3009028</td>\n",
       "<td>0.6587225</td>\n",
       "<td>0.6345290</td>\n",
       "<td>0.9453074</td>\n",
       "<td>1.8171386</td>\n",
       "<td>0.1069757</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:22:13</td>\n",
       "<td> 8 min 42.286 sec</td>\n",
       "<td>5502 obs/sec</td>\n",
       "<td>72.8174160</td>\n",
       "<td>325</td>\n",
       "<td>2567178.0</td>\n",
       "<td>0.1126093</td>\n",
       "<td>0.0430467</td>\n",
       "<td>0.9488120</td>\n",
       "<td>0.9988823</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0157962</td>\n",
       "<td>0.3030694</td>\n",
       "<td>0.7151072</td>\n",
       "<td>0.6292471</td>\n",
       "<td>0.9429730</td>\n",
       "<td>1.8179266</td>\n",
       "<td>0.1048689</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:22:18</td>\n",
       "<td> 8 min 47.026 sec</td>\n",
       "<td>5501 obs/sec</td>\n",
       "<td>72.8174160</td>\n",
       "<td>325</td>\n",
       "<td>2567178.0</td>\n",
       "<td>0.2608013</td>\n",
       "<td>0.2164834</td>\n",
       "<td>0.7254386</td>\n",
       "<td>0.9735486</td>\n",
       "<td>1.8260321</td>\n",
       "<td>0.0941850</td>\n",
       "<td>0.3007279</td>\n",
       "<td>0.2802116</td>\n",
       "<td>0.6349537</td>\n",
       "<td>0.9532455</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1261704</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -----------------  ---------------------------------\n",
       "    2018-06-25 03:13:36  0.000 sec                           0         0             0            nan              nan                 nan            nan             nan              nan                              nan                nan                   nan              nan               nan                nan\n",
       "    2018-06-25 03:13:38  8.960 sec         3130 obs/sec      0.225103  1             7936         0.487011         0.665662            0.0425899      0.720752        1.82603          0.374568                         0.49131            0.676461              0.0256569        0.705703          1.82642            0.386236\n",
       "    2018-06-25 03:14:42  1 min 13.089 sec  5552 obs/sec      9.42156   42            332157       0.260801         0.216483            0.725439       0.973549        1.82603          0.094185                         0.300728           0.280212              0.634954         0.953246          1.82642            0.12617\n",
       "    2018-06-25 03:15:51  2 min 20.030 sec  5626 obs/sec      19.5009   87            687505       0.240203         0.17894             0.767097       0.989333        1.82603          0.0541021                        0.31009            0.309559              0.611872         0.962793          1.82642            0.105571\n",
       "    2018-06-25 03:16:38  3 min  7.149 sec  5616 obs/sec      26.2301   117           924743       0.207674         0.136148            0.825906       0.993231        1.82603          0.0425511                        0.304461           0.337261              0.625834         0.960713          1.82642            0.106976\n",
       "    2018-06-25 03:17:26  3 min 54.848 sec  5631 obs/sec      33.1708   148           1.16944e+06  0.195487         0.12173             0.845739       0.995633        1.82603          0.0349492                        0.310126           0.402577              0.61178          0.95895           1.82642            0.103933\n",
       "    2018-06-25 03:18:14  4 min 42.766 sec  5635 obs/sec      40.1093   179           1.41405e+06  0.145992         0.0705546           0.913965       0.997143        1.82603          0.0279396                        0.295182           0.442638              0.648293         0.95441           1.82642            0.103699\n",
       "    2018-06-25 03:19:01  5 min 30.441 sec  5614 obs/sec      46.8125   209           1.65037e+06  0.14089          0.0656799           0.919872       0.997953        1.82603          0.023102                         0.293316           0.459521              0.652726         0.953673          1.82642            0.104401\n",
       "    2018-06-25 03:19:48  6 min 17.346 sec  5592 obs/sec      53.3261   238           1.88001e+06  0.12866          0.0563776           0.93318        0.998265        1.82603          0.0193504                        0.296165           0.53568               0.645948         0.950401          1.82354            0.103699\n",
       "    2018-06-25 03:20:36  7 min  4.842 sec  5568 obs/sec      59.8222   267           2.10903e+06  0.126383         0.0535049           0.935524       0.998463        1.82603          0.0197453                        0.29767            0.584917              0.642339         0.946778          1.82383            0.105571\n",
       "    2018-06-25 03:21:25  7 min 54.304 sec  5521 obs/sec      66.3172   296           2.33801e+06  0.124057         0.0511289           0.937876       0.998412        1.82603          0.0204364                        0.300903           0.658723              0.634529         0.945307          1.81714            0.106976\n",
       "    2018-06-25 03:22:13  8 min 42.286 sec  5502 obs/sec      72.8174   325           2.56718e+06  0.112609         0.0430467           0.948812       0.998882        1.82603          0.0157962                        0.303069           0.715107              0.629247         0.942973          1.81793            0.104869\n",
       "    2018-06-25 03:22:18  8 min 47.026 sec  5501 obs/sec      72.8174   325           2.56718e+06  0.260801         0.216483            0.725439       0.973549        1.82603          0.094185                         0.300728           0.280212              0.634954         0.953246          1.82642            0.12617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ArrTime</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0020700</td></tr>\n",
       "<tr><td>CRSArrTime</td>\n",
       "<td>0.9233475</td>\n",
       "<td>0.9233475</td>\n",
       "<td>0.0019113</td></tr>\n",
       "<tr><td>DepTime</td>\n",
       "<td>0.6727085</td>\n",
       "<td>0.6727085</td>\n",
       "<td>0.0013925</td></tr>\n",
       "<tr><td>CRSDepTime</td>\n",
       "<td>0.6114694</td>\n",
       "<td>0.6114694</td>\n",
       "<td>0.0012657</td></tr>\n",
       "<tr><td>AirTime</td>\n",
       "<td>0.5077853</td>\n",
       "<td>0.5077853</td>\n",
       "<td>0.0010511</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>TailNum.N782SA</td>\n",
       "<td>0.1062474</td>\n",
       "<td>0.1062474</td>\n",
       "<td>0.0002199</td></tr>\n",
       "<tr><td>TailNum.N813AW</td>\n",
       "<td>0.1056661</td>\n",
       "<td>0.1056661</td>\n",
       "<td>0.0002187</td></tr>\n",
       "<tr><td>Dest.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>Origin.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>UniqueCarrier.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance    percentage\n",
       "-------------------------  ---------------------  -------------------  ----------------------\n",
       "ArrTime                    1.0                    1.0                  0.002069951623165104\n",
       "CRSArrTime                 0.923347532749176      0.923347532749176    0.0019112847241596512\n",
       "DepTime                    0.6727085113525391     0.6727085113525391   0.0013924740749911692\n",
       "CRSDepTime                 0.6114694476127625     0.6114694476127625   0.0012657121756019074\n",
       "AirTime                    0.5077853202819824     0.5077853202819824   0.0010510910479371019\n",
       "---                        ---                    ---                  ---\n",
       "TailNum.N782SA             0.1062474474310875     0.1062474474310875   0.00021992707626712865\n",
       "TailNum.N813AW             0.10566609352827072    0.10566609352827072  0.0002187237018123597\n",
       "Dest.missing(NA)           0.0                    0.0                  0.0\n",
       "Origin.missing(NA)         0.0                    0.0                  0.0\n",
       "UniqueCarrier.missing(NA)  0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_200_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_200_epochs.plot() #overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning idea : Does another Layer helps ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 1.83 s, sys: 182 ms, total: 2.01 s\n",
      "Wall time: 8min 49s\n"
     ]
    }
   ],
   "source": [
    "m_200x200x200= H2ODeepLearningEstimator(epochs=200,\n",
    "                                       #Same early stopping as it is default\n",
    "                                       hidden=[200,200,200])\n",
    "%time m_200x200x200.train(xAll,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building Time: 8min 49 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.09166490194096985\n",
      "RMSE: 0.3027621210471512\n",
      "LogLoss: 0.30701643402864787\n",
      "Mean Per-Class Error: 0.12191513138334409\n",
      "AUC: 0.9517772378228196\n",
      "Gini: 0.9035544756456393\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2997237719048822: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1625.0</td>\n",
       "<td>325.0</td>\n",
       "<td>0.1667</td>\n",
       "<td> (325.0/1950.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>227.0</td>\n",
       "<td>2274.0</td>\n",
       "<td>0.0908</td>\n",
       "<td> (227.0/2501.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1852.0</td>\n",
       "<td>2599.0</td>\n",
       "<td>0.124</td>\n",
       "<td> (552.0/4451.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1625  325    0.1667   (325.0/1950.0)\n",
       "YES    227   2274   0.0908   (227.0/2501.0)\n",
       "Total  1852  2599   0.124    (552.0/4451.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2997238</td>\n",
       "<td>0.8917647</td>\n",
       "<td>257.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0330450</td>\n",
       "<td>0.9234522</td>\n",
       "<td>368.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6129411</td>\n",
       "<td>0.9139588</td>\n",
       "<td>149.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3121781</td>\n",
       "<td>0.8762076</td>\n",
       "<td>252.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999833</td>\n",
       "<td>0.9990282</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0001156</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999833</td>\n",
       "<td>0.9994872</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5345320</td>\n",
       "<td>0.7503543</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3931723</td>\n",
       "<td>0.8736505</td>\n",
       "<td>224.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5345320</td>\n",
       "<td>0.8780849</td>\n",
       "<td>177.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.299724     0.891765  257\n",
       "max f2                       0.033045     0.923452  368\n",
       "max f0point5                 0.612941     0.913959  149\n",
       "max accuracy                 0.312178     0.876208  252\n",
       "max precision                0.999983     0.999028  0\n",
       "max recall                   0.000115558  1         399\n",
       "max specificity              0.999983     0.999487  0\n",
       "max absolute_mcc             0.534532     0.750354  177\n",
       "max min_per_class_accuracy   0.393172     0.873651  224\n",
       "max mean_per_class_accuracy  0.534532     0.878085  177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 56.19 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0186475</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0331867</td>\n",
       "<td>0.0331867</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0202202</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0027989</td>\n",
       "<td>0.0359856</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0301056</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0535786</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0402157</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0179928</td>\n",
       "<td>0.0715714</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0501011</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0891643</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002022</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.1783287</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1500786</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.2670932</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2001797</td>\n",
       "<td>0.9999702</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.3562575</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3001573</td>\n",
       "<td>0.9875707</td>\n",
       "<td>1.7476937</td>\n",
       "<td>1.7690313</td>\n",
       "<td>0.9820225</td>\n",
       "<td>0.9940120</td>\n",
       "<td>0.1747301</td>\n",
       "<td>0.5309876</td>\n",
       "<td>74.7693731</td>\n",
       "<td>76.9031310</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4001348</td>\n",
       "<td>0.8154356</td>\n",
       "<td>1.6397127</td>\n",
       "<td>1.7367198</td>\n",
       "<td>0.9213483</td>\n",
       "<td>0.9758563</td>\n",
       "<td>0.1639344</td>\n",
       "<td>0.6949220</td>\n",
       "<td>63.9712654</td>\n",
       "<td>73.6719798</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5001123</td>\n",
       "<td>0.5351250</td>\n",
       "<td>1.3637610</td>\n",
       "<td>1.6621616</td>\n",
       "<td>0.7662921</td>\n",
       "<td>0.9339623</td>\n",
       "<td>0.1363455</td>\n",
       "<td>0.8312675</td>\n",
       "<td>36.3761012</td>\n",
       "<td>66.2161550</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6000899</td>\n",
       "<td>0.2570563</td>\n",
       "<td>0.8918437</td>\n",
       "<td>1.5338233</td>\n",
       "<td>0.5011236</td>\n",
       "<td>0.8618495</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.9204318</td>\n",
       "<td>-10.8156288</td>\n",
       "<td>53.3823311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000674</td>\n",
       "<td>0.0766907</td>\n",
       "<td>0.4639187</td>\n",
       "<td>1.3810288</td>\n",
       "<td>0.2606742</td>\n",
       "<td>0.7759949</td>\n",
       "<td>0.0463814</td>\n",
       "<td>0.9668133</td>\n",
       "<td>-53.6081298</td>\n",
       "<td>38.1028846</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8000449</td>\n",
       "<td>0.0096846</td>\n",
       "<td>0.2359587</td>\n",
       "<td>1.2379353</td>\n",
       "<td>0.1325843</td>\n",
       "<td>0.6955911</td>\n",
       "<td>0.0235906</td>\n",
       "<td>0.9904038</td>\n",
       "<td>-76.4041350</td>\n",
       "<td>23.7935267</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9000225</td>\n",
       "<td>0.0008481</td>\n",
       "<td>0.0839853</td>\n",
       "<td>1.1097506</td>\n",
       "<td>0.0471910</td>\n",
       "<td>0.6235647</td>\n",
       "<td>0.0083966</td>\n",
       "<td>0.9988005</td>\n",
       "<td>-91.6014718</td>\n",
       "<td>10.9750608</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000024</td>\n",
       "<td>0.0119979</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0067416</td>\n",
       "<td>0.5618962</td>\n",
       "<td>0.0011995</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.8002103</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0186475                   1                  1.77969    1.77969            1                1                           0.0331867       0.0331867                  77.9688   77.9688\n",
       "    2        0.0202202                   1                  1.77969    1.77969            1                1                           0.00279888      0.0359856                  77.9688   77.9688\n",
       "    3        0.0301056                   1                  1.77969    1.77969            1                1                           0.017593        0.0535786                  77.9688   77.9688\n",
       "    4        0.0402157                   1                  1.77969    1.77969            1                1                           0.0179928       0.0715714                  77.9688   77.9688\n",
       "    5        0.0501011                   1                  1.77969    1.77969            1                1                           0.017593        0.0891643                  77.9688   77.9688\n",
       "    6        0.100202                    1                  1.77969    1.77969            1                1                           0.0891643       0.178329                   77.9688   77.9688\n",
       "    7        0.150079                    1                  1.77969    1.77969            1                1                           0.0887645       0.267093                   77.9688   77.9688\n",
       "    8        0.20018                     0.99997            1.77969    1.77969            1                1                           0.0891643       0.356257                   77.9688   77.9688\n",
       "    9        0.300157                    0.987571           1.74769    1.76903            0.982022         0.994012                    0.17473         0.530988                   74.7694   76.9031\n",
       "    10       0.400135                    0.815436           1.63971    1.73672            0.921348         0.975856                    0.163934        0.694922                   63.9713   73.672\n",
       "    11       0.500112                    0.535125           1.36376    1.66216            0.766292         0.933962                    0.136345        0.831267                   36.3761   66.2162\n",
       "    12       0.60009                     0.257056           0.891844   1.53382            0.501124         0.861849                    0.0891643       0.920432                   -10.8156  53.3823\n",
       "    13       0.700067                    0.0766907          0.463919   1.38103            0.260674         0.775995                    0.0463814       0.966813                   -53.6081  38.1029\n",
       "    14       0.800045                    0.00968463         0.235959   1.23794            0.132584         0.695591                    0.0235906       0.990404                   -76.4041  23.7935\n",
       "    15       0.900022                    0.000848062        0.0839853  1.10975            0.047191         0.623565                    0.00839664      0.9988                     -91.6015  10.9751\n",
       "    16       1                           2.37671e-06        0.0119979  1                  0.00674157       0.561896                    0.00119952      1                          -98.8002  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_200x200x200.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4VOXZ+PHvnT1kD0nYEhKQNWwhCYuyi1iwVq1aBbVuVX+itrbWt2pfW62tra+1Smuta11aUbRaFRXBDUEWhYRVdmQNiUkICVnInuf3xzMJAQJJIJMzydyf65ormZNnzrnnKHPPs4sxBqWUUgrAx+kAlFJKeQ5NCkoppRpoUlBKKdVAk4JSSqkGmhSUUko10KSglFKqgSYF5fVE5BkR+Y1D1+4tIqUi4uvE9ZU6niYF5bFEZLyIrBCRwyJySESWi8iotr6OMeZWY8zv2/q8IpIkIkZE/I47/rKI/MF17X3GmFBjTG0z57peRJa1dYxKHc+v+SJKtT8RCQc+AGYDbwIBwASgso2v49vcB3JnICJ+xpgap+NQnk9rCspTDQAwxrxujKk1xpQbYz42xmyoLyAiN4vIFhEpEZHNIpLqOj5YRL4QkSIR2SQiFzV6zcsi8rSILBCRMmBK42/uIjJZRLJE5JcikiciOSJyQ6PXdxWR90WkWERWi8gfzuQb/PG1CVeNYJfrPe0WkatFZDDwDHC2q6mpyFU2QkT+JSL5IrJXRO4XEZ9G51kuIk+IyCHg967a1rBG144TkXIRiT3d+FXno0lBeartQK2IvCIiM0QkqvEfReRHwIPAtUA4cBFQICL+wPvAx0Ac8FNgrogMbPTyq4CHgTCgqQ/07kAE0Av4CfBUo+s/BZS5ylznerQJEQkB/gbMMMaEAecA64wxW4BbgZWupqZI10uedMXZF5iEvRc3NDrlGGAX9j48BMwDrmn091nAp8aY/LZ6D6rj06SgPJIxphgYDxjgeSBfROaLSDdXkZuAR40xq4210xizFxgLhAKPGGOqjDGfY5uhZjU6/XvGmOXGmDpjTEUTl68GHjLGVBtjFgClwEBXZ/BlwAPGmCPGmM3AKy14OwddtZYi17f8q05Rtg4YKiLBxpgcY8ympgq5YrkSuM8YU2KM2QP8Bfhxo2LZxpgnjTE1xphyV6xX1dcmXGX/3YL4lRfRpKA8ljFmizHmemNMPDAU6AnMcf05Afi2iZf1BPYbY+oaHduL/dZfb38zly44rv39CDbRxGL74Rq/vrlzAcQYYyLrH8BrTRUyxpRhP+hvBXJE5EMRGXSyc2L7WfY2OnbK92mM+Rpby5nkOm8/YH4L4ldeRJOC6hCMMVuBl7HJAewH3llNFM0GEhp9GwboDRxofLrTDCMfqAHiGx1LOM1zNckYs8gYMw3oAWzF1pLgxJgPYms0iY2OteR9voJtQvox8NZJakrKi2lSUB5JRAa5OnvjXc8TsE1AX7mKvADcLSJpYvUTkUSg/tvwr0TEX0QmAz/AtqefEdcopf8CD4pIF9e37WvP9Lz1RKSbiFzk6luoxDZb1Y+MygXiRSSgUSxvAg+LSJjrvd8FvNrMZf4N/BCbGP7VVrGrzkOTgvJUJdiO0q9do4S+Ar4BfglgjPkPtrP4NVfZd4FoY0wVttN5Bvbb9D+Aa101jbZwB7Zz9zvsB+zrtN0wWR/s+8sGDmE7j29z/e1zYBPwnYgcdB37KTYB7sJ2mL8GvHiqCxhjsoA12FrEl20Ut+pERDfZUer0icj/Ad2NMW02CsndRORFbCf0/U7HojyPTl5TqhVcTUYBwEZgFHbI6k2OBtUKIpIEXAqMdDYS5am0+Uip1gnD9iuUYdv0/wK852hELSQiv8c2wf3ZGLPb6XiUZ9LmI6WUUg20pqCUUqpBh+tTiImJMUlJSa1/YUUuHMmCyOHg49/mcSmllCfLzMw8aIxpdp2rDpcUkpKSyMjIaP0LCzJg0Sg45z5Imtn2gSmllAcTkb3Nl/Km5qOoFPALg7wlTkeilFIey3uSgo8fxI7XpKCUUqfgPUkBoNskKN4CFXlOR6KUUh6pw/UpnK4PNmSzenU0vwsG8r6E3pc5HZJSXq+6upqsrCwqKnRdvrYSFBREfHw8/v6nN6DGa5JCRXUdc3fE8UBKF3zylmhSUMoDZGVlERYWRlJSEiLidDgdnjGGgoICsrKy6NOnz2mdw2uaj9ITo6jBj9zAVO1XUMpDVFRU0LVrV00IbURE6Nq16xnVvLwmKSR27UJMaABrK4dD0UaoPOR0SEop0ITQxs70fnpNUhAR0hKj+Ci3P2Ag/7T3WldKqU7La5ICQFpiFB9/l4jxCdQmJKW8XEFBASkpKaSkpNC9e3d69erV8LyqqqpF57jhhhvYtm3bKcs89dRTzJ07ty1Cbhde09EMkJYYTaUJoDA4lWhNCkp5ta5du7Ju3ToAHnzwQUJDQ7n77ruPKWOMwRiDj0/T359feumlZq9z++23n3mw7ciragpDe4UT4OfDN9UpULgWqg47HZJSysPs3LmToUOHcuutt5KamkpOTg633HIL6enpDBkyhIceeqih7Pjx41m3bh01NTVERkZy7733MmLECM4++2zy8ux8qPvvv585c+Y0lL/33nsZPXo0AwcOZMWKFQCUlZVx2WWXMWLECGbNmkV6enpDwmpvXlVTCPTzZUR8BJ8UDGJiWB0cXAE9ZzgdllIK+N37m9icXdym50zuGc4DPxjS6tdt3ryZl156iWeeeQaARx55hOjoaGpqapgyZQqXX345ycnJx7zm8OHDTJo0iUceeYS77rqLF198kXvvvfeEcxtjWLVqFfPnz+ehhx5i4cKFPPnkk3Tv3p23336b9evXk5qaenpvuA14VU0BbBPSu/vjMeKv/QpKqSadddZZjBo1quH566+/TmpqKqmpqWzZsoXNmzef8Jrg4GBmzLBfMtPS0tizZ0+T57700ktPKLNs2TJmzrQLdY4YMYIhQ1qfyNqKV9UUwM5XeGZJIKUhIwnL1aSglKc4nW/07hISEtLw+44dO/jrX//KqlWriIyM5JprrmlyHkBAQEDD776+vtTU1DR57sDAwBPKeNJmZ15YU4gCYLtJhUMZUFPmcERKKU9WXFxMWFgY4eHh5OTksGjRoja/xvjx43nzzTcB2LhxY5M1kfbidTWFqJAAzooNYUnRYNL8ayB/BfSY5nRYSikPlZqaSnJyMkOHDqVv376MGzeuza/x05/+lGuvvZbhw4eTmprK0KFDiYiIaPPrtESH26M5PT3dnNYmO43c89YGvtyyi+X9LkeS74MRv2+j6JRSrbFlyxYGDx7sdBiOq6mpoaamhqCgIHbs2MH555/Pjh078PM7ve/tTd1XEck0xqQ391qvqykApCVF8UaGP5VhIwjSzmallMNKS0uZOnUqNTU1GGN49tlnTzshnCnvTAqufoXdPukMLngZasrBL9jZoJRSXisyMpLMzEynwwC8sKMZoG9MCNEhAawoGQp1VVDwtdMhKaWUR/DKpCAipPaO4p2sPoBA3lKnQ1JKKY/glUkBID0pim/yhZrw4TqJTSmlXLw3Kbj6FQ4EjIKDK6G2ZasiKqVUZ+bWpCAi00Vkm4jsFJETFgERkSdEZJ3rsV1EitwZT2NDe0UQ4OvD6iPDobYcDq1ur0srpTzE5MmTT5iMNmfOHG677baTviY0NBSA7OxsLr/88pOet7mh83PmzOHIkSMNzy+44AKKitrtI/Ck3JYURMQXeAqYASQDs0TkmBWkjDG/MMakGGNSgCeB/7ornuMF+fsyLD6C93P62gPahKSU15k1axbz5s075ti8efOYNWtWs6/t2bMnb7311mlf+/iksGDBAiIjI0/7fG3FnTWF0cBOY8wuY0wVMA+4+BTlZwGvuzGeE6QnRrEyy4e68CHa2ayUF7r88sv54IMPqKysBGDPnj1kZ2eTkpLC1KlTSU1NZdiwYbz33nsnvHbPnj0MHToUgPLycmbOnMnw4cO58sorKS8vbyg3e/bshmW3H3jgAQD+9re/kZ2dzZQpU5gyZQoASUlJHDx4EIDHH3+coUOHMnTo0IZlt/fs2cPgwYO5+eabGTJkCOeff/4x12kr7pyn0AvY3+h5FjCmqYIikgj0AT4/yd9vAW4B6N27d5sFmJYYxbNLd3Gwyxji8t+Euhrw8cqpG0o5L/PnUNjGewhEpUDanJP+uWvXrowePZqFCxdy8cUXM2/ePK688kqCg4N55513CA8P5+DBg4wdO5aLLrropPsfP/3003Tp0oUNGzawYcOGY5a+fvjhh4mOjqa2tpapU6eyYcMGfvazn/H444+zePFiYmJijjlXZmYmL730El9//TXGGMaMGcOkSZOIiopix44dvP766zz//PNcccUVvP3221xzzTVtc69c3FlTaOrunWxNjZnAW8aY2qb+aIx5zhiTboxJj42NbbMA6yexra8cATWlcGhNm51bKdUxNG5Cqm86Msbw61//muHDh3Peeedx4MABcnNzT3qOpUuXNnw4Dx8+nOHDhzf87c033yQ1NZWRI0eyadOmZhe7W7ZsGT/84Q8JCQkhNDSUSy+9lC+//BKAPn36kJKSApx6ee4z4c6vxVlAQqPn8UD2ScrOBNp9z7quoYH0iQnho7wBTPPH9ivEjG7vMJRScMpv9O50ySWXcNddd7FmzRrKy8tJTU3l5ZdfJj8/n8zMTPz9/UlKSmpyuezGmqpF7N69m8cee4zVq1cTFRXF9ddf3+x5TrUeXf2y22CX3nZH85E7awqrgf4i0kdEArAf/POPLyQiA4EoYKUbYzmptMQovtjniwkbqP0KSnmh0NBQJk+ezI033tjQwXz48GHi4uLw9/dn8eLF7N2795TnmDhxInPnzgXgm2++YcOGDYBddjskJISIiAhyc3P56KOPGl4TFhZGSUlJk+d69913OXLkCGVlZbzzzjtMmDChrd5us9yWFIwxNcAdwCJgC/CmMWaTiDwkIhc1KjoLmGccWq41PTGKQ2VVlISfDflfQl2TLVhKqU5s1qxZrF+/vmH3s6uvvpqMjAzS09OZO3cugwYNOuXrZ8+eTWlpKcOHD+fRRx9l9Gjb4jBixAhGjhzJkCFDuPHGG49ZdvuWW25hxowZDR3N9VJTU7n++usZPXo0Y8aM4aabbmLkyJFt/I5PziuXzm5sZ14J5z2+lHnTvmVs7p0wfQ1Et99/AKW8mS6d7R5nsnS2185ortc3JpTILv58dsj1TUDnKyilvJjXJwUfHyGtdxSf7QuA0L6aFJRSXs3rkwLYTXd25ZdRGTXe9iuYOqdDUsprdLQmbE93pvdTkwKQnhgNwA5SobIADju3abZS3iQoKIiCggJNDG3EGENBQQFBQUGnfQ6dvgsMj4/A31f48vAQhoJtQooc6nRYSnV68fHxZGVlkZ+f73QonUZQUBDx8fGn/XpNCtjF8Yb2iuDzLJjdPcEmhQHtPpdOKa/j7+9Pnz59nA5DNaLNRy7piVGszyqmNnaincSm1VmllBfSpOCSlhhFVU0dWX7pUJELJdudDkkppdqdJgWXNFdn81elrr4EHZqqlGcrXAdHDjgdRaejScElNiyQxK5d+OxABAR1h1xNCkp5pLpa2PAgfJQKn0yAqkKnI+pUNCk0kpYYRebeIkzcJFtT0H4FpTxLeS4s/h588zvo9QMoz4IV1+jcojakSaGR9MRoCsqqKOgyBsoPQNlup0NSStXLWwoLR8LB5TDmnzDxXUj7K2QvgG9+73R0nYYmhUbSk+ymO5nlw+wBbUJSynmmDjb9CT6bAn5hcP7XcNaNIAL9boU+18LG38GBBU5H2iloUmikX2wo4UF+LM6JhcAY7WxWymmVBfDFhbD+19D7CpieAVFHdzVDBEY9A1EjYMXVULrLuVg7CU0Kjfj4iO1X2FcEcRM1KSjlpPyV8NFIyP0MRv0DznkN/MNOLOcXDBPetr9/eRnUHGnfODsZTQrHSU+KZkdeKUcix0HZHijb53RISnkXY2DrE/DpRBA/OH8F9J9tawUnE9oXzplrh6munq2DRM6AJoXjpCXafoVvqkfYA7pFp1Ltp6oQvrwU1txlRxfNWAPRaS17ba8LYOgDsPtfsPNZ98bZiWlSOM6I+Ej8fIQlud3BP1KbkJRqLwUZ8FEaHPgAUp+wTUIBka07x7DfQs8LIPNncPBr98TZyWlSOE5wgC9Deoazel8xxE3QpKCUuxkD25+CT8aBqYFpX8Kgn5+6uehkxAfO/jcEx9v+hYq8to+3k9Ok0IS0xGjW7y+iJmYilOyA8hynQ1Kqc6ouhuUzIeMO6H4ezFgLMWPP7JyB0baWUVVgz11X0zaxeglNCk1IT4qisqaObxlpD2i/glJtr3A9LEyH/W9DyiMw6X0I7No2544eCaOehdzFsP5/2+acXkKTQhPSXZ3NywoS7GQZbUJSqu0YAztfgI/HQk0ZTF0MyffYpp+21PdaO2ppy6Ow7+22PXcn5takICLTRWSbiOwUkXtPUuYKEdksIptE5DV3xtNSceFBJEQHs3pvCcSO06SgVFupKYOV18GqmyF2vG0uipvgvuulPgFdx8BX18Phre67TifitqQgIr7AU8AMIBmYJSLJx5XpD9wHjDPGDAF+7q54Wis9MZqMvYWYuIl2z+YK3S5QqTNyeDMsGg17XoVhv4PJCyEozr3X9A2ECW+Bb7Ad6lpd4t7rdQLurCmMBnYaY3YZY6qAecDFx5W5GXjKGFMIYIzxmKECaYlRHCytJDdwtD2g/QpKnb7d/4aFo6DyIJz7iR066uPbPtfuEg/j34CSbfDVjTqxrRnuTAq9gP2Nnme5jjU2ABggIstF5CsRmd7UiUTkFhHJEJGM9trgu35xvJWH+9hvGZoUlGq9mnL4+mZYeS10HQUz1kH3qe0fR7cpMOIR2P8WbH28/a/fgbgzKTQ1yPj4FO0H9AcmA7OAF0TkhNkqxpjnjDHpxpj02NjYNg+0KQPiwggL8mP1vjKIOUf7FZRqreLttjP52xdgyK/h3E8huIdz8Qy+GxIug3X3QO4XzsXh4dyZFLKAhEbP44HsJsq8Z4ypNsbsBrZhk4TjfHyE1N5RZO4phLhJULRBd3hSqqX2vmmHm5YfgMkLYMTD4OPnbEwiMPYlCOsPy6+EI1nOxuOh3JkUVgP9RaSPiAQAM4H5x5V5F5gCICIx2OYkj1n7Ni0xiu15JZRGjgMM5H3pdEhKebbaSlh9h/3QjRwK09dCzxlOR3WUfxhM+K9dSfXLH0FtldMRtUzRN/D1Te2yNLjbkoIxpga4A1gEbAHeNMZsEpGHROQiV7FFQIGIbAYWA/9jjClwV0ytlZ4YhTGQWdoPfAK1X0GpUyndbZeq2PEUDPolnLcEQhKaf117ixgMY1+Egq/swnuerOYIrLvPLiH+7T8h52O3X9Kt9TljzAJgwXHHftvodwPc5Xp4nJTekfj6CKv3lTMpZoz2Kyh1MkUb4fPz7Dfvie9C/PEDDT1M7x/ZPoYtj0HMGOjzY6cjOlH2Qlh9m90WOP4SyHq3XS6rM5pPoUuAH8k9wsnYe8j2KxSusWu1KKWOOrQGPp0M4g/nr/T8hFBvxJ8gbjKsusXuw+ApynNg2Uz4Ygb4BtgZ36OebrfLa1JoRlpiFOv2F1ETM8HuFZu/3OmQlPIc+Svhs3PBPxymLYWIQU5H1HI+fjBuHgR0tSuqOj2QxNTBjqfhg0G2VjDsIZixHrpNbtcwNCk0Iz0piorqOrZUJdtdoLQJSSkr9wtYPA0CY+G8pXb3s44muBuM/w8c2Q8rrrEfzE4o3AAfj7PNRdGj4IKNMOw3dkZ2O9Ok0Iz0xGgAVmVV2ck32tmsFGQvss0bIYm2huCJHcotFXs2pM6B7AXwzR/a99o1ZbD2V7AwFUq/hbNftTO+w50bma9JoRndI4LoFRnMmr2u+QoFq+1/SKW8VdZ8WHoRhA+CqV84OyGtrfSfDUk/ho0PQvZH7XPNAx/Ch0Ngy5+h7w1w4Vboc/XpbS7UhjQptEB6UhQZew9hYifanaEOrnQ6JKWcsfdN2/4elQJTP4eg9llhwO1EYPQzEDkcVlzt3vkAR7LtHIklF4JfCJz3JYx53m4O5AE0KbRAemIUucWVHPBPtWu+52q/gvJCu16BFbMg5mzbxBEQ5XREbcuvi92xzRib+GrK2/b8dbWw7UnbkZz9AYz4o53cFze+ba9zhjQptECqa9OdjAM1EJUK+dqvoLzMjmfsngTdzoUpH9nRRp1R2Flwzqt2iOrq2W23ouqhtXYdqMyf2aR6wTcw5D475NTDaFJogUHdwwkN9Ds6X+Hg11Bb4XRYSrWPrXPsB2TP79stM/1CnI7IvXp9H4Y+ALtfgZ3Pntm5qksh8y5YlG5HOJ3zOkxZaJOPh9Kk0AK+PsLI3pFk1C+OV1dpE4NSnd2mP8KaX9jVRSf8F3yDnI6ofQz7LfSYYb/Zn+6/9az34MNk2PYEnHWL7UhOmul4R3JzNCm0UFpiFNtySygOHwOIzldQnZsxsP5+u+l90tV2kpcHNnW4jfjYZqTgXrDscqhoxf5fZfth6Q9h6SUQEAnTVsDop+3vHYAmhRZKT4zGGFj7ndgRCpoUVGdlDKy9GzY9DGfdBGNfcX7ZaycERtvaUeVBWD4T6mpOXb6uxja1fZgMOYsg5f9geqadB9GBaFJooZTekfgIZO6p71dY2XGW3VWqpUwdZNxudycb8FMY/Wz7bZvpiaJHwqhnIHexrTWdTEEGLBpjm9riJsL3N0Hyr8DHv/1ibSOaFFooNNCPwT3CydhbCN0mQW05HMpwOiyl2k5dLXz9E7v+zuBfQdpfbTOKt+t7HfS7FbY8CvvePvZv1cWQcSd8PAYqcuySGZM+gNA+zsTaBvS/eCuk1y+O19U1rlibkFRnUVdtJ23tehmGPQgpj3h8h2i7SpsDXcfYYbmHt9omtv3/hQ8Gw/Ynod9s+P4W6H15h79vmhRaIS0pmiNVtWwtDISIIZoUVOdQWwnLroB9b0DKozDsgQ7/wdbmfANhwlvgGwxfXgpLL7YT3AJj4fyvYNTfISDC6SjbhCaFVkivn8S255BtN8xf3nznk1KerKbcjpLJehfSnoTk/3E6Is/VJd6OwirZBt99BiP/AtMzIGa005G1KU0KrdAzMpgeEUG2XyFuEtSUQuFap8NS6vRUl8KS79uRMmNegIF3OB2R5+t+rh1i+oNtMPiuTjkqS5NCK6UlRpFZnxRAm5BUx1R1GBZ/zy4Ff86rcNZPnI6o44gZY2sNnZQmhVZKT4wi53AFByojIGyALo6nOp7KAvh8KhxaDePegKSrnI5IeRBNCq2UnmSXtz3ar/ClHcqnVEdQkQefTYGib2DCO9D7MqcjUh5Gk0IrDeoeRpcA36NNSNWH4fBGp8NSqnlHDsCnE6HkW5j8oV34TanjuDUpiMh0EdkmIjtF5N4m/n69iOSLyDrX4yZ3xtMW/Hx9jl0cD7QJSXm+0j02IRzJtqt0dp/qdETKQ7ktKYiIL/AUMANIBmaJSHITRd8wxqS4Hi+4K562lJYYzdbviin16wEhfbSzWXm24h02IVQegnM/hbgJTkekPJg7awqjgZ3GmF3GmCpgHnCxG6/XbtITo6gzsHafa8mL/KV2zRilPM3hzTYh1JbDeYs73Zh61fbcmRR6AfsbPc9yHTveZSKyQUTeEpGEpk4kIreISIaIZOTn57sj1lYZWb843t5CiJ1oR3Mc3uJ0WEodq3AdfOpq4jxvid1XWalmuDMpNDVP/vi97d4Hkowxw4FPgVeaOpEx5jljTLoxJj021vmNwsOC/BnYPdwmhW46X0F5oIOr4NMpdlmG85ZCRFMtt0qdyJ1JIQto/M0/HshuXMAYU2CMqXQ9fR5Ic2M8bSo9MYq1+4qoDU6yE1k0KShPkfclfH6e3Q/gvKUQ3t/piFQH4s6ksBroLyJ9RCQAmAnMb1xARHo0enoR0GHaYNISoyitrGFrbokdhZS3pO02+VbqdH33KSyeDl162oQQmuR0RKqDafXCHSLiA4QaY4pPVc4YUyMidwCLAF/gRWPMJhF5CMgwxswHfiYiFwE1wCHg+tbG45Q01+J4mXsLGRI3EfbMhZLtED7Q4ciU42rKIHsh1FW5BiDUuX4a+7Pxsaae15c7ZZk615eQRsfqKmHn8xA+AKZ8AsHdHLsFquNqUVIQkdeAW4FaIBOIEJHHjTF/PtXrjDELgAXHHftto9/vA+5rbdCeID4qmG7hgWTsKeTaIfX9Cks1KXg7UwdLL4XvPnbfNcQH8LE/xQeQo8dizrZLPAd2dd/1VafW0ppCsjGmWESuxn7I34NNDqdMCp2ZiJCeGG07m8NSIKibbULqd7PToSknbX3cJoSRj0GvCznmw7vhw1yOPd5kmUYf9seU0X0OlHu1NCn4i4g/cAnwd2NMtYh4fQN6WmIUH27MIae4gh6N+xX0H653KlgN6+6DhMtg0F36/4HqkFra0fwssAcIAZaKSCJwyj4Fb5CeVL/pjmvJiyNZULbb4aiUI6pLYPksCO4BY57XhKA6rBYlBWPM34wxvYwxFxhrLzDFzbF5vME9wgn2r18cb6I9mLfU2aCUM1bfbr8QnPMaBEQ5HY1Sp61FSUFE7hSRcLH+KSJrgHPdHJvH8/f1ISUh0iaFiGTbuafzFbzP7n/Dnn/D0AcgbrzT0Sh1RlrafHSjawjq+UAscAPwiNui6kDSk6LYnFNMWVWdXfJCV0z1LiU7YfVttqY45H+djkapM9bSpFDfQHoB8JIxZj1NL2PhddISo6itM6zfX2T7Fcp2Q9n+5l+oOr7aKtuP4OMPZ78KPr5OR6TUGWtpUsgUkY+xSWGRiIQBuiwoMLJ3FCKQcUy/gtYWvMKG++FQBoz5J4Q0uZajUh1OS5PCT4B7gVHGmCNAALYJyetFBPszIC7MJoXI4eAfoZ3N3iDnY9jyZ+g/GxJ+6HQ0SrWZFs1TMMbUiUg8cJXYoXZLjDHvuzWyDiQtKYr312VTiw++sRO0ptDZlefCymshYgiM/IvT0SjVplo6+ugR4E5gs+vxMxH5kzsD60jSE6Moqaxhe26JXUpGfVjUAAAgAElEQVS7ZDuU5zgdlnIHUwdfXWf35h43D/yCnY5IqTbV0uajC4BpxpgXjTEvAtMB3fXbJT0xGnD1K8TqfIVObesTkLMIUp+AyKFOR6NUm2vN0tmRjX6PaOtAOrKE6GBiwwLJ3HMIolPBL1STQmdUkAHr74P4H0K//+d0NEq5RUvXPvoTsFZEFmOHok6kg65u6g52cbwoW1Pw8YPYcdqv0NnUL2MR1A3GvKDLWKhOq6XLXLwOjAX+63qcbYyZ587AOpq0xCiyCsvJLa6w8xUOb4KKg06HpdpKxh1QtgvOmWt3NFOqkzplUhCR1PoH0AO7xeZ+oKfrmHJJT7IfFHYdJNf+CvnahNQp7H4Vdv8Lhvzm6FwUpTqp5pqPTjXezqDrHzUY0jOcIH8fMvYUckFyut0wPXcJJFzqdGjqTJR8C6tnQ+wEGHq/09Eo5XanTArGGK9fCbWl/H19GBEfSebeQ+AbYHfA0ppCx9Z4GYtzXrX9RUp1ci3djrOpr7uHgY3GmLy2DanjSkuM4rmluyivqiU4bhJsfBCqCnUp5Y5qw2/g0GqY8DaE9HY6GqXaRWuWuXgBuNr1eB64C1guIj92U2wdTnpSFDV1hnX1i+NhIG+Z02Gp05HzMWx5FPrdqk2Ayqu0NCnUAYONMZcZYy4DkoFKYAx2v2YFpPa2NYLMvYeg62jwCdChqR1RRd7RZSxSH3c6GqXaVUuTQpIxJrfR8zxggDHmEFDd9mF1TJFdAugfF2rnK/gFQ9cxmhQ6GlMHK3UZC+W9WpoUvhSRD0TkOhG5DpiP3as5BCg62YtEZLqIbBORnSJy7ynKXS4iRkTSWxe+50lPimLN3kLq6oxtQipcYyc+qY5h6xzIWWhrCLqMhfJCLU0KtwMvASnASOAV4HZjTNnJRiiJiC/wFDAD29w0S0SSmygXBvwM+Lr14XuetMRoiitq2JFXahfHM3WQv9zpsFRLHMqE9fdC/CW2L0EpL9TSGc0GWAZ8DnwKLHUdO5XRwE5jzC5jTBUwD7i4iXK/Bx4FKloctQdLT7T9Chl7D9lhqeKnTUgdQXUJLJvpWsbin7qMhfJaLV06+wpgFXA5cAXwtYhc3szLemFnP9fLch1rfN6RQIIx5oNmrn+LiGSISEZ+fn5LQnZMYtcuxIQG2JnNfiEQna5JoSPI+KldxuLsV3UZC+XVWjob53+xu67lAYhILLbG8NYpXtPUV62G2oWI+ABPANc3d3FjzHPAcwDp6enN1VAcJSKkJUbZpAC2CWnLX6DmCPh1cTY41bTdc2H3KzD0t/a/l1JerKV9Cj7HTVIraMFrs4DGG9fGA9mNnocBQ4EvRGQPdsG9+Z2iszkxmr0FR8gvqbSdzaYGDq50OizVlIZlLMbB0N84HY1SjmtpUlgoIotE5HoRuR74EFjQzGtWA/1FpI+IBAAzsaOWADDGHDbGxBhjkowxScBXwEXGmIxWvwsPk5rYaL5C7DgQH21C8kT1y1iIr139VJexUKrFHc3/g22+GQ6MAJ4zxpxy0poxpga4A1gEbAHeNMZsEpGHROSiMwvbsw3tFU6An10cD/9wiBqpScETbfytXcZizPMQkuh0NEp5hBZ/NTLGvA283ZqTG2MWcFyNwhjz25OUndyac3uyQD9fRsRH2ElsYJuQtj8FtRXgG+RscMrK+QQ2/x/0uwV6NzdmQinv0dx+CiUiUtzEo0REitsryI4oLTGaTdmHqaiutUmhrhIKVjkdloKjy1iED7Z7LSulGpwyKRhjwowx4U08wowx4e0VZEeUnhhFda1h/f4iiJsAiN1fQTnL1MHK6+3qtePm6YgwpY7T0o5m1UppDZPYXEtnRw6H7A+gbJ/DkXm5bX+FnI8g9S8QNdzpaJTyOJoU3CQqJICzYkOOzldInGmbj95LhPcH2slSWfOhWlvh2s2hNbDuHuh1EfS/zelolPJIOgbPjdITo1m46Tvq6gw+yfdArx/Ad5/Ytfq/fRG2/90ugxEzFrpPs4+uo3RopDtUl8LymRAYB2Nf1GUslDoJ/fRxo7SkKN7I2M+ug6X0iwuDyCH2MejnUFtpJ7TlfGwTxcYHYeMD4B8B3c6FHtOg+/kQdpbTb6NzyPwplOyEqYshsKvT0SjlsTQpuFHD4nh7Cm1SaMw3ELpNtg/+CJUFkPv50SSR9Y4tF9LHlSCm2WSh6/K03p7XYNfLdsayLmOh1ClpUnCjPjEhRIcEkLG3kJmjm9njN7Ar9P6RfRhjv9V+50oQe+fBzufszOjo9KNNTTFng29A+7yZjqp0F6y6FWLOsWsbKaVOSZOCG4kIqb0bLY7X8hdCeH/7GHA71FXbTuqcT2yS2PwIbHrYrsIaN9kmiB7nQ/ggbSuvV1cLJTvgq+tsMh33mvbVKNUC+q/EzdKTovh0Sy4HSyuJCQ08vZP4+Ns1lGLHwfAHoeow5C4+2mmd/aEtF9zraF9E9/MgKLbN3odHq62Ew9/AobVQ6HoUbYCaMvv38W/qMhZKtZAmBTdLb1gcr5DvDeneNicNiICES+wDoHSPTRDffQJZ79n2c4CoFFcz01gI7Wv7JwIi2iYGp1QXQ+G6YxPA4c12JVoAvzD7vvv+xP6MORsiBjkbs1IdiCYFNxvaK4IAX5+2TQrHC02CfjfbR12t3Re6vhaxbQ5sqT5aNiAaQvscTRKhfY8+79Lbs/ooyr87+sFfnwRKvz3696BudrHBnt+H6JH299C+trlIKXVaNCm4WZC/L8PiI8jYc6h9Lujja+c6dB0FQ35tm1CKt9oO19LdR38WroOsd21/RT3xgeD4kySNPhDU3T19FqbOFdNxCaDiu6NlQvvaD/2+N9if0SMhuEfbx6KUl9Ok0A7SE6N4afkeKqprCfL3bd+L+4VAdJp9HK+uFsqzbaIo231s4shZCOU5x5b3DYaQpGNrF40Th3/Yidc44ZrVtrmncK1NTPU/62d2iy9EJNuO8yjXt/+olI7f7KVUB6FJoR2kJUbx7NJdbDxwmFFJHjTPwMcXQhLsgybG79eUQ9meo4miceLIWwo1JceWD4w5sXYRHG9fV18DOPwN1FXZ8r5d7JpQSVcfTQCRQ3V5caUcpEmhHaQ16mz2qKTQHL9giBhsH8czBqoONZ0wDmXA/rePdv6CnYcRNRIG3nn023/YAJuYlFIeQ5NCO+gaGkjfmBC7E1tnmVArYj/oA7tC1ya21a6rhfIsOJJlO7C7xOscCqVOV0AUnPuJnYvkZjpMo52M6RvN0h35LNr0XfOFOwMfXzs3IHacbZ7ShKDU6fMNtHOPusS7/VKaFNrJ3ecPZHCPcG59NZOXl+92OhyllGqSJoV20jU0kHk3j+W8wd148P3N/OGDzdTVGafDUkqpY2hSaEfBAb48c00a15+TxAvLdnP7a2vsHs5KKeUhNCm0M18f4YEfJHP/9wezcNN3XP3C1xwqq3I6LKWUAjQpOEJEuGlCX566KpWNBw5z2dMr2FtQ5nRYSinl3qQgItNFZJuI7BSRe5v4+60islFE1onIMhFJdmc8nuaCYT14/eYxFB2p4of/WMGafa1cYlsppdqY25KCiPgCTwEzgGRgVhMf+q8ZY4YZY1KAR4HH3RWPp0pLjOa/t40jLMiPWc99xcJvvGTIqlLKI7mzpjAa2GmM2WWMqQLmARc3LmCMKW70NATwyuE4fWJC+O/scxjcI5zZczN5cZkOWVVKOcOdSaEXsL/R8yzXsWOIyO0i8i22pvCzpk4kIreISIaIZOTn57slWKd1DQ3k9ZvHcn5yNx76YDMPvb+ZWh2yqpRqZ+5MCk1NYT3hU84Y85Qx5izgHuD+pk5kjHnOGJNujEmPje28u4kFB/jyj6vTuGFcEi8u383tc3XIqlKqfbkzKWQBCY2exwPZpyg/D7jEjfF0CHbI6hB+c2EyizZ/x6znv6KgtNLpsJRSXsKdSWE10F9E+ohIADATmN+4gIj0b/T0+8AON8bTofxkfB+evjqVzdnFXPr0CnYf1CGrSin3c1tSMMbUAHcAi4AtwJvGmE0i8pCIXOQqdoeIbBKRdcBdwHXuiqcjmj60B6/dPJaSihou/cdyMvfqkFWllHuJMR2rMzM9Pd1kZGQ4HUa72nOwjOtfWkXO4QrmXJnCjGG6DaVSqnVEJNMY08Q698fSGc0dQFJMCP+9bRxDeoZz22tr+KcOWVVKuYkmhQ4iOiSA124ey/Qh3fn9B5t5cP4mHbKqlGpzmhQ6kCB/X566KpWfjO/Dyyv2MPvVTMqrdMiqUqrtaFLoYHx8hN9cmMwDP0jmky25zHr+Kw7qkFWlVBvRpNBB3TCuD09fncaWnGIu/ccKduWXOh2SUqoT0KTQgU0f2p3XbxlLaWUNlz69gow9h5wOSSnVwWlS6OBSe0fxzm3nENUlgKte+JoPN+Q4HZJSqgPTpNAJJHYN4e3Z5zCsVwS3v7aG55fuoqPNP1FKeQZNCp1EdEgAc28awwXDuvPwgi06ZFUpdVo0KXQiQf6+/H1WKrdM7MsrK/dyqw5ZVUq1kiaFTsbHR/j1BYP53UVD+GxLLjOfW0l+iQ5ZVUq1jCaFTuq6c5J49sfpbMstYfqcpbyxeh912pyklGqGJoVObFpyN965bRx9YkK45+2NXPKP5azZpyutKqVOTpNCJze4Rzj/ufVs/jozhdziCi79xwp++eZ68koqnA5NKeWBNCl4ARHh4pRefP7LycyefBbvr8/m3MeW8NzSb6mqqXM6PKWUB9Gk4EVCAv24Z/ogFv1iImP6RPPHBVuZPmcpX2zLczo0pZSH0KTghfrEhPDP60fx0vWjMMD1L63mplcy2FugW34q5e00KXixKYPiWPTzidw7YxArvz3ItMeX8udFWymrrHE6NKWUQzQpeLkAPx9unXQWn989mQuH9+Cpxd8y9S9LeG/dAV0qQykvpElBAdAtPIjHr0zh7dlnExMWwJ3z1nHls1+xKfuw06EppdqRJgV1jLTEaN67fTx/unQYO/NL+cGTy7j/3Y0UllU5HZpSqh1oUlAn8PURZo3uzeJfTubas5N4fdV+Jj/2Bf9euUcX2VOqk3NrUhCR6SKyTUR2isi9Tfz9LhHZLCIbROQzEUl0ZzyqdSK6+PPgRUNY8LMJJPcI5zfvbeLCJ5fx9a4Cp0NTSrmJ25KCiPgCTwEzgGRglogkH1dsLZBujBkOvAU86q541Okb2D2M124ewz+uTqW4vJorn/uKn76+luyicqdDU0q1MXfWFEYDO40xu4wxVcA84OLGBYwxi40xR1xPvwLi3RiPOgMiwgXDevDpXZO4c2p/Pt70HVP/soS/f76DimpdnlupzsKdSaEXsL/R8yzXsZP5CfBRU38QkVtEJENEMvLz89swRNVawQG+/GLaAD69axKTB8by2MfbOf+JpXyyOVeHsCrVCbgzKUgTx5r81BCRa4B04M9N/d0Y85wxJt0Ykx4bG9uGIarTlRDdhaevSWPuTWMI9PPh5n9lcN1Lq9mZV+p0aEqpM+DOpJAFJDR6Hg9kH19IRM4D/he4yBiju8F0MOP6xbDgzgn89sJk1u4rZPqcpTz84WZKKqqdDk0pdRrcmRRWA/1FpI+IBAAzgfmNC4jISOBZbELQVdk6KH9fH24c34fFd0/m8rR4Xli2mymPLeE/Gft1Yx+lOhi3JQVjTA1wB7AI2AK8aYzZJCIPichFrmJ/BkKB/4jIOhGZf5LTqQ4gJjSQRy4bznu3jyMhOpj/eWsDP3x6hc6KVuoMlVRU89v3vmHV7kNuv5Z0tM7B9PR0k5GR4XQYqhl1dYZ31x3gjwu2UnSkitmTz+KOc/sR6OfrdGhKdTh5JRWMfvgz/nDJUK4Ze3rTuUQk0xiT3lw5ndGs3MLHR7g0NZ5P75rIxSm9ePLznVz4t2Ws1e1AlfJomhSUW0V2CeAvV4zgpRtGUVpZw2VPr+CPC7bo3AalPJQmBdUupgyM4+NfTGTm6N48t3QXM/76Zbu0jyqlWkeTgmo3YUH+/PGHw5h70xhq6uq44tmVPPDeN7qpj1IeRJOCanfj+sWw8M6JXH9OEv/6ai/fm7OUZTsOOh2WUgpNCsohIYF+PHjREN78f2cT4OvDNf/8mnvf3kCxTnpTylGaFJSjRiVFs+DOCfy/SX15M2M/5z++lM+35jodllJeS5OCclyQvy/3zRjMO7eNIzzYjxtfzuAXb6zT3d6UcoAmBeUxRiRE8v5Px/Ozqf15f302055Ywkcbc5wOSymvoklBeZRAP1/umjaA+XeMp1t4ELPnruG2uZnkl+haiUq1B00KyiMl9wzn3dvH8T/fG8inm/M4/4klvLfugO7ZoABYvvMgVz67kmtfXMVHG3Oorq1zOqROw8/pAJQ6GX9fH26f0o/vDenG/7y1gTvnreP99dn84ZJhdI8Icjo85YBN2Yd55KOtfLnjIL0igzHGMHvuGmJCA7kiPZ5Zo3uTEN3F6TA7NE0KyuP1iwvjrVvP4aXlu3ns421Me2IJv/l+Mj9Kj0ekqb2cVGez/9AR/vLxNt5dl01kF3/u//5grhmbiL+vD0u25/Ha1/t4Zsm3PL3kW8b3i+HqMb2ZOrgb/r7aGNJamhRUh+DrI9w0oS/nDe7GPW9v4Fdvb+D9Ddn86dJhxEfpN8PO6lBZFX//fCevfrUXEZg9+SxunXQWEcH+DWXOHdSNcwd1I+dwOW+s3s8bq/dz66triA2ztYeZo7T20Bq6dLbqcOrqDHNX7eORBVsAuHfGIK4ek4iPj9YaOovyqlpeXL6bZ774lrKqGn6UlsDPp/WnR0Rws6+tqa1jyfZ8Xvt6H4u35WGAif1jmTW6N1MHx3XI2kN7Lp2tNQXV4fj4CD8em8iUgbHc99+N/Oa9Tby/IYdHLxtOUkyI0+GpM1BTW8dbmVk88el2cosrOW9wN341fSADuoW1+Bx+vj5MHdyNqYO7kV3UuPaQSVxYIFeOSuDKUQlawzwJrSmoDs0Yw38ys/j9B5uprq3j7vMHcsO4Pvi2U62horqWg6WV5JVUkldcSX5pJfnFFVTXGYb1imBk78gWfbv1dsYYPtmcy6OLtrEzr5TU3pHcO2Mwo/tEt8n5a2rrWLwtn9dX2doDwKQBrtrDoDj8PLz2oDUFpVpIRLgiPYFJA2L533c28ocPt/DBhhz+fPlw+rfi22VjxhiKK2rIL6lo+KDPK64kr6SC/BKbAOp/Hi4/ca0mEfAVoca1P3W38EBGJkQxsnckKQmRDIuPoEuA/tOrl7HnEI98tJWMvYX0jQ3hmWvS+N6Qbm06iMDP14dpyd2YltyNAw21h338v39n0i08kCvTE7hCaw+A1hRUJ2KMYf76bB6cv4myylruPK8/t0zs29CGXFNbR0FZleuD3vWB7/pwP/4Dv7LmxHHvgX4+xIUHEhcWRGxoIHHhgQ0/48KCiA0LJC4skOiQAGqNYUtOCWv3FbJufxFr9xWx79ARwHaaD+oeRkpCJCN7R5GSEEnfmBCv6xPZmVfC/y3cxiebc4kNC+QX5w3givT4dvvWXlNbx+db83h91T6+2J4PwOQBsVw1xjZNelLtoT1rCpoUVKdzsLSSB97bxIcbc+gTE0KQvy/5JRUUlFXR1P/ukV38iQsLdH2oBzX8Xv88Nsx+8IcF+p3Rt9eC0sqGBLFuv32UuvaSCA/yI8WVIEb2jiQlPpKokIDTvpYnyy2uYM6n23lj9X66BPhx66S+3Di+j6O1p6zCIw19D3kllXQPD+KKUQnMHJVAz0jnm/80KZyCJgXVUgu/yeHlFXsIDfQjttE3+YYEEB5ETGgAgX6+jsRXV2f4Nr+UtfuKWLu/kLX7itieW4Kr1Yk+MSGMTIgkpXckIxOiGNQjrEOOnKlXXFHNs0u+5Z/LdlNbZ7hmbCI/Pbc/0R6U/Gpq6/hsq533sHRHPgJMHhjHVaN7M9nB2oMmhVPQpKA6s9LKGjZkFTXUKNbuK+JgqV33KdDPp6Hzur7ZqUdEkMdP4KusqeXfK/fy98U7KTpSzcUpPbn7/IEeP3dg/yFX7SFjP/kllfSICOKKdDtyqb1rD50mKYjIdOCvgC/wgjHmkeP+PhGYAwwHZhpj3mrunJoUlDcxxnCgqLyhyWntvkK+yS6mytXnUd+JbWsTkQzsHkZ4kL9H9E/U1RneW3+AxxZt50BRORP6x3DP9EEM7RXhdGitUl1bx2db8nht1T6+dNUeBnYPZ0C3UPrHhdK/Wxj940JJ7BritlFvnWL0kYj4Ak8B04AsYLWIzDfGbG5UbB9wPXC3u+JQqiMTEeKjuhAf1YUfjOgJQFVNHVtyio92Yu8vYuGm7xq9BiKC/YkM9ieySwCRXY7+HhHsT1QX1++Njkd18ScsyL9NPtSMMSzdcZBHPtrKlpxihvQM55HLhjGhf+wZn9sJ/r4+TB/anelDu7P/0BH+k5nF+v1FZOwp5L112Q3lAvx86BsTwoBuYQzoFkq/OPuzd3QXj+q0bo47e3ZGAzuNMbsARGQecDHQkBSMMXtcf9MlDpVqoQA/H0YkRDIiIbLhWH0n9u6DZRSXV1NUXk3RkWoKj1RxqKyKXfllFB2porii5qTnFYHwIP9jkkj97xFdAogM9icqxJ/I4GMTSkTw0WSyMeswjyzcwvKdBcRHBfPXmSn8YHhPj6i5tIWE6C7cNW1Aw/PSyhp25pWyPbek4Wfm3kLmrz8xWfTvFsaA+ppFt1ASPTRZuDMp9AL2N3qeBYw5nROJyC3ALQC9e/c+88iU6mS6hgYydXC3ZsvV1NZRXFFD0ZEqisqrOexKHEVHql3P7fHCI9UUHaliT0EZRUeqKa6obnLkVr3wID/Cg/3JKiwnqos/v70wmavH9nasE7+9hAb6kZJg5580VlpZw7euJLEjr5QduSWs2VvI+42Tha8PfWNDGpqfBnSzCcPpZOHOpNDUV4PT6sAwxjwHPAe2T+FMglLKm/n5+hAdEtDqET+1daZRDeTEhHK43P5+eVo8N47vQ3iQf/Mn7cRCA/1OqM0BlLlqFvWJYkdeKWv3NZ0s+sWFMsCVMNpzhJY7k0IWkNDoeTyQfZKySikP5usjRIUEuOZO6PpSpyvkFMni2/xStueWsiOvhB25pazPKuKDDcduR+vTDiPN3Db6SET8gO3AVOAAsBq4yhizqYmyLwMftGT0kYjkA3tbGU4McLCVr+mM9D5Yeh8svQ+Wt9yHRGNMs7397h6SegF2yKkv8KIx5mEReQjIMMbMF5FRwDtAFFABfGeMGeKGODJaMhSrs9P7YOl9sPQ+WHofjuXWeeXGmAXAguOO/bbR76uxzUpKKaU8gOeNh1JKKeUYb0kKzzkdgIfQ+2DpfbD0Plh6HxrpcGsfKaWUch9vqSkopZRqAU0KSimlGnT6pCAi00Vkm4jsFJF7nY6nvYjIiyKSJyLfNDoWLSKfiMgO188oJ2NsDyKSICKLRWSLiGwSkTtdx73qXohIkIisEpH1rvvwO9fxPiLytes+vCEinrO5gZuIiK+IrBWRD1zPve4enEqnTgqNVmqdASQDs0Qk2dmo2s3LwPTjjt0LfGaM6Q985nre2dUAvzTGDAbGAre7/h/wtntRCZxrjBkBpADTRWQs8H/AE677UAj8xMEY28udwJZGz73xHpxUp04KNFqp1RhTBdSv1NrpGWOWAoeOO3wx8Irr91eAS9o1KAcYY3KMMWtcv5dgPwx64WX3wlilrqf+rocBzgXqVxLo9PdBROKB7wMvuJ4LXnYPmtPZk0JTK7X2cigWT9DNGJMD9sMSiHM4nnYlIknASOBrvPBeuJpN1gF5wCfAt0CRMaZ+PW1v+PcxB/gVUL9cf1e87x6cUmdPCm22Uqvq2EQkFHgb+LkxptjpeJxgjKk1xqRgVxEYDQxuqlj7RtV+RORCIM8Yk9n4cBNFO+09aAm3LnPhAXSl1mPlikgPY0yOiPTAfmPs9ETEH5sQ5hpj/us67JX3AsAYUyQiX2D7WCJFxM/1Tbmz//sYB1zkWpMtCAjH1hy86R40q7PXFFYD/V2jCwKAmcB8h2Ny0nzgOtfv1wHvORhLu3C1Gf8T2GKMebzRn7zqXohIrIhEun4PBs7D9q8sBi53FevU98EYc58xJt4Yk4T9LPjcGHM1XnQPWqLTz2huaqVWh0NqFyLyOjAZuyxwLvAA8C7wJtAbuz/2j4wxx3dGdyoiMh74EtjI0XbkX2P7FbzmXojIcGwnqi/2y+CbxpiHRKQvdgBGNLAWuMYYU+lcpO1DRCYDdxtjLvTWe3AynT4pKKWUarnO3nyklFKqFTQpKKWUaqBJQSmlVANNCkoppRpoUlBKKdVAk4JSbiYik+tX5FTK02lSUEop1UCTglIuInKNa8+BdSLyrGsBuVIR+YuIrBGRz0Qk1lU2RUS+EpENIvJO/X4MItJPRD517VuwRkTOcp0+VETeEpGtIjLXNdMaEXlERDa7zvOYQ29dqQaaFJQCRGQwcCUwzrVoXC1wNRACrDHGpAJLsDPDAf4F3GOMGY6dLV1/fC7wlGvfgnOAHNfxkcDPsft69AXGiUg08ENgiOs8f3Dvu1SqeZoUlLKmAmnAatfy0lOxH951wBuuMq8C40UkAog0xixxHX8FmCgiYUAvY8w7AMaYCmPMEVeZVcaYLGNMHbAOSAKKgQrgBRG5FKgvq5RjNCkoZQnwijEmxfUYaIx5sIlyp1oXpqllmOs1XkunFqhflXM0dgXXS4CFrYxZqTanSUEp6zPgchGJg4Y9nBOx/0bqV9C8ClhmjDkMFIrIBNfxHwNLXPs0ZInIJa5zBIpIl5Nd0LXHQ4QxZgG2aSnFHW9Mqdbo7PspKNUixpjNInI/8LGI+ADVwO1AGTBERDKBw9h+B7BLLD/j+tDfBdzgOv5j4FkRech1jh+d4rJhwHsiEoStZfyijd+WUq2mq6QqdQoiUmqMCXU6DqXaizYfKaWUaile+cYAAAAtSURBVKA1BaWUUg20pqCUUqqBJgWllFINNCkopZRqoElBKaVUA00KSimlGvx/OYh51TRI+YMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_200x200x200.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1529876519143_83\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.056320554312119825\n",
      "RMSE: 0.23731951945029686\n",
      "LogLoss: 0.18349903925371555\n",
      "Mean Per-Class Error: 0.07254156522630684\n",
      "AUC: 0.9813151981576332\n",
      "Gini: 0.9626303963152665\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3685781828585548: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>4037.0</td>\n",
       "<td>406.0</td>\n",
       "<td>0.0914</td>\n",
       "<td> (406.0/4443.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>321.0</td>\n",
       "<td>5290.0</td>\n",
       "<td>0.0572</td>\n",
       "<td> (321.0/5611.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4358.0</td>\n",
       "<td>5696.0</td>\n",
       "<td>0.0723</td>\n",
       "<td> (727.0/10054.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  ---------------\n",
       "NO     4037  406    0.0914   (406.0/4443.0)\n",
       "YES    321   5290   0.0572   (321.0/5611.0)\n",
       "Total  4358  5696   0.0723   (727.0/10054.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3685782</td>\n",
       "<td>0.9357035</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1611983</td>\n",
       "<td>0.9534103</td>\n",
       "<td>313.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5843758</td>\n",
       "<td>0.9473582</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4003168</td>\n",
       "<td>0.9282872</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999880</td>\n",
       "<td>0.9995712</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0006222</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999880</td>\n",
       "<td>0.9997749</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4003168</td>\n",
       "<td>0.8546595</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4250018</td>\n",
       "<td>0.9260381</td>\n",
       "<td>219.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4003168</td>\n",
       "<td>0.9274584</td>\n",
       "<td>227.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.368578     0.935704  238\n",
       "max f2                       0.161198     0.95341   313\n",
       "max f0point5                 0.584376     0.947358  166\n",
       "max accuracy                 0.400317     0.928287  227\n",
       "max precision                0.999988     0.999571  0\n",
       "max recall                   0.000622199  1         398\n",
       "max specificity              0.999988     0.999775  0\n",
       "max absolute_mcc             0.400317     0.85466   227\n",
       "max min_per_class_accuracy   0.425002     0.926038  219\n",
       "max mean_per_class_accuracy  0.400317     0.927458  227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 55.81 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0192958</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0345749</td>\n",
       "<td>0.0345749</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200915</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0014258</td>\n",
       "<td>0.0360007</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300378</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0178221</td>\n",
       "<td>0.0538228</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400835</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0180004</td>\n",
       "<td>0.0718232</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500298</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0178221</td>\n",
       "<td>0.0896453</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000597</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0896453</td>\n",
       "<td>0.1792907</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499901</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0894671</td>\n",
       "<td>0.2687578</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000199</td>\n",
       "<td>0.9999783</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.7918375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0896453</td>\n",
       "<td>0.3584031</td>\n",
       "<td>79.1837462</td>\n",
       "<td>79.1837462</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999801</td>\n",
       "<td>0.9933565</td>\n",
       "<td>1.7829228</td>\n",
       "<td>1.7888669</td>\n",
       "<td>0.9950249</td>\n",
       "<td>0.9983422</td>\n",
       "<td>0.1782214</td>\n",
       "<td>0.5366245</td>\n",
       "<td>78.2922848</td>\n",
       "<td>78.8866909</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000398</td>\n",
       "<td>0.8755864</td>\n",
       "<td>1.7651202</td>\n",
       "<td>1.7829273</td>\n",
       "<td>0.9850895</td>\n",
       "<td>0.9950273</td>\n",
       "<td>0.1766174</td>\n",
       "<td>0.7132418</td>\n",
       "<td>76.5120204</td>\n",
       "<td>78.2927281</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5927980</td>\n",
       "<td>1.5511429</td>\n",
       "<td>1.7365888</td>\n",
       "<td>0.8656716</td>\n",
       "<td>0.9691665</td>\n",
       "<td>0.1550526</td>\n",
       "<td>0.8682944</td>\n",
       "<td>55.1142878</td>\n",
       "<td>73.6588843</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999602</td>\n",
       "<td>0.2667497</td>\n",
       "<td>0.9609954</td>\n",
       "<td>1.6073661</td>\n",
       "<td>0.5363184</td>\n",
       "<td>0.8970491</td>\n",
       "<td>0.0960613</td>\n",
       "<td>0.9643557</td>\n",
       "<td>-3.9004585</td>\n",
       "<td>60.7366132</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000199</td>\n",
       "<td>0.0683394</td>\n",
       "<td>0.2921087</td>\n",
       "<td>1.4193654</td>\n",
       "<td>0.1630219</td>\n",
       "<td>0.7921284</td>\n",
       "<td>0.0292283</td>\n",
       "<td>0.9935840</td>\n",
       "<td>-70.7891308</td>\n",
       "<td>41.9365424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999801</td>\n",
       "<td>0.0071115</td>\n",
       "<td>0.0570535</td>\n",
       "<td>1.2491400</td>\n",
       "<td>0.0318408</td>\n",
       "<td>0.6971279</td>\n",
       "<td>0.0057031</td>\n",
       "<td>0.9992871</td>\n",
       "<td>-94.2946469</td>\n",
       "<td>24.9139954</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999403</td>\n",
       "<td>0.0006861</td>\n",
       "<td>0.0071317</td>\n",
       "<td>1.1111848</td>\n",
       "<td>0.0039801</td>\n",
       "<td>0.6201370</td>\n",
       "<td>0.0007129</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.2868309</td>\n",
       "<td>11.1184792</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000026</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5580863</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0192958                   1                  1.79184     1.79184            1                1                           0.0345749       0.0345749                  79.1837   79.1837\n",
       "    2        0.0200915                   1                  1.79184     1.79184            1                1                           0.00142577      0.0360007                  79.1837   79.1837\n",
       "    3        0.0300378                   1                  1.79184     1.79184            1                1                           0.0178221       0.0538228                  79.1837   79.1837\n",
       "    4        0.0400835                   1                  1.79184     1.79184            1                1                           0.0180004       0.0718232                  79.1837   79.1837\n",
       "    5        0.0500298                   1                  1.79184     1.79184            1                1                           0.0178221       0.0896453                  79.1837   79.1837\n",
       "    6        0.10006                     1                  1.79184     1.79184            1                1                           0.0896453       0.179291                   79.1837   79.1837\n",
       "    7        0.14999                     1                  1.79184     1.79184            1                1                           0.0894671       0.268758                   79.1837   79.1837\n",
       "    8        0.20002                     0.999978           1.79184     1.79184            1                1                           0.0896453       0.358403                   79.1837   79.1837\n",
       "    9        0.29998                     0.993357           1.78292     1.78887            0.995025         0.998342                    0.178221        0.536624                   78.2923   78.8867\n",
       "    10       0.40004                     0.875586           1.76512     1.78293            0.985089         0.995027                    0.176617        0.713242                   76.512    78.2927\n",
       "    11       0.5                         0.592798           1.55114     1.73659            0.865672         0.969167                    0.155053        0.868294                   55.1143   73.6589\n",
       "    12       0.59996                     0.26675            0.960995    1.60737            0.536318         0.897049                    0.0960613       0.964356                   -3.90046  60.7366\n",
       "    13       0.70002                     0.0683394          0.292109    1.41937            0.163022         0.792128                    0.0292283       0.993584                   -70.7891  41.9365\n",
       "    14       0.79998                     0.00711149         0.0570535   1.24914            0.0318408        0.697128                    0.00570308      0.999287                   -94.2946  24.914\n",
       "    15       0.89994                     0.000686109        0.00713169  1.11118            0.0039801        0.620137                    0.000712885     1                          -99.2868  11.1185\n",
       "    16       1                           2.56458e-06        0           1                  0                0.558086                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.09806416166794199\n",
      "RMSE: 0.31315197854706583\n",
      "LogLoss: 0.3327197540773978\n",
      "Mean Per-Class Error: 0.12720338257668673\n",
      "AUC: 0.9439774559765837\n",
      "Gini: 0.8879549119531673\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.39308791117014685: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1663.0</td>\n",
       "<td>270.0</td>\n",
       "<td>0.1397</td>\n",
       "<td> (270.0/1933.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>286.0</td>\n",
       "<td>2053.0</td>\n",
       "<td>0.1223</td>\n",
       "<td> (286.0/2339.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1949.0</td>\n",
       "<td>2323.0</td>\n",
       "<td>0.1301</td>\n",
       "<td> (556.0/4272.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1663  270    0.1397   (270.0/1933.0)\n",
       "YES    286   2053   0.1223   (286.0/2339.0)\n",
       "Total  1949  2323   0.1301   (556.0/4272.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3930879</td>\n",
       "<td>0.8807379</td>\n",
       "<td>225.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0249481</td>\n",
       "<td>0.9140426</td>\n",
       "<td>372.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6219470</td>\n",
       "<td>0.9035676</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4761788</td>\n",
       "<td>0.8707865</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999850</td>\n",
       "<td>0.9989950</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0001275</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999850</td>\n",
       "<td>0.9994827</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4761788</td>\n",
       "<td>0.7425213</td>\n",
       "<td>195.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4121361</td>\n",
       "<td>0.8675634</td>\n",
       "<td>216.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4761788</td>\n",
       "<td>0.8727966</td>\n",
       "<td>195.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.393088     0.880738  225\n",
       "max f2                       0.0249481    0.914043  372\n",
       "max f0point5                 0.621947     0.903568  150\n",
       "max accuracy                 0.476179     0.870787  195\n",
       "max precision                0.999985     0.998995  0\n",
       "max recall                   0.000127528  1         399\n",
       "max specificity              0.999985     0.999483  0\n",
       "max absolute_mcc             0.476179     0.742521  195\n",
       "max min_per_class_accuracy   0.412136     0.867563  216\n",
       "max mean_per_class_accuracy  0.476179     0.872797  195"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0205993</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0376229</td>\n",
       "<td>0.0376229</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0301966</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0175289</td>\n",
       "<td>0.0551518</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0400281</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0179564</td>\n",
       "<td>0.0731082</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0500936</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0183839</td>\n",
       "<td>0.0914921</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1001873</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.1829842</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1500468</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.2740487</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.2001404</td>\n",
       "<td>0.9999773</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.3655408</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3000936</td>\n",
       "<td>0.9849122</td>\n",
       "<td>1.7665389</td>\n",
       "<td>1.8064762</td>\n",
       "<td>0.9672131</td>\n",
       "<td>0.9890796</td>\n",
       "<td>0.1765712</td>\n",
       "<td>0.5421120</td>\n",
       "<td>76.6538874</td>\n",
       "<td>80.6476227</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.4000468</td>\n",
       "<td>0.8113223</td>\n",
       "<td>1.5954455</td>\n",
       "<td>1.7537494</td>\n",
       "<td>0.8735363</td>\n",
       "<td>0.9602106</td>\n",
       "<td>0.1594699</td>\n",
       "<td>0.7015819</td>\n",
       "<td>59.5445521</td>\n",
       "<td>75.3749421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5165958</td>\n",
       "<td>1.3473602</td>\n",
       "<td>1.6725096</td>\n",
       "<td>0.7377049</td>\n",
       "<td>0.9157303</td>\n",
       "<td>0.1346729</td>\n",
       "<td>0.8362548</td>\n",
       "<td>34.7360158</td>\n",
       "<td>67.2509619</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5999532</td>\n",
       "<td>0.2486454</td>\n",
       "<td>0.7784748</td>\n",
       "<td>1.5235619</td>\n",
       "<td>0.4262295</td>\n",
       "<td>0.8341787</td>\n",
       "<td>0.0778110</td>\n",
       "<td>0.9140658</td>\n",
       "<td>-22.1525242</td>\n",
       "<td>52.3561947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6999064</td>\n",
       "<td>0.0739412</td>\n",
       "<td>0.4619521</td>\n",
       "<td>1.3719541</td>\n",
       "<td>0.2529274</td>\n",
       "<td>0.7511706</td>\n",
       "<td>0.0461736</td>\n",
       "<td>0.9602394</td>\n",
       "<td>-53.8047946</td>\n",
       "<td>37.1954112</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7998596</td>\n",
       "<td>0.0084569</td>\n",
       "<td>0.3036907</td>\n",
       "<td>1.2384603</td>\n",
       "<td>0.1662763</td>\n",
       "<td>0.6780802</td>\n",
       "<td>0.0303549</td>\n",
       "<td>0.9905943</td>\n",
       "<td>-69.6309298</td>\n",
       "<td>23.8460265</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8998127</td>\n",
       "<td>0.0007437</td>\n",
       "<td>0.0812693</td>\n",
       "<td>1.1099169</td>\n",
       "<td>0.0444965</td>\n",
       "<td>0.6077003</td>\n",
       "<td>0.0081231</td>\n",
       "<td>0.9987174</td>\n",
       "<td>-91.8730657</td>\n",
       "<td>10.9916945</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000038</td>\n",
       "<td>0.0128020</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0070093</td>\n",
       "<td>0.5475187</td>\n",
       "<td>0.0012826</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.7197980</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0205993                   1                  1.82642    1.82642            1                1                           0.0376229       0.0376229                  82.6422   82.6422\n",
       "    2        0.0301966                   1                  1.82642    1.82642            1                1                           0.0175289       0.0551518                  82.6422   82.6422\n",
       "    3        0.0400281                   1                  1.82642    1.82642            1                1                           0.0179564       0.0731082                  82.6422   82.6422\n",
       "    4        0.0500936                   1                  1.82642    1.82642            1                1                           0.0183839       0.0914921                  82.6422   82.6422\n",
       "    5        0.100187                    1                  1.82642    1.82642            1                1                           0.0914921       0.182984                   82.6422   82.6422\n",
       "    6        0.150047                    1                  1.82642    1.82642            1                1                           0.0910646       0.274049                   82.6422   82.6422\n",
       "    7        0.20014                     0.999977           1.82642    1.82642            1                1                           0.0914921       0.365541                   82.6422   82.6422\n",
       "    8        0.300094                    0.984912           1.76654    1.80648            0.967213         0.98908                     0.176571        0.542112                   76.6539   80.6476\n",
       "    9        0.400047                    0.811322           1.59545    1.75375            0.873536         0.960211                    0.15947         0.701582                   59.5446   75.3749\n",
       "    10       0.5                         0.516596           1.34736    1.67251            0.737705         0.91573                     0.134673        0.836255                   34.736    67.251\n",
       "    11       0.599953                    0.248645           0.778475   1.52356            0.42623          0.834179                    0.077811        0.914066                   -22.1525  52.3562\n",
       "    12       0.699906                    0.0739412          0.461952   1.37195            0.252927         0.751171                    0.0461736       0.960239                   -53.8048  37.1954\n",
       "    13       0.79986                     0.00845692         0.303691   1.23846            0.166276         0.67808                     0.0303549       0.990594                   -69.6309  23.846\n",
       "    14       0.899813                    0.000743739        0.0812693  1.10992            0.0444965        0.6077                      0.00812313      0.998717                   -91.8731  10.9917\n",
       "    15       1                           3.77182e-06        0.012802   1                  0.00700935       0.547519                    0.0012826       1                          -98.7198  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_r2</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:40:09</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:40:13</td>\n",
       "<td> 9.774 sec</td>\n",
       "<td>2450 obs/sec</td>\n",
       "<td>0.3005815</td>\n",
       "<td>1</td>\n",
       "<td>10597.0</td>\n",
       "<td>0.5099460</td>\n",
       "<td>0.7692335</td>\n",
       "<td>-0.0544100</td>\n",
       "<td>0.6871979</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.4057092</td>\n",
       "<td>0.5126886</td>\n",
       "<td>0.7873675</td>\n",
       "<td>-0.0609812</td>\n",
       "<td>0.6738278</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.4344569</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:41:09</td>\n",
       "<td> 1 min  5.147 sec</td>\n",
       "<td>3294 obs/sec</td>\n",
       "<td>5.1309885</td>\n",
       "<td>17</td>\n",
       "<td>180893.0</td>\n",
       "<td>0.3257559</td>\n",
       "<td>0.3262880</td>\n",
       "<td>0.5697254</td>\n",
       "<td>0.9368758</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.1565546</td>\n",
       "<td>0.3483240</td>\n",
       "<td>0.3717816</td>\n",
       "<td>0.5102581</td>\n",
       "<td>0.9151534</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1741573</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:41:59</td>\n",
       "<td> 1 min 54.825 sec</td>\n",
       "<td>3415 obs/sec</td>\n",
       "<td>9.6524181</td>\n",
       "<td>32</td>\n",
       "<td>340296.0</td>\n",
       "<td>0.2813600</td>\n",
       "<td>0.2429084</td>\n",
       "<td>0.6790142</td>\n",
       "<td>0.9738882</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0899145</td>\n",
       "<td>0.3319746</td>\n",
       "<td>0.3459581</td>\n",
       "<td>0.5551535</td>\n",
       "<td>0.9402012</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1439607</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:42:51</td>\n",
       "<td> 2 min 47.091 sec</td>\n",
       "<td>3472 obs/sec</td>\n",
       "<td>14.4522479</td>\n",
       "<td>48</td>\n",
       "<td>509514.0</td>\n",
       "<td>0.2373195</td>\n",
       "<td>0.1834990</td>\n",
       "<td>0.7716358</td>\n",
       "<td>0.9813152</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0723095</td>\n",
       "<td>0.3131520</td>\n",
       "<td>0.3327198</td>\n",
       "<td>0.6041682</td>\n",
       "<td>0.9439775</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1301498</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:43:43</td>\n",
       "<td> 3 min 38.814 sec</td>\n",
       "<td>3510 obs/sec</td>\n",
       "<td>19.2726989</td>\n",
       "<td>64</td>\n",
       "<td>679459.0</td>\n",
       "<td>0.1875245</td>\n",
       "<td>0.1167430</td>\n",
       "<td>0.8574139</td>\n",
       "<td>0.9920995</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0466481</td>\n",
       "<td>0.3004637</td>\n",
       "<td>0.3521733</td>\n",
       "<td>0.6355948</td>\n",
       "<td>0.9494753</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1161049</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:44:32</td>\n",
       "<td> 4 min 28.000 sec</td>\n",
       "<td>3526 obs/sec</td>\n",
       "<td>23.7920862</td>\n",
       "<td>79</td>\n",
       "<td>838790.0</td>\n",
       "<td>0.1974178</td>\n",
       "<td>0.1259172</td>\n",
       "<td>0.8419722</td>\n",
       "<td>0.9902296</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0529143</td>\n",
       "<td>0.3230248</td>\n",
       "<td>0.4833588</td>\n",
       "<td>0.5788158</td>\n",
       "<td>0.9367837</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1320225</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:45:22</td>\n",
       "<td> 5 min 18.318 sec</td>\n",
       "<td>3525 obs/sec</td>\n",
       "<td>28.3154163</td>\n",
       "<td>94</td>\n",
       "<td>998260.0</td>\n",
       "<td>0.1805019</td>\n",
       "<td>0.1051820</td>\n",
       "<td>0.8678934</td>\n",
       "<td>0.9941952</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0398846</td>\n",
       "<td>0.3113268</td>\n",
       "<td>0.4840689</td>\n",
       "<td>0.6087689</td>\n",
       "<td>0.9421701</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1170412</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:46:15</td>\n",
       "<td> 6 min 10.885 sec</td>\n",
       "<td>3533 obs/sec</td>\n",
       "<td>33.1520919</td>\n",
       "<td>110</td>\n",
       "<td>1168777.0</td>\n",
       "<td>0.1724872</td>\n",
       "<td>0.0979282</td>\n",
       "<td>0.8793645</td>\n",
       "<td>0.9955374</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0343147</td>\n",
       "<td>0.3227887</td>\n",
       "<td>0.5822544</td>\n",
       "<td>0.5794311</td>\n",
       "<td>0.9396089</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1189139</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:47:04</td>\n",
       "<td> 7 min  0.287 sec</td>\n",
       "<td>3512 obs/sec</td>\n",
       "<td>37.3786130</td>\n",
       "<td>124</td>\n",
       "<td>1317783.0</td>\n",
       "<td>0.2063043</td>\n",
       "<td>0.1461835</td>\n",
       "<td>0.8274250</td>\n",
       "<td>0.9917342</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0429680</td>\n",
       "<td>0.3330547</td>\n",
       "<td>0.6497426</td>\n",
       "<td>0.5522543</td>\n",
       "<td>0.9382163</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1228933</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:47:55</td>\n",
       "<td> 7 min 51.332 sec</td>\n",
       "<td>3508 obs/sec</td>\n",
       "<td>41.9130052</td>\n",
       "<td>139</td>\n",
       "<td>1477643.0</td>\n",
       "<td>0.1734407</td>\n",
       "<td>0.1078121</td>\n",
       "<td>0.8780272</td>\n",
       "<td>0.9941378</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0353093</td>\n",
       "<td>0.3129639</td>\n",
       "<td>0.5274694</td>\n",
       "<td>0.6046435</td>\n",
       "<td>0.9409397</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1179775</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:48:48</td>\n",
       "<td> 8 min 43.785 sec</td>\n",
       "<td>3493 obs/sec</td>\n",
       "<td>46.4377251</td>\n",
       "<td>154</td>\n",
       "<td>1637162.0</td>\n",
       "<td>0.1677276</td>\n",
       "<td>0.0919385</td>\n",
       "<td>0.8859304</td>\n",
       "<td>0.9962381</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0319276</td>\n",
       "<td>0.3191121</td>\n",
       "<td>0.5869824</td>\n",
       "<td>0.5889573</td>\n",
       "<td>0.9388468</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1175094</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:48:53</td>\n",
       "<td> 8 min 48.764 sec</td>\n",
       "<td>3492 obs/sec</td>\n",
       "<td>46.4377251</td>\n",
       "<td>154</td>\n",
       "<td>1637162.0</td>\n",
       "<td>0.2373195</td>\n",
       "<td>0.1834990</td>\n",
       "<td>0.7716358</td>\n",
       "<td>0.9813152</td>\n",
       "<td>1.7918375</td>\n",
       "<td>0.0723095</td>\n",
       "<td>0.3131520</td>\n",
       "<td>0.3327198</td>\n",
       "<td>0.6041682</td>\n",
       "<td>0.9439775</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1301498</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration          training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -----------------  ---------------------------------\n",
       "    2018-06-25 03:40:09  0.000 sec                           0         0             0            nan              nan                 nan            nan             nan              nan                              nan                nan                   nan              nan               nan                nan\n",
       "    2018-06-25 03:40:13  9.774 sec         2450 obs/sec      0.300581  1             10597        0.509946         0.769234            -0.05441       0.687198        1.79184          0.405709                         0.512689           0.787367              -0.0609812       0.673828          1.82642            0.434457\n",
       "    2018-06-25 03:41:09  1 min  5.147 sec  3294 obs/sec      5.13099   17            180893       0.325756         0.326288            0.569725       0.936876        1.79184          0.156555                         0.348324           0.371782              0.510258         0.915153          1.82642            0.174157\n",
       "    2018-06-25 03:41:59  1 min 54.825 sec  3415 obs/sec      9.65242   32            340296       0.28136          0.242908            0.679014       0.973888        1.79184          0.0899145                        0.331975           0.345958              0.555154         0.940201          1.82642            0.143961\n",
       "    2018-06-25 03:42:51  2 min 47.091 sec  3472 obs/sec      14.4522   48            509514       0.23732          0.183499            0.771636       0.981315        1.79184          0.0723095                        0.313152           0.33272               0.604168         0.943977          1.82642            0.13015\n",
       "    2018-06-25 03:43:43  3 min 38.814 sec  3510 obs/sec      19.2727   64            679459       0.187524         0.116743            0.857414       0.9921          1.79184          0.0466481                        0.300464           0.352173              0.635595         0.949475          1.82642            0.116105\n",
       "    2018-06-25 03:44:32  4 min 28.000 sec  3526 obs/sec      23.7921   79            838790       0.197418         0.125917            0.841972       0.99023         1.79184          0.0529143                        0.323025           0.483359              0.578816         0.936784          1.82642            0.132022\n",
       "    2018-06-25 03:45:22  5 min 18.318 sec  3525 obs/sec      28.3154   94            998260       0.180502         0.105182            0.867893       0.994195        1.79184          0.0398846                        0.311327           0.484069              0.608769         0.94217           1.82642            0.117041\n",
       "    2018-06-25 03:46:15  6 min 10.885 sec  3533 obs/sec      33.1521   110           1.16878e+06  0.172487         0.0979282           0.879365       0.995537        1.79184          0.0343147                        0.322789           0.582254              0.579431         0.939609          1.82642            0.118914\n",
       "    2018-06-25 03:47:04  7 min  0.287 sec  3512 obs/sec      37.3786   124           1.31778e+06  0.206304         0.146184            0.827425       0.991734        1.79184          0.042968                         0.333055           0.649743              0.552254         0.938216          1.82642            0.122893\n",
       "    2018-06-25 03:47:55  7 min 51.332 sec  3508 obs/sec      41.913    139           1.47764e+06  0.173441         0.107812            0.878027       0.994138        1.79184          0.0353093                        0.312964           0.527469              0.604644         0.94094           1.82642            0.117978\n",
       "    2018-06-25 03:48:48  8 min 43.785 sec  3493 obs/sec      46.4377   154           1.63716e+06  0.167728         0.0919385           0.88593        0.996238        1.79184          0.0319276                        0.319112           0.586982              0.588957         0.938847          1.82642            0.117509\n",
       "    2018-06-25 03:48:53  8 min 48.764 sec  3492 obs/sec      46.4377   154           1.63716e+06  0.23732          0.183499            0.771636       0.981315        1.79184          0.0723095                        0.313152           0.33272               0.604168         0.943977          1.82642            0.13015"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ArrTime</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0042562</td></tr>\n",
       "<tr><td>CRSArrTime</td>\n",
       "<td>0.9063724</td>\n",
       "<td>0.9063724</td>\n",
       "<td>0.0038577</td></tr>\n",
       "<tr><td>CRSDepTime</td>\n",
       "<td>0.6789995</td>\n",
       "<td>0.6789995</td>\n",
       "<td>0.0028899</td></tr>\n",
       "<tr><td>DepTime</td>\n",
       "<td>0.6144415</td>\n",
       "<td>0.6144415</td>\n",
       "<td>0.0026152</td></tr>\n",
       "<tr><td>TailNum.NA</td>\n",
       "<td>0.5461983</td>\n",
       "<td>0.5461983</td>\n",
       "<td>0.0023247</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>TailNum.N664UA</td>\n",
       "<td>0.0451967</td>\n",
       "<td>0.0451967</td>\n",
       "<td>0.0001924</td></tr>\n",
       "<tr><td>TailNum.N413AA</td>\n",
       "<td>0.0443478</td>\n",
       "<td>0.0443478</td>\n",
       "<td>0.0001888</td></tr>\n",
       "<tr><td>Dest.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>Origin.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>UniqueCarrier.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance     percentage\n",
       "-------------------------  ---------------------  --------------------  ----------------------\n",
       "ArrTime                    1.0                    1.0                   0.004256153309570686\n",
       "CRSArrTime                 0.9063723683357239     0.9063723683357239    0.0038576597551955127\n",
       "CRSDepTime                 0.6789994835853577     0.6789994835853577    0.002889925899258607\n",
       "DepTime                    0.614441454410553      0.614441454410553     0.0026151570297269014\n",
       "TailNum.NA                 0.546198308467865      0.546198308467865     0.0023247037382674142\n",
       "---                        ---                    ---                   ---\n",
       "TailNum.N664UA             0.045196712017059326   0.045196712017059326  0.00019236413543312027\n",
       "TailNum.N413AA             0.0443478487432003     0.0443478487432003    0.00018875124320071217\n",
       "Dest.missing(NA)           0.0                    0.0                   0.0\n",
       "Origin.missing(NA)         0.0                    0.0                   0.0\n",
       "UniqueCarrier.missing(NA)  0.0                    0.0                   0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_200x200x200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sticking with two layers and doubling the neurons in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 4.02 s, sys: 395 ms, total: 4.42 s\n",
      "Wall time: 19min 26s\n"
     ]
    }
   ],
   "source": [
    "m_400x400= H2ODeepLearningEstimator(epochs=200,\n",
    "                                       #Same early stopping as it is default\n",
    "                                       hidden=[400,400])\n",
    "%time m_400x400.train(xAll,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building Time: 16min 26seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.09266793918939957\n",
      "RMSE: 0.3044140916406459\n",
      "LogLoss: 0.30828911627666566\n",
      "Mean Per-Class Error: 0.12154492049334109\n",
      "AUC: 0.9539155619803361\n",
      "Gini: 0.9078311239606722\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5938319943538659: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1619.0</td>\n",
       "<td>331.0</td>\n",
       "<td>0.1697</td>\n",
       "<td> (331.0/1950.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>200.0</td>\n",
       "<td>2301.0</td>\n",
       "<td>0.08</td>\n",
       "<td> (200.0/2501.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1819.0</td>\n",
       "<td>2632.0</td>\n",
       "<td>0.1193</td>\n",
       "<td> (531.0/4451.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1619  331    0.1697   (331.0/1950.0)\n",
       "YES    200   2301   0.08     (200.0/2501.0)\n",
       "Total  1819  2632   0.1193   (531.0/4451.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5938320</td>\n",
       "<td>0.8965517</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2685210</td>\n",
       "<td>0.9287678</td>\n",
       "<td>281.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9160883</td>\n",
       "<td>0.9105722</td>\n",
       "<td>57.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5990044</td>\n",
       "<td>0.8807010</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999850</td>\n",
       "<td>0.9981802</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0014139</td>\n",
       "<td>1.0</td>\n",
       "<td>395.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999850</td>\n",
       "<td>0.9989744</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5938320</td>\n",
       "<td>0.7572566</td>\n",
       "<td>178.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7204757</td>\n",
       "<td>0.8784486</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7204757</td>\n",
       "<td>0.8784551</td>\n",
       "<td>135.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.593832     0.896552  178\n",
       "max f2                       0.268521     0.928768  281\n",
       "max f0point5                 0.916088     0.910572  57\n",
       "max accuracy                 0.599004     0.880701  177\n",
       "max precision                0.999985     0.99818   0\n",
       "max recall                   0.00141391   1         395\n",
       "max specificity              0.999985     0.998974  0\n",
       "max absolute_mcc             0.593832     0.757257  178\n",
       "max min_per_class_accuracy   0.720476     0.878449  135\n",
       "max mean_per_class_accuracy  0.720476     0.878455  135"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 56.19 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0352730</td>\n",
       "<td>1.0</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0627749</td>\n",
       "<td>0.0627749</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0402157</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0087965</td>\n",
       "<td>0.0715714</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0501011</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0175930</td>\n",
       "<td>0.0891643</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.1002022</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0891643</td>\n",
       "<td>0.1783287</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1500786</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.7796881</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.2670932</td>\n",
       "<td>77.9688125</td>\n",
       "<td>77.9688125</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.2001797</td>\n",
       "<td>0.9999859</td>\n",
       "<td>1.7717075</td>\n",
       "<td>1.7776907</td>\n",
       "<td>0.9955157</td>\n",
       "<td>0.9988777</td>\n",
       "<td>0.0887645</td>\n",
       "<td>0.3558577</td>\n",
       "<td>77.1707461</td>\n",
       "<td>77.7690719</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.3001573</td>\n",
       "<td>0.9978639</td>\n",
       "<td>1.7556923</td>\n",
       "<td>1.7703634</td>\n",
       "<td>0.9865169</td>\n",
       "<td>0.9947605</td>\n",
       "<td>0.1755298</td>\n",
       "<td>0.5313874</td>\n",
       "<td>75.5692330</td>\n",
       "<td>77.0363412</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.4001348</td>\n",
       "<td>0.9649751</td>\n",
       "<td>1.6077183</td>\n",
       "<td>1.7297250</td>\n",
       "<td>0.9033708</td>\n",
       "<td>0.9719259</td>\n",
       "<td>0.1607357</td>\n",
       "<td>0.6921232</td>\n",
       "<td>60.7718261</td>\n",
       "<td>72.9724954</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.5001123</td>\n",
       "<td>0.8224268</td>\n",
       "<td>1.3597617</td>\n",
       "<td>1.6557655</td>\n",
       "<td>0.7640449</td>\n",
       "<td>0.9303684</td>\n",
       "<td>0.1359456</td>\n",
       "<td>0.8280688</td>\n",
       "<td>35.9761713</td>\n",
       "<td>65.5765546</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.6000899</td>\n",
       "<td>0.5638919</td>\n",
       "<td>0.9678304</td>\n",
       "<td>1.5411526</td>\n",
       "<td>0.5438202</td>\n",
       "<td>0.8659678</td>\n",
       "<td>0.0967613</td>\n",
       "<td>0.9248301</td>\n",
       "<td>-3.2169604</td>\n",
       "<td>54.1152614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.7000674</td>\n",
       "<td>0.2539187</td>\n",
       "<td>0.4879145</td>\n",
       "<td>1.3907383</td>\n",
       "<td>0.2741573</td>\n",
       "<td>0.7814506</td>\n",
       "<td>0.0487805</td>\n",
       "<td>0.9736106</td>\n",
       "<td>-51.2085503</td>\n",
       "<td>39.0738313</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.8000449</td>\n",
       "<td>0.0400644</td>\n",
       "<td>0.1999650</td>\n",
       "<td>1.2419334</td>\n",
       "<td>0.1123596</td>\n",
       "<td>0.6978377</td>\n",
       "<td>0.0199920</td>\n",
       "<td>0.9936026</td>\n",
       "<td>-80.0035042</td>\n",
       "<td>24.1933443</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.9000225</td>\n",
       "<td>0.0021345</td>\n",
       "<td>0.0559902</td>\n",
       "<td>1.1101949</td>\n",
       "<td>0.0314607</td>\n",
       "<td>0.6238143</td>\n",
       "<td>0.0055978</td>\n",
       "<td>0.9992003</td>\n",
       "<td>-94.4009812</td>\n",
       "<td>11.0194864</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0079986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0044944</td>\n",
       "<td>0.5618962</td>\n",
       "<td>0.0007997</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.2001402</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.035273                    1                  1.77969    1.77969            1                1                           0.0627749       0.0627749                  77.9688   77.9688\n",
       "    2        0.0402157                   1                  1.77969    1.77969            1                1                           0.00879648      0.0715714                  77.9688   77.9688\n",
       "    3        0.0501011                   1                  1.77969    1.77969            1                1                           0.017593        0.0891643                  77.9688   77.9688\n",
       "    4        0.100202                    1                  1.77969    1.77969            1                1                           0.0891643       0.178329                   77.9688   77.9688\n",
       "    5        0.150079                    1                  1.77969    1.77969            1                1                           0.0887645       0.267093                   77.9688   77.9688\n",
       "    6        0.20018                     0.999986           1.77171    1.77769            0.995516         0.998878                    0.0887645       0.355858                   77.1707   77.7691\n",
       "    7        0.300157                    0.997864           1.75569    1.77036            0.986517         0.99476                     0.17553         0.531387                   75.5692   77.0363\n",
       "    8        0.400135                    0.964975           1.60772    1.72972            0.903371         0.971926                    0.160736        0.692123                   60.7718   72.9725\n",
       "    9        0.500112                    0.822427           1.35976    1.65577            0.764045         0.930368                    0.135946        0.828069                   35.9762   65.5766\n",
       "    10       0.60009                     0.563892           0.96783    1.54115            0.54382          0.865968                    0.0967613       0.92483                    -3.21696  54.1153\n",
       "    11       0.700067                    0.253919           0.487914   1.39074            0.274157         0.781451                    0.0487805       0.973611                   -51.2086  39.0738\n",
       "    12       0.800045                    0.0400644          0.199965   1.24193            0.11236          0.697838                    0.019992        0.993603                   -80.0035  24.1933\n",
       "    13       0.900022                    0.00213454         0.0559902  1.11019            0.0314607        0.623814                    0.00559776      0.9992                     -94.401   11.0195\n",
       "    14       1                           2.04153e-09        0.0079986  1                  0.00449438       0.561896                    0.00079968      1                          -99.2001  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_400x400.model_performance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_400x400.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1529876519143_109\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.059580784654206326\n",
      "RMSE: 0.2440917545805395\n",
      "LogLoss: 0.18856760589307767\n",
      "Mean Per-Class Error: 0.07089554473302662\n",
      "AUC: 0.9831388526891259\n",
      "Gini: 0.9662777053782519\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7072332233210687: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>4148.0</td>\n",
       "<td>315.0</td>\n",
       "<td>0.0706</td>\n",
       "<td> (315.0/4463.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>397.0</td>\n",
       "<td>5178.0</td>\n",
       "<td>0.0712</td>\n",
       "<td> (397.0/5575.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>4545.0</td>\n",
       "<td>5493.0</td>\n",
       "<td>0.0709</td>\n",
       "<td> (712.0/10038.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  ---------------\n",
       "NO     4148  315    0.0706   (315.0/4463.0)\n",
       "YES    397   5178   0.0712   (397.0/5575.0)\n",
       "Total  4545  5493   0.0709   (712.0/10038.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.7072332</td>\n",
       "<td>0.9356704</td>\n",
       "<td>130.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3930598</td>\n",
       "<td>0.9551677</td>\n",
       "<td>236.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8467875</td>\n",
       "<td>0.9510222</td>\n",
       "<td>82.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7072332</td>\n",
       "<td>0.9290695</td>\n",
       "<td>130.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999794</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0109596</td>\n",
       "<td>1.0</td>\n",
       "<td>387.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999794</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7072332</td>\n",
       "<td>0.8567560</td>\n",
       "<td>130.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7072332</td>\n",
       "<td>0.9287892</td>\n",
       "<td>130.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7072332</td>\n",
       "<td>0.9291045</td>\n",
       "<td>130.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.707233     0.93567   130\n",
       "max f2                       0.39306      0.955168  236\n",
       "max f0point5                 0.846787     0.951022  82\n",
       "max accuracy                 0.707233     0.92907   130\n",
       "max precision                0.999979     1         0\n",
       "max recall                   0.0109596    1         387\n",
       "max specificity              0.999979     1         0\n",
       "max absolute_mcc             0.707233     0.856756  130\n",
       "max min_per_class_accuracy   0.707233     0.928789  130\n",
       "max mean_per_class_accuracy  0.707233     0.929104  130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 55.54 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0365611</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0658296</td>\n",
       "<td>0.0658296</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0403467</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0068161</td>\n",
       "<td>0.0726457</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0500100</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0173991</td>\n",
       "<td>0.0900448</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.1000199</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0900448</td>\n",
       "<td>0.1800897</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1500299</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0900448</td>\n",
       "<td>0.2701345</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.2000398</td>\n",
       "<td>0.9999876</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0900448</td>\n",
       "<td>0.3601794</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.3000598</td>\n",
       "<td>0.9987725</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1800897</td>\n",
       "<td>0.5402691</td>\n",
       "<td>80.0538117</td>\n",
       "<td>80.0538117</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.3999801</td>\n",
       "<td>0.9775156</td>\n",
       "<td>1.7861769</td>\n",
       "<td>1.7969505</td>\n",
       "<td>0.9920239</td>\n",
       "<td>0.9980075</td>\n",
       "<td>0.1784753</td>\n",
       "<td>0.7187444</td>\n",
       "<td>78.6176895</td>\n",
       "<td>79.6950494</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8420642</td>\n",
       "<td>1.5620206</td>\n",
       "<td>1.7499552</td>\n",
       "<td>0.8675299</td>\n",
       "<td>0.9719068</td>\n",
       "<td>0.1562332</td>\n",
       "<td>0.8749776</td>\n",
       "<td>56.2020617</td>\n",
       "<td>74.9955157</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.6000199</td>\n",
       "<td>0.5350334</td>\n",
       "<td>0.9092359</td>\n",
       "<td>1.6098120</td>\n",
       "<td>0.5049801</td>\n",
       "<td>0.8940727</td>\n",
       "<td>0.0909417</td>\n",
       "<td>0.9659193</td>\n",
       "<td>-9.0764118</td>\n",
       "<td>60.9812014</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6999402</td>\n",
       "<td>0.1900719</td>\n",
       "<td>0.2872244</td>\n",
       "<td>1.4210054</td>\n",
       "<td>0.1595214</td>\n",
       "<td>0.7892115</td>\n",
       "<td>0.0286996</td>\n",
       "<td>0.9946188</td>\n",
       "<td>-71.2775575</td>\n",
       "<td>42.1005388</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7999602</td>\n",
       "<td>0.0298107</td>\n",
       "<td>0.0484208</td>\n",
       "<td>1.2493896</td>\n",
       "<td>0.0268924</td>\n",
       "<td>0.6938979</td>\n",
       "<td>0.0048430</td>\n",
       "<td>0.9994619</td>\n",
       "<td>-95.1579154</td>\n",
       "<td>24.9389587</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.8999801</td>\n",
       "<td>0.0016188</td>\n",
       "<td>0.0053801</td>\n",
       "<td>1.1111357</td>\n",
       "<td>0.0029880</td>\n",
       "<td>0.6171131</td>\n",
       "<td>0.0005381</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.4619906</td>\n",
       "<td>11.1135710</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5553895</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0365611                   1                  1.80054     1.80054            1                1                           0.0658296       0.0658296                  80.0538   80.0538\n",
       "    2        0.0403467                   1                  1.80054     1.80054            1                1                           0.00681614      0.0726457                  80.0538   80.0538\n",
       "    3        0.05001                     1                  1.80054     1.80054            1                1                           0.0173991       0.0900448                  80.0538   80.0538\n",
       "    4        0.10002                     1                  1.80054     1.80054            1                1                           0.0900448       0.18009                    80.0538   80.0538\n",
       "    5        0.15003                     1                  1.80054     1.80054            1                1                           0.0900448       0.270135                   80.0538   80.0538\n",
       "    6        0.20004                     0.999988           1.80054     1.80054            1                1                           0.0900448       0.360179                   80.0538   80.0538\n",
       "    7        0.30006                     0.998772           1.80054     1.80054            1                1                           0.18009         0.540269                   80.0538   80.0538\n",
       "    8        0.39998                     0.977516           1.78618     1.79695            0.992024         0.998007                    0.178475        0.718744                   78.6177   79.695\n",
       "    9        0.5                         0.842064           1.56202     1.74996            0.86753          0.971907                    0.156233        0.874978                   56.2021   74.9955\n",
       "    10       0.60002                     0.535033           0.909236    1.60981            0.50498          0.894073                    0.0909417       0.965919                   -9.07641  60.9812\n",
       "    11       0.69994                     0.190072           0.287224    1.42101            0.159521         0.789212                    0.0286996       0.994619                   -71.2776  42.1005\n",
       "    12       0.79996                     0.0298107          0.0484208   1.24939            0.0268924        0.693898                    0.00484305      0.999462                   -95.1579  24.939\n",
       "    13       0.89998                     0.00161884         0.00538009  1.11114            0.00298805       0.617113                    0.000538117     1                          -99.462   11.1136\n",
       "    14       1                           9.76946e-10        0           1                  0                0.55539                     0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.09989803487181408\n",
      "RMSE: 0.316066503875077\n",
      "LogLoss: 0.3422899694763406\n",
      "Mean Per-Class Error: 0.12263720484897334\n",
      "AUC: 0.9480759571334445\n",
      "Gini: 0.896151914266889\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6870341148824416: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>NO</b></td>\n",
       "<td><b>YES</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>NO</td>\n",
       "<td>1667.0</td>\n",
       "<td>266.0</td>\n",
       "<td>0.1376</td>\n",
       "<td> (266.0/1933.0)</td></tr>\n",
       "<tr><td>YES</td>\n",
       "<td>264.0</td>\n",
       "<td>2075.0</td>\n",
       "<td>0.1129</td>\n",
       "<td> (264.0/2339.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>1931.0</td>\n",
       "<td>2341.0</td>\n",
       "<td>0.1241</td>\n",
       "<td> (530.0/4272.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       NO    YES    Error    Rate\n",
       "-----  ----  -----  -------  --------------\n",
       "NO     1667  266    0.1376   (266.0/1933.0)\n",
       "YES    264   2075   0.1129   (264.0/2339.0)\n",
       "Total  1931  2341   0.1241   (530.0/4272.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.6870341</td>\n",
       "<td>0.8867521</td>\n",
       "<td>143.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2433378</td>\n",
       "<td>0.9192042</td>\n",
       "<td>290.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9283702</td>\n",
       "<td>0.9041517</td>\n",
       "<td>50.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7139116</td>\n",
       "<td>0.8768727</td>\n",
       "<td>133.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999853</td>\n",
       "<td>0.9951124</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0038920</td>\n",
       "<td>1.0</td>\n",
       "<td>394.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999853</td>\n",
       "<td>0.9974133</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7139116</td>\n",
       "<td>0.7521161</td>\n",
       "<td>133.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7201760</td>\n",
       "<td>0.8755879</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7893028</td>\n",
       "<td>0.8773628</td>\n",
       "<td>108.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.687034     0.886752  143\n",
       "max f2                       0.243338     0.919204  290\n",
       "max f0point5                 0.92837      0.904152  50\n",
       "max accuracy                 0.713912     0.876873  133\n",
       "max precision                0.999985     0.995112  0\n",
       "max recall                   0.00389199   1         394\n",
       "max specificity              0.999985     0.997413  0\n",
       "max absolute_mcc             0.713912     0.752116  133\n",
       "max min_per_class_accuracy   0.720176     0.875588  131\n",
       "max mean_per_class_accuracy  0.789303     0.877363  108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 54.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0386236</td>\n",
       "<td>1.0</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0705430</td>\n",
       "<td>0.0705430</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0407303</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0038478</td>\n",
       "<td>0.0743908</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0500936</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0171013</td>\n",
       "<td>0.0914921</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.1001873</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0914921</td>\n",
       "<td>0.1829842</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.1500468</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.8264215</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.2740487</td>\n",
       "<td>82.6421548</td>\n",
       "<td>82.6421548</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.2001404</td>\n",
       "<td>0.9999853</td>\n",
       "<td>1.8178869</td>\n",
       "<td>1.8242854</td>\n",
       "<td>0.9953271</td>\n",
       "<td>0.9988304</td>\n",
       "<td>0.0910646</td>\n",
       "<td>0.3651133</td>\n",
       "<td>81.7886868</td>\n",
       "<td>82.4285382</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.3000936</td>\n",
       "<td>0.9979566</td>\n",
       "<td>1.7622615</td>\n",
       "<td>1.8036269</td>\n",
       "<td>0.9648712</td>\n",
       "<td>0.9875195</td>\n",
       "<td>0.1761437</td>\n",
       "<td>0.5412569</td>\n",
       "<td>76.2261540</td>\n",
       "<td>80.3626895</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.4000468</td>\n",
       "<td>0.9635408</td>\n",
       "<td>1.6082775</td>\n",
       "<td>1.7548181</td>\n",
       "<td>0.8805621</td>\n",
       "<td>0.9607958</td>\n",
       "<td>0.1607525</td>\n",
       "<td>0.7020094</td>\n",
       "<td>60.8277522</td>\n",
       "<td>75.4818128</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8148075</td>\n",
       "<td>1.3601922</td>\n",
       "<td>1.6759299</td>\n",
       "<td>0.7447307</td>\n",
       "<td>0.9176030</td>\n",
       "<td>0.1359555</td>\n",
       "<td>0.8379649</td>\n",
       "<td>36.0192160</td>\n",
       "<td>67.5929885</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.5999532</td>\n",
       "<td>0.5195666</td>\n",
       "<td>0.8640214</td>\n",
       "<td>1.5406646</td>\n",
       "<td>0.4730679</td>\n",
       "<td>0.8435427</td>\n",
       "<td>0.0863617</td>\n",
       "<td>0.9243266</td>\n",
       "<td>-13.5978565</td>\n",
       "<td>54.0664606</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.6999064</td>\n",
       "<td>0.2212402</td>\n",
       "<td>0.4576747</td>\n",
       "<td>1.3860035</td>\n",
       "<td>0.2505855</td>\n",
       "<td>0.7588629</td>\n",
       "<td>0.0457460</td>\n",
       "<td>0.9700727</td>\n",
       "<td>-54.2325280</td>\n",
       "<td>38.6003509</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.7998596</td>\n",
       "<td>0.0397069</td>\n",
       "<td>0.2053120</td>\n",
       "<td>1.2384603</td>\n",
       "<td>0.1124122</td>\n",
       "<td>0.6780802</td>\n",
       "<td>0.0205216</td>\n",
       "<td>0.9905943</td>\n",
       "<td>-79.4687976</td>\n",
       "<td>23.8460265</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.8998127</td>\n",
       "<td>0.0022571</td>\n",
       "<td>0.0941013</td>\n",
       "<td>1.1113424</td>\n",
       "<td>0.0515222</td>\n",
       "<td>0.6084807</td>\n",
       "<td>0.0094057</td>\n",
       "<td>1.0</td>\n",
       "<td>-90.5898656</td>\n",
       "<td>11.1342352</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5475187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0386236                   1                  1.82642    1.82642            1                1                           0.070543        0.070543                   82.6422   82.6422\n",
       "    2        0.0407303                   1                  1.82642    1.82642            1                1                           0.0038478       0.0743908                  82.6422   82.6422\n",
       "    3        0.0500936                   1                  1.82642    1.82642            1                1                           0.0171013       0.0914921                  82.6422   82.6422\n",
       "    4        0.100187                    1                  1.82642    1.82642            1                1                           0.0914921       0.182984                   82.6422   82.6422\n",
       "    5        0.150047                    1                  1.82642    1.82642            1                1                           0.0910646       0.274049                   82.6422   82.6422\n",
       "    6        0.20014                     0.999985           1.81789    1.82429            0.995327         0.99883                     0.0910646       0.365113                   81.7887   82.4285\n",
       "    7        0.300094                    0.997957           1.76226    1.80363            0.964871         0.98752                     0.176144        0.541257                   76.2262   80.3627\n",
       "    8        0.400047                    0.963541           1.60828    1.75482            0.880562         0.960796                    0.160752        0.702009                   60.8278   75.4818\n",
       "    9        0.5                         0.814807           1.36019    1.67593            0.744731         0.917603                    0.135956        0.837965                   36.0192   67.593\n",
       "    10       0.599953                    0.519567           0.864021   1.54066            0.473068         0.843543                    0.0863617       0.924327                   -13.5979  54.0665\n",
       "    11       0.699906                    0.22124            0.457675   1.386              0.250585         0.758863                    0.045746        0.970073                   -54.2325  38.6004\n",
       "    12       0.79986                     0.0397069          0.205312   1.23846            0.112412         0.67808                     0.0205216       0.990594                   -79.4688  23.846\n",
       "    13       0.899813                    0.00225714         0.0941013  1.11134            0.0515222        0.608481                    0.00940573      1                          -90.5899  11.1342\n",
       "    14       1                           1.5548e-09         0          1                  0                0.547519                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_r2</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:49:49</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:49:52</td>\n",
       "<td>14.319 sec</td>\n",
       "<td>1134 obs/sec</td>\n",
       "<td>0.1082116</td>\n",
       "<td>1</td>\n",
       "<td>3815.0</td>\n",
       "<td>0.5429824</td>\n",
       "<td>0.8832042</td>\n",
       "<td>-0.1939722</td>\n",
       "<td>0.6410194</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.4412234</td>\n",
       "<td>0.5520363</td>\n",
       "<td>0.9115628</td>\n",
       "<td>-0.2300868</td>\n",
       "<td>0.6269436</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.4524813</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:51:42</td>\n",
       "<td> 2 min  6.209 sec</td>\n",
       "<td>2475 obs/sec</td>\n",
       "<td>7.1813076</td>\n",
       "<td>69</td>\n",
       "<td>253177.0</td>\n",
       "<td>0.3165548</td>\n",
       "<td>0.3074543</td>\n",
       "<td>0.5941921</td>\n",
       "<td>0.9551753</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.1211397</td>\n",
       "<td>0.3390064</td>\n",
       "<td>0.3506310</td>\n",
       "<td>0.5361088</td>\n",
       "<td>0.9355536</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1500468</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:53:53</td>\n",
       "<td> 4 min 15.781 sec</td>\n",
       "<td>2477 obs/sec</td>\n",
       "<td>15.5051482</td>\n",
       "<td>149</td>\n",
       "<td>546634.0</td>\n",
       "<td>0.2440918</td>\n",
       "<td>0.1885676</td>\n",
       "<td>0.7587158</td>\n",
       "<td>0.9831389</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0709305</td>\n",
       "<td>0.3160665</td>\n",
       "<td>0.3422900</td>\n",
       "<td>0.5967658</td>\n",
       "<td>0.9480760</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1240637</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:55:46</td>\n",
       "<td> 6 min  8.024 sec</td>\n",
       "<td>2486 obs/sec</td>\n",
       "<td>22.6906254</td>\n",
       "<td>218</td>\n",
       "<td>799958.0</td>\n",
       "<td>0.1960993</td>\n",
       "<td>0.1229900</td>\n",
       "<td>0.8442691</td>\n",
       "<td>0.9909189</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0541941</td>\n",
       "<td>0.3048394</td>\n",
       "<td>0.3615178</td>\n",
       "<td>0.6249037</td>\n",
       "<td>0.9525768</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1221910</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:57:37</td>\n",
       "<td> 7 min 59.928 sec</td>\n",
       "<td>2477 obs/sec</td>\n",
       "<td>29.6755637</td>\n",
       "<td>285</td>\n",
       "<td>1046212.0</td>\n",
       "<td>0.1868639</td>\n",
       "<td>0.1121889</td>\n",
       "<td>0.8585922</td>\n",
       "<td>0.9924766</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.3139473</td>\n",
       "<td>0.4448362</td>\n",
       "<td>0.6021550</td>\n",
       "<td>0.9455544</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1280431</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 03:59:33</td>\n",
       "<td> 9 min 54.889 sec</td>\n",
       "<td>2484 obs/sec</td>\n",
       "<td>37.0889236</td>\n",
       "<td>356</td>\n",
       "<td>1307570.0</td>\n",
       "<td>0.1605353</td>\n",
       "<td>0.0835093</td>\n",
       "<td>0.8956329</td>\n",
       "<td>0.9966233</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0291891</td>\n",
       "<td>0.3104472</td>\n",
       "<td>0.5246365</td>\n",
       "<td>0.6109765</td>\n",
       "<td>0.9465204</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1168071</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 04:01:23</td>\n",
       "<td>11 min 45.770 sec</td>\n",
       "<td>2486 obs/sec</td>\n",
       "<td>44.1423628</td>\n",
       "<td>424</td>\n",
       "<td>1556239.0</td>\n",
       "<td>0.1437171</td>\n",
       "<td>0.0686848</td>\n",
       "<td>0.9163551</td>\n",
       "<td>0.9972397</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0263997</td>\n",
       "<td>0.3116090</td>\n",
       "<td>0.6090554</td>\n",
       "<td>0.6080592</td>\n",
       "<td>0.9438668</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1151685</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 04:03:16</td>\n",
       "<td>13 min 38.093 sec</td>\n",
       "<td>2474 obs/sec</td>\n",
       "<td>51.0183520</td>\n",
       "<td>490</td>\n",
       "<td>1798652.0</td>\n",
       "<td>0.1525167</td>\n",
       "<td>0.0756920</td>\n",
       "<td>0.9057986</td>\n",
       "<td>0.9972381</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0283921</td>\n",
       "<td>0.3158974</td>\n",
       "<td>0.6602574</td>\n",
       "<td>0.5971972</td>\n",
       "<td>0.9396234</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1137640</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 04:05:09</td>\n",
       "<td>15 min 30.932 sec</td>\n",
       "<td>2466 obs/sec</td>\n",
       "<td>57.9739328</td>\n",
       "<td>557</td>\n",
       "<td>2043871.0</td>\n",
       "<td>0.1278042</td>\n",
       "<td>0.0524872</td>\n",
       "<td>0.9338525</td>\n",
       "<td>0.9983152</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0227137</td>\n",
       "<td>0.3108902</td>\n",
       "<td>0.7282794</td>\n",
       "<td>0.6098654</td>\n",
       "<td>0.9415411</td>\n",
       "<td>1.8244492</td>\n",
       "<td>0.1121255</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 04:07:00</td>\n",
       "<td>17 min 22.455 sec</td>\n",
       "<td>2456 obs/sec</td>\n",
       "<td>64.7354418</td>\n",
       "<td>622</td>\n",
       "<td>2282248.0</td>\n",
       "<td>0.1299233</td>\n",
       "<td>0.0548984</td>\n",
       "<td>0.9316408</td>\n",
       "<td>0.9982546</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0223152</td>\n",
       "<td>0.3181252</td>\n",
       "<td>0.7918896</td>\n",
       "<td>0.5914957</td>\n",
       "<td>0.9386654</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1158708</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 04:08:53</td>\n",
       "<td>19 min 15.343 sec</td>\n",
       "<td>2458 obs/sec</td>\n",
       "<td>71.9119274</td>\n",
       "<td>691</td>\n",
       "<td>2535255.0</td>\n",
       "<td>0.1241192</td>\n",
       "<td>0.0500269</td>\n",
       "<td>0.9376121</td>\n",
       "<td>0.9985200</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0194262</td>\n",
       "<td>0.3193636</td>\n",
       "<td>0.8615285</td>\n",
       "<td>0.5883090</td>\n",
       "<td>0.9358258</td>\n",
       "<td>1.8227392</td>\n",
       "<td>0.1132959</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-06-25 04:09:04</td>\n",
       "<td>19 min 25.969 sec</td>\n",
       "<td>2458 obs/sec</td>\n",
       "<td>71.9119274</td>\n",
       "<td>691</td>\n",
       "<td>2535255.0</td>\n",
       "<td>0.2440918</td>\n",
       "<td>0.1885676</td>\n",
       "<td>0.7587158</td>\n",
       "<td>0.9831389</td>\n",
       "<td>1.8005381</td>\n",
       "<td>0.0709305</td>\n",
       "<td>0.3160665</td>\n",
       "<td>0.3422900</td>\n",
       "<td>0.5967658</td>\n",
       "<td>0.9480760</td>\n",
       "<td>1.8264215</td>\n",
       "<td>0.1240637</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration           training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  -----------------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -----------------  ---------------------------------\n",
       "    2018-06-25 03:49:49  0.000 sec                            0         0             0            nan              nan                 nan            nan             nan              nan                              nan                nan                   nan              nan               nan                nan\n",
       "    2018-06-25 03:49:52  14.319 sec         1134 obs/sec      0.108212  1             3815         0.542982         0.883204            -0.193972      0.641019        1.80054          0.441223                         0.552036           0.911563              -0.230087        0.626944          1.82642            0.452481\n",
       "    2018-06-25 03:51:42  2 min  6.209 sec   2475 obs/sec      7.18131   69            253177       0.316555         0.307454            0.594192       0.955175        1.80054          0.12114                          0.339006           0.350631              0.536109         0.935554          1.82642            0.150047\n",
       "    2018-06-25 03:53:53  4 min 15.781 sec   2477 obs/sec      15.5051   149           546634       0.244092         0.188568            0.758716       0.983139        1.80054          0.0709305                        0.316067           0.34229               0.596766         0.948076          1.82642            0.124064\n",
       "    2018-06-25 03:55:46  6 min  8.024 sec   2486 obs/sec      22.6906   218           799958       0.196099         0.12299             0.844269       0.990919        1.80054          0.0541941                        0.304839           0.361518              0.624904         0.952577          1.82642            0.122191\n",
       "    2018-06-25 03:57:37  7 min 59.928 sec   2477 obs/sec      29.6756   285           1.04621e+06  0.186864         0.112189            0.858592       0.992477        1.80054          0.047619                         0.313947           0.444836              0.602155         0.945554          1.82642            0.128043\n",
       "    2018-06-25 03:59:33  9 min 54.889 sec   2484 obs/sec      37.0889   356           1.30757e+06  0.160535         0.0835093           0.895633       0.996623        1.80054          0.0291891                        0.310447           0.524636              0.610977         0.94652           1.82642            0.116807\n",
       "    2018-06-25 04:01:23  11 min 45.770 sec  2486 obs/sec      44.1424   424           1.55624e+06  0.143717         0.0686848           0.916355       0.99724         1.80054          0.0263997                        0.311609           0.609055              0.608059         0.943867          1.82642            0.115169\n",
       "    2018-06-25 04:03:16  13 min 38.093 sec  2474 obs/sec      51.0184   490           1.79865e+06  0.152517         0.075692            0.905799       0.997238        1.80054          0.0283921                        0.315897           0.660257              0.597197         0.939623          1.82642            0.113764\n",
       "    2018-06-25 04:05:09  15 min 30.932 sec  2466 obs/sec      57.9739   557           2.04387e+06  0.127804         0.0524872           0.933853       0.998315        1.80054          0.0227137                        0.31089            0.728279              0.609865         0.941541          1.82445            0.112125\n",
       "    2018-06-25 04:07:00  17 min 22.455 sec  2456 obs/sec      64.7354   622           2.28225e+06  0.129923         0.0548984           0.931641       0.998255        1.80054          0.0223152                        0.318125           0.79189               0.591496         0.938665          1.82642            0.115871\n",
       "    2018-06-25 04:08:53  19 min 15.343 sec  2458 obs/sec      71.9119   691           2.53526e+06  0.124119         0.0500269           0.937612       0.99852         1.80054          0.0194262                        0.319364           0.861528              0.588309         0.935826          1.82274            0.113296\n",
       "    2018-06-25 04:09:04  19 min 25.969 sec  2458 obs/sec      71.9119   691           2.53526e+06  0.244092         0.188568            0.758716       0.983139        1.80054          0.0709305                        0.316067           0.34229               0.596766         0.948076          1.82642            0.124064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>ArrTime</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0018182</td></tr>\n",
       "<tr><td>CRSArrTime</td>\n",
       "<td>0.9013873</td>\n",
       "<td>0.9013873</td>\n",
       "<td>0.0016389</td></tr>\n",
       "<tr><td>DepTime</td>\n",
       "<td>0.6633399</td>\n",
       "<td>0.6633399</td>\n",
       "<td>0.0012061</td></tr>\n",
       "<tr><td>CRSDepTime</td>\n",
       "<td>0.6506033</td>\n",
       "<td>0.6506033</td>\n",
       "<td>0.0011830</td></tr>\n",
       "<tr><td>TailNum.NA</td>\n",
       "<td>0.5013327</td>\n",
       "<td>0.5013327</td>\n",
       "<td>0.0009115</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>TailNum.N472AA</td>\n",
       "<td>0.1256116</td>\n",
       "<td>0.1256116</td>\n",
       "<td>0.0002284</td></tr>\n",
       "<tr><td>TailNum.N200WN</td>\n",
       "<td>0.1255245</td>\n",
       "<td>0.1255245</td>\n",
       "<td>0.0002282</td></tr>\n",
       "<tr><td>Dest.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>Origin.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>UniqueCarrier.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                   relative_importance    scaled_importance    percentage\n",
       "-------------------------  ---------------------  -------------------  ----------------------\n",
       "ArrTime                    1.0                    1.0                  0.0018182479248456387\n",
       "CRSArrTime                 0.9013872742652893     0.9013872742652893   0.001638945540915129\n",
       "DepTime                    0.6633398532867432     0.6633398532867432   0.0012061163117060313\n",
       "CRSDepTime                 0.6506032943725586     0.6506032943725586   0.001182958089890641\n",
       "TailNum.NA                 0.501332700252533      0.501332700252533    0.0009115471418914287\n",
       "---                        ---                    ---                  ---\n",
       "TailNum.N472AA             0.12561164796352386    0.12561164796352386  0.00022839311824611819\n",
       "TailNum.N200WN             0.12552449107170105    0.12552449107170105  0.00022823464540842534\n",
       "Dest.missing(NA)           0.0                    0.0                  0.0\n",
       "Origin.missing(NA)         0.0                    0.0                  0.0\n",
       "UniqueCarrier.missing(NA)  0.0                    0.0                  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_400x400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why three layer neurons is quicker than 2 layer neuron ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did it take longer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Neuron Layers: predicting IsArrDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 801,202 weights/biases, 9.2 MB, 363,116 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>3802</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5234414</td>\n",
       "<td>0.4771924</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001009</td>\n",
       "<td>0.0254511</td>\n",
       "<td>-0.3309801</td>\n",
       "<td>0.2242589</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2961834</td>\n",
       "<td>0.3685958</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0070119</td>\n",
       "<td>0.0893284</td>\n",
       "<td>-0.0222179</td>\n",
       "<td>0.2433962</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0257978</td>\n",
       "<td>0.0649899</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042965</td>\n",
       "<td>0.3348324</td>\n",
       "<td>0.0276584</td>\n",
       "<td>0.4522240</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight             weight_rms            mean_bias              bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  -------------------  ----------  ----------------------  --------------------  ---------------------  -------------------\n",
       "    1        3802     Input      0.0\n",
       "    2        200      Rectifier  0.0        0.0   0.0   0.5234414331644508    0.47719240188598633  0.0         0.00010089607414829211  0.025451064109802246  -0.3309800522673425    0.2242588996887207\n",
       "    3        200      Rectifier  0.0        0.0   0.0   0.29618338798482763   0.36859583854675293  0.0         -0.0070118679072177035  0.08932837843894958   -0.022217877866016537  0.24339622259140015\n",
       "    4        2        Softmax               0.0   0.0   0.025797777340339962  0.06498989462852478  0.0         0.00429653389233863     0.33483242988586426   0.02765842066246524    0.4522240161895752"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_def.summary() #800k weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3802, 200, 200, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_def.summary()['units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800800"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this gives number of weights plus biases\n",
    "(3802 * 200) + (200 * 200)+(200 * 2) #Plus 200 +200+ 2 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Neuron Layers: predicting IsArrDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 841,402 weights/biases, 9.7 MB, 1,637,162 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>3802</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1201443</td>\n",
       "<td>0.2814668</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0005121</td>\n",
       "<td>0.0319420</td>\n",
       "<td>-0.1536235</td>\n",
       "<td>0.3961180</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0376978</td>\n",
       "<td>0.0818093</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0357392</td>\n",
       "<td>0.0917043</td>\n",
       "<td>0.7239650</td>\n",
       "<td>0.1080936</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>200</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1320740</td>\n",
       "<td>0.1975344</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0065727</td>\n",
       "<td>0.0798736</td>\n",
       "<td>-0.1623716</td>\n",
       "<td>0.2204847</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0211679</td>\n",
       "<td>0.0547472</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0083639</td>\n",
       "<td>0.3016576</td>\n",
       "<td>-0.0052966</td>\n",
       "<td>0.2901752</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight             weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  -------------------  ----------  ----------------------  -------------------  ---------------------  -------------------\n",
       "    1        3802     Input      0.0\n",
       "    2        200      Rectifier  0.0        0.0   0.0   0.12014429613311593   0.28146684169769287  0.0         -0.0005121002655050221  0.03194199502468109  -0.1536235021580046    0.39611804485321045\n",
       "    3        200      Rectifier  0.0        0.0   0.0   0.03769781935168939   0.08180931210517883  0.0         -0.035739165562437517   0.09170427918434143  0.7239649664221498     0.10809358954429626\n",
       "    4        200      Rectifier  0.0        0.0   0.0   0.13207396883622496   0.197534441947937    0.0         -0.006572714018938207   0.07987362146377563  -0.1623716337068501    0.2204846739768982\n",
       "    5        2        Softmax               0.0   0.0   0.021167921202431897  0.05474722385406494  0.0         0.008363910497137113    0.3016575574874878   -0.005296588287663939  0.290175199508667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_200x200x200.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3802, 400, 400, 2]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_400x400.summary()['units'] # has double the number of weights thats why it took more time to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Neuron Layers: predicting IsArrDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 1,682,402 weights/biases, 19.3 MB, 2,535,255 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>3802</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>400</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5280311</td>\n",
       "<td>0.4748262</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000408</td>\n",
       "<td>0.0253470</td>\n",
       "<td>-0.3096682</td>\n",
       "<td>0.1888503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>400</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3318304</td>\n",
       "<td>0.3663535</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0096166</td>\n",
       "<td>0.0630659</td>\n",
       "<td>-0.0590029</td>\n",
       "<td>0.2950772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0317337</td>\n",
       "<td>0.0718888</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0094838</td>\n",
       "<td>0.2417504</td>\n",
       "<td>-0.0119784</td>\n",
       "<td>0.7799013</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type       dropout    l1    l2    mean_rate            rate_rms             momentum    mean_weight             weight_rms            mean_bias              bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  -------------------  -------------------  ----------  ----------------------  --------------------  ---------------------  -------------------\n",
       "    1        3802     Input      0.0\n",
       "    2        400      Rectifier  0.0        0.0   0.0   0.5280310529511237   0.47482621669769287  0.0         4.0824215879885746e-05  0.025347024202346802  -0.3096682044242364    0.18885034322738647\n",
       "    3        400      Rectifier  0.0        0.0   0.0   0.33183044645178034  0.36635351181030273  0.0         -0.009616552563387932   0.06306594610214233   -0.059002876565644125  0.29507720470428467\n",
       "    4        2        Softmax               0.0   0.0   0.03173366237429036  0.07188877463340759  0.0         -0.009483803426774103   0.24175035953521729   -0.011978395589267943  0.7799012660980225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_400x400.summary() # 1.6 million weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 3501,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 132,\n",
       " 134,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nlevels() #enum cardinality 0-normal, more than 0- categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing this to find out which column has so many categories for ex: 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2OFrame: 'py_3_sid_bcfc' \n",
      "Dimensions: 35255 obs. of 31 variables\n",
      "$ Year              :  num 1987 1987 1987 1987 1987 1987 1987 1987 1987 1987\n",
      "$ Month             :  num 10 10 10 10 10 10 10 10 10 10\n",
      "$ DayofMonth        :  num 14 15 17 18 22 23 24 25 26 28\n",
      "$ DayOfWeek         :  num 3 4 6 7 4 5 6 7 1 3\n",
      "$ DepTime           :  num 741 729 741 729 728 731 744 729 735 741\n",
      "$ CRSDepTime        :  num 730 730 730 730 730 730 730 730 730 725\n",
      "$ ArrTime           :  num 912 903 918 847 852 902 908 851 904 919\n",
      "$ CRSArrTime        :  num 849 849 849 849 849 849 849 849 849 855\n",
      "$ UniqueCarrier     :  Factor w/ 10 level(s) \"AA\",\"CO\",\"DL\",\"HP\",\"PI\",\"PS\",\"TW\",\"UA\",\"US\",\"WN\" \n",
      "$ FlightNum         :  num 1451 1451 1451 1451 1451 1451 1451 1451 1451 1451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ TailNum           :  Factor w/ 3501 level(s) \"-N912<0xE5>\",\"-N913<0xE5>\",\"-N918<0xE5>\",\"-N919<0xE5>\",\"-N920<0xE5>\",\"-N922<0xE5>\",\"-N923<0xE5>\",\"-N924<0xE5>\",\"-N925<0xE5>\",\"-N926<0xE5>\",\"-N927<0xE5>\",\"-N928<0xE5>\",\"-N934<0xE5>\",\"-N936<0xE5>\",\"-N955<0xE5>\",\"-N958<0xE5>\",\"-N959<0xE5>\",\"-N965<0xE5>\",\"-N967<0xE5>\",\"-N970<0xE5>\",\"-N991<0xE5>\",\"0\",\"000000\",\"112\",\"<0xE4>NKNO<0xE6>\",\"EI-BWD\",\"N055AA\",\"N056AA\",\"N057AA\",\"N058AA\",\"N059AA\",\"N060AA\",\"N061AA\",\"N064AA\",\"N066AA\",\"N067AA\",\"N068AA\",\"N069AA\",\"N070AA\",\"N071AA\",\"N073AA\",\"N076AA\",\"N077AA\",\"N078AA\",\"N079AA\",\"N082AA\",\"N084AA\",\"N101<0xE4E6>\",\"N102\",\"N102UW\",\"N103\",\"N10323\",\"N103DA\",\"N103UW\",\"N104\",\"N104UW\",\"N105\",\"N105UW\",\"N106DA\",\"N106UW\",\"N107UW\",\"N108<0xE4E6>\",\"N108DL\",\"N108UW\",\"N109UW\",\"N110HM\",\"N110UW\",\"N111UW\",\"N112DL\",\"N112UW\",\"N113<0xE4E6>\",\"N113DA\",\"N113UW\",\"N114<0xE4E6>\",\"N114UW\",\"N115<0xE4E6>\",\"N116<0xE4E6>\",\"N116DL\",\"N117<0xE4E6>\",\"N117DL\",\"N118<0xE4E6>\",\"N118DL\",\"N118UW\",\"N119<0xE4E6>\",\"N119DL\",\"N119UW\",\"N120<0xE4E6>\",\"N120DL\",\"N121<0xE4E6>\",\"N121DE\",\"N121UW\",\"N122<0xE4E6>\",\"N122DL\",\"N122UW\",\"N12313\",\"N12318\",\"N12319\",\"N12322\",\"N12327\",\"N12349\",\"N123<0xE4E6>\",\"N123DN\",\"N123UW\",\"N124<0xE4E6>\",\"N124DE\",\"N124UW\",\"N125DL\",\"N126AW\",\"N126DL\",\"N127AW\",\"N127DL\",\"N128AW\",\"N128DL\",\"N129\",\"N130\",\"N130DL\",\"N131DN\",\"N132AA\",\"N132DN\",\"N13331\",\"N133DN\",\"N134DL\",\"N135DL\",\"N13624\",\"N136DL\",\"N13716\",\"N13718\",\"N13720\",\"N13750\",\"N137DL\",\"N138AW\",\"N138DL\",\"N139DL\",\"N1402A\",\"N140LL\",\"N141AW\",\"N14308\",\"N14320\",\"N14324\",\"N14335\",\"N14336\",\"N14337\",\"N14341\",\"N14342\",\"N14347\",\"N14383\",\"N145AW\",\"N14629\",\"N14639\",\"N14704\",\"N14731\",\"N14735\",\"N147AW\",\"N149AW\",\"N150AW\",\"N151AW\",\"N154AW\",\"N155AW\",\"N156AW\",\"N15710\",\"N15712\",\"N157AW\",\"N158AW\",\"N160AW\",\"N161<0xE4E6>\",\"N161UW\",\"N162UW\",\"N16301\",\"N16310\",\"N163UW\",\"N164AW\",\"N164UW\",\"N165AW\",\"N165UW\",\"N16618\",\"N16648\",\"N16649\",\"N16650\",\"N16651\",\"N166AW\",\"N166UW\",\"N16701\",\"N16703\",\"N16713\",\"N16732\",\"N167AW\",\"N167UW\",\"N168AW\",\"N168UW\",\"N169AW\",\"N169UW\",\"N170UW\",\"N171UW\",\"N172AW\",\"N172UW\",\"N17306\",\"N17309\",\"N17317\",\"N17321\",\"N17329\",\"N17344\",\"N17345\",\"N17386\",\"N173AW\",\"N173UW\",\"N174<0xE4E6>\",\"N174AW\",\"N174UW\",\"N175AW\",\"N175UW\",\"N17614\",\"N17619\",\"N17620\",\"N17627\",\"N17640\",\"N176UW\",\"N17719\",\"N17730\",\"N177UW\",\"N178AW\",\"N178UW\",\"N179AW\",\"N179UW\",\"N180<0xE4E6>\",\"N180AW\",\"N180UW\",\"N1810U\",\"N1811U\",\"N1812U\",\"N1813U\",\"N1814U\",\"N1815U\",\"N1816U\",\"N1817U\",\"N181AW\",\"N181UW\",\"N1823U\",\"N1824U\",\"N1825U\",\"N182AW\",\"N182UW\",\"N1830U\",\"N1831U\",\"N1832U\",\"N1838U\",\"N183<0xE4E6>\",\"N183AW\",\"N183UW\",\"N1841U\",\"N1842U\",\"N1844U\",\"N1846U\",\"N184AW\",\"N184UW\",\"N185AW\",\"N185UW\",\"N18611\",\"N18622\",\"N186AW\",\"N186UW\",\"N187AW\",\"N187UW\",\"N188AW\",\"N188UW\",\"N189AW\",\"N19357\",\"N19382\",\"N19621\",\"N19623\",\"N19634\",\"N197UA\",\"N20\",\"N200WN\",\"N201\",\"N201LV\",\"N202\",\"N202AA\",\"N202UA\",\"N202WN\",\"N203AU\",\"N203UA\",\"N203WN\",\"N204\",\"N204UA\",\"N204WN\",\"N205\",\"N205AA\",\"N205WN\",\"N206\",\"N20643\",\"N206UA\",\"N206WN\",\"N207\",\"N207AA\",\"N207WN\",\"N208\",\"N208AA\",\"N208WN\",\"N209\",\"N209WN\",\"N210\",\"N210AA\",\"N210WN\",\"N211\",\"N211WN\",\"N212\",\"N212WN\",\"N213\",\"N213UA\",\"N213WN\",\"N214\",\"N214WN\",\"N215\",\"N215AA\",\"N215WN\",\"N216\",\"N216AA\",\"N216UA\",\"N216WR\",\"N217\",\"N21723\",\"N217JC\",\"N218\",\"N218AA\",\"N218WN\",\"N219\",\"N219WN\",\"N220\",\"N220US\",\"N220WN\",\"N221\",\"N221WN\",\"N222\",\"N222WN\",\"N223\",\"N223AA\",\"N223US\",\"N223WN\",\"N224\",\"N224AA\",\"N224US\",\"N224WN\",\"N225\",\"N225AA\",\"N225US\",\"N225WN\",\"N226\",\"N226AA\",\"N226US\",\"N226WN\",\"N227\",\"N227AA\",\"N227AU\",\"N227UA\",\"N227WN\",\"N228\",\"N228AA\",\"N228US\",\"N228WN\",\"N229\",\"N229US\",\"N229WN\",\"N23\",\"N230\",\"N230AU\",\"N230WN\",\"N231\",\"N231US\",\"N231WN\",\"N232\",\"N232AA\",\"N232US\",\"N232WN\",\"N233\",\"N233AA\",\"N233LV\",\"N233US\",\"N234\",\"N234AA\",\"N234US\",\"N235\",\"N235US\",\"N235WN\",\"N236\",\"N236AA\",\"N236US\",\"N236WN\",\"N237\",\"N23707\",\"N23708\",\"N23721\",\"N237AA\",\"N237US\",\"N237WN\",\"N238\",\"N238US\",\"N238WN\",\"N239\",\"N239US\",\"N239WN\",\"N24\",\"N240\",\"N240AU\",\"N240WN\",\"N241\",\"N241AA\",\"N241US\",\"N241WN\",\"N242AA\",\"N242US\",\"N242WN\",\"N243\",\"N24343\",\"N243US\",\"N243WN\",\"N244\",\"N244AA\",\"N244US\",\"N244WN\",\"N245\",\"N245AA\",\"N245US\",\"N245WN\",\"N246\",\"N24633\",\"N246AA\",\"N246LV\",\"N246US\",\"N247\",\"N24702\",\"N24706\",\"N24715\",\"N24736\",\"N247US\",\"N247WN\",\"N248\",\"N248AA\",\"N248US\",\"N248WN\",\"N249\",\"N249AA\",\"N249US\",\"N249WN\",\"N250\",\"N250WN\",\"N251\",\"N251AA\",\"N251AU\",\"N251WN\",\"N252\",\"N252AU\",\"N252WN\",\"N253\",\"N253AA\",\"N253AU\",\"N253WN\",\"N254\",\"N254AU\",\"N254WN\",\"N255\",\"N255AA\",\"N255AU\",\"N255WN\",\"N256\",\"N256AU\",\"N256WN\",\"N257\",\"N25705\",\"N257AU\",\"N257WN\",\"N258\",\"N258AA\",\"N258WN\",\"N259\",\"N259AA\",\"N259AU\",\"N259WN\",\"N26\",\"N260\",\"N260AU\",\"N260WN\",\"N261\",\"N261AU\",\"N261WN\",\"N262\",\"N262AU\",\"N262WN\",\"N263AU\",\"N263WN\",\"N264AU\",\"N264LV\",\"N265AU\",\"N265WN\",\"N266AA\",\"N266AU\",\"N266WN\",\"N267AU\",\"N267WN\",\"N268AU\",\"N268WN\",\"N269AA\",\"N269AU\",\"N269WN\",\"N27\",\"N270\",\"N270AU\",\"N270WN\",\"N271\",\"N271AA\",\"N271AU\",\"N271WN\",\"N272AU\",\"N272WN\",\"N273AU\",\"N273WN\",\"N274AA\",\"N274US\",\"N274WN\",\"N275AU\",\"N275WN\",\"N27610\",\"N276AA\",\"N276AU\",\"N276WN\",\"N27722\",\"N27733\",\"N27734\",\"N277AU\",\"N277WN\",\"N278AA\",\"N278WN\",\"N279AA\",\"N279AU\",\"N279WN\",\"N28\",\"N2807W\",\"N2809W\",\"N280AU\",\"N280WN\",\"N2812W\",\"N2813W\",\"N2814W\",\"N2815W\",\"N2816W\",\"N2817W\",\"N2819W\",\"N281AU\",\"N281WN\",\"N2820W\",\"N2821W\",\"N2824W\",\"N2826W\",\"N2829W\",\"N282AU\",\"N282WA\",\"N282WN\",\"N283AA\",\"N283AU\",\"N283WA\",\"N283WN\",\"N284AU\",\"N284WN\",\"N285AA\",\"N285AU\",\"N285WN\",\"N286\",\"N286AA\",\"N286AU\",\"N286WN\",\"N287AA\",\"N287AU\",\"N287WN\",\"N288AA\",\"N288AU\",\"N288WN\",\"N289AA\",\"N289CT\",\"N29\",\"N290AA\",\"N290WA\",\"N290WN\",\"N291AA\",\"N291WA\",\"N291WN\",\"N292AA\",\"N292WA\",\"N292WN\",\"N293\",\"N293AA\",\"N293WA\",\"N294AA\",\"N294WA\",\"N294WN\",\"N295AA\",\"N295WA\",\"N295WN\",\"N296AA\",\"N296WA\",\"N296WN\",\"N29717\",\"N297AA\",\"N297WA\",\"N297WN\",\"N298AA\",\"N298WN\",\"N299WN\",\"N300\",\"N300A<0xE4>\",\"N300AU\",\"N300SW\",\"N301\",\"N301AU\",\"N301SW\",\"N301UA\",\"N302\",\"N302AU\",\"N302AW\",\"N302SW\",\"N302UA\",\"N303\",\"N303AW\",\"N303SW\",\"N303UA\",\"N304\",\"N304AW\",\"N304SW\",\"N304UA\",\"N305\",\"N305AW\",\"N305SW\",\"N305UA\",\"N306\",\"N306AW\",\"N306SW\",\"N306UA\",\"N307\",\"N307AW\",\"N307SW\",\"N307UA\",\"N308\",\"N308AW\",\"N308SA\",\"N308SW\",\"N308UA\",\"N309\",\"N309AW\",\"N309SW\",\"N309UA\",\"N310\",\"N310SW\",\"N310UA\",\"N311\",\"N311AW\",\"N311SW\",\"N311UA\",\"N312\",\"N312AW\",\"N312SW\",\"N312UA\",\"N313\",\"N313AW\",\"N313SW\",\"N313UA\",\"N314\",\"N314AW\",\"N314SW\",\"N314UA\",\"N315\",\"N315AW\",\"N315SW\",\"N315UA\",\"N316\",\"N316AW\",\"N316SW\",\"N316UA\",\"N317\",\"N317SW\",\"N317UA\",\"N318\",\"N318SW\",\"N318UA\",\"N319\",\"N319UA\",\"N320\",\"N320SW\",\"N320UA\",\"N321\",\"N321SW\",\"N321UA\",\"N322\",\"N322AW\",\"N322UA\",\"N323\",\"N323AW\",\"N323SW\",\"N323UA\",\"N324\",\"N324AW\",\"N324SW\",\"N324UA\",\"N325\",\"N325AW\",\"N325SW\",\"N325UA\",\"N326\",\"N326AW\",\"N326SW\",\"N326UA\",\"N327\",\"N327AW\",\"N327SW\",\"N327UA\",\"N327US\",\"N328\",\"N328AW\",\"N328SW\",\"N328UA\",\"N329\",\"N329AW\",\"N329SW\",\"N329UA\",\"N329US\",\"N330\",\"N330AW\",\"N330SW\",\"N330UA\",\"N331\",\"N331AW\",\"N331SW\",\"N331UA\",\"N332\",\"N332AW\",\"N332SW\",\"N332UA\",\"N333\",\"N333SW\",\"N333UA\",\"N334\",\"N334<0xE4E2>\",\"N334AW\",\"N334SW\",\"N334UA\",\"N334US\",\"N335\",\"N335<0xE4E2>\",\"N335AW\",\"N335SW\",\"N335UA\",\"N335US\",\"N336\",\"N33635\",\"N33637\",\"N336<0xE4E2>\",\"N336AW\",\"N336SW\",\"N336UA\",\"N336US\",\"N337\",\"N337<0xE4E2>\",\"N337SW\",\"N337UA\",\"N337US\",\"N338\",\"N338<0xE4E2>\",\"N338SW\",\"N338UA\",\"N338US\",\"N339\",\"N339<0xE4E2>\",\"N339SW\",\"N339UA\",\"N339US\",\"N340\",\"N340<0xE4E2>\",\"N340LV\",\"N340UA\",\"N340US\",\"N341\",\"N341<0xE4E2>\",\"N341SW\",\"N341UA\",\"N341US\",\"N342\",\"N342<0xE4E2>\",\"N342SW\",\"N342UA\",\"N342US\",\"N343\",\"N34315\",\"N343SW\",\"N343UA\",\"N344\",\"N344SW\",\"N344UA\",\"N345\",\"N345SA\",\"N345UA\",\"N346\",\"N346<0xE4E2>\",\"N346SW\",\"N346UA\",\"N346US\",\"N347\",\"N347SW\",\"N347UA\",\"N348\",\"N348SW\",\"N348UA\",\"N349\",\"N349<0xE4E2>\",\"N349UA\",\"N349US\",\"N350\",\"N350<0xE4E2>\",\"N350SW\",\"N350UA\",\"N350US\",\"N351\",\"N351<0xE4E2>\",\"N351SW\",\"N351UA\",\"N351US\",\"N352\",\"N352<0xE4E2>\",\"N352SW\",\"N352UA\",\"N352US\",\"N353\",\"N353<0xE4E2>\",\"N353SW\",\"N353UA\",\"N353US\",\"N354\",\"N354<0xE4E2>\",\"N354SW\",\"N354UA\",\"N354US\",\"N355\",\"N355<0xE4E2>\",\"N355SW\",\"N355UA\",\"N355US\",\"N356\",\"N356<0xE4E2>\",\"N356SW\",\"N356UA\",\"N356US\",\"N357\",\"N357SW\",\"N357UA\",\"N358\",\"N358SW\",\"N358UA\",\"N359\",\"N359SW\",\"N360\",\"N360SW\",\"N360UA\",\"N361\",\"N361SW\",\"N361UA\",\"N362\",\"N362SW\",\"N362UA\",\"N363\",\"N363SW\",\"N363UA\",\"N364\",\"N364SW\",\"N364UA\",\"N365\",\"N365SW\",\"N365UA\",\"N366\",\"N366SW\",\"N366UA\",\"N367\",\"N367SW\",\"N367UA\",\"N368\",\"N368SW\",\"N368UA\",\"N369\",\"N369SW\",\"N369UA\",\"N370\",\"N370SW\",\"N370UA\",\"N371\",\"N371<0xE4E2>\",\"N371SW\",\"N371UA\",\"N371US\",\"N372\",\"N372UA\",\"N372US\",\"N373\",\"N373<0xE4E2>\",\"N373UA\",\"N373US\",\"N374\",\"N374<0xE4E2>\",\"N374SW\",\"N374UA\",\"N374US\",\"N375\",\"N375<0xE4E2>\",\"N375UA\",\"N375US\",\"N376\",\"N376<0xE4E2>\",\"N376SW\",\"N376UA\",\"N376US\",\"N377UA\",\"N378\",\"N378SW\",\"N378UA\",\"N379\",\"N379SW\",\"N379UA\",\"N380\",\"N380SW\",\"N380UA\",\"N381UA\",\"N382\",\"N382SW\",\"N382UA\",\"N383\",\"N383<0xE4E2>\",\"N383SW\",\"N383UA\",\"N383US\",\"N384\",\"N384<0xE4E2>\",\"N384SW\",\"N384UA\",\"N384US\",\"N385\",\"N385<0xE4E2>\",\"N385SW\",\"N385UA\",\"N385US\",\"N386\",\"N386SW\",\"N386UA\",\"N387\",\"N38727\",\"N387<0xE4E2>\",\"N387SW\",\"N387UA\",\"N387US\",\"N388\",\"N388SW\",\"N388UA\",\"N389\",\"N389<0xE4E2>\",\"N389SW\",\"N389UA\",\"N389US\",\"N390\",\"N390<0xE4E2>\",\"N390SW\",\"N390UA\",\"N390US\",\"N391\",\"N391<0xE4E2>\",\"N391SW\",\"N391UA\",\"N391US\",\"N392\",\"N392<0xE4E2>\",\"N392SW\",\"N392UA\",\"N392US\",\"N39340\",\"N39343\",\"N393<0xE4E2>\",\"N393UA\",\"N393US\",\"N394\",\"N394<0xE4E2>\",\"N394SW\",\"N394UA\",\"N394US\",\"N395\",\"N395<0xE4E2>\",\"N395SW\",\"N395UA\",\"N395US\",\"N396\",\"N396<0xE4E2>\",\"N396SW\",\"N396UA\",\"N396US\",\"N397\",\"N39726\",\"N397<0xE4E2>\",\"N397SW\",\"N397UA\",\"N397US\",\"N398\",\"N398SW\",\"N398UA\",\"N398US\",\"N399\",\"N399UA\",\"N399WN\",\"N400\",\"N400AA\",\"N400DA\",\"N400WN\",\"N401\",\"N401AA\",\"N401DA\",\"N401UA\",\"N401WN\",\"N402\",\"N402DA\",\"N402UA\",\"N402WN\",\"N403\",\"N403AA\",\"N403DA\",\"N403UA\",\"N403WN\",\"N404<0xE4E2>\",\"N404AA\",\"N404DA\",\"N404UA\",\"N404US\",\"N404WN\",\"N405\",\"N405<0xE4E2>\",\"N405AA\",\"N405DA\",\"N405EA\",\"N405UA\",\"N405US\",\"N405WN\",\"N406\",\"N406<0xE4E2>\",\"N406AA\",\"N406DA\",\"N406UA\",\"N406US\",\"N406WN\",\"N407\",\"N407<0xE4E2>\",\"N407AA\",\"N407DA\",\"N407UA\",\"N407US\",\"N407WN\",\"N408\",\"N408<0xE4E2>\",\"N408DA\",\"N408EA\",\"N408UA\",\"N408US\",\"N408WN\",\"N409\",\"N409<0xE4E2>\",\"N409AA\",\"N409DA\",\"N409UA\",\"N409US\",\"N409WN\",\"N410\",\"N410AA\",\"N410EA\",\"N410UA\",\"N410WN\",\"N411\",\"N411<0xE4E2>\",\"N411EA\",\"N411UA\",\"N411US\",\"N411WN\",\"N412\",\"N412<0xE4E2>\",\"N412AA\",\"N412EA\",\"N412UA\",\"N412US\",\"N412WN\",\"N413\",\"N413<0xE4E2>\",\"N413AA\",\"N413UA\",\"N413US\",\"N413WN\",\"N414\",\"N414AA\",\"N414UA\",\"N414WN\",\"N415\",\"N415<0xE4E2>\",\"N415AA\",\"N415UA\",\"N415US\",\"N415WN\",\"N416\",\"N416AA\",\"N416DA\",\"N416EA\",\"N416UA\",\"N416WN\",\"N417\",\"N417<0xE4E2>\",\"N417AA\",\"N417EA\",\"N417UA\",\"N417US\",\"N417WN\",\"N418\",\"N418<0xE4E2>\",\"N418AA\",\"N418DA\",\"N418EA\",\"N418UA\",\"N418US\",\"N418WN\",\"N419\",\"N419<0xE4E2>\",\"N419AA\",\"N419DA\",\"N419UA\",\"N419US\",\"N419WN\",\"N420\",\"N420<0xE4E2>\",\"N420AA\",\"N420DA\",\"N420UA\",\"N420US\",\"N420WN\",\"N421\",\"N421<0xE4E2>\",\"N421AA\",\"N421DA\",\"N421LV\",\"N421UA\",\"N421US\",\"N422\",\"N422<0xE4E2>\",\"N422AA\",\"N422UA\",\"N422US\",\"N422WN\",\"N423\",\"N423<0xE4E2>\",\"N423AA\",\"N423UA\",\"N423US\",\"N423WN\",\"N424\",\"N424<0xE4E2>\",\"N424UA\",\"N424US\",\"N424WN\",\"N425\",\"N425<0xE4E2>\",\"N425AA\",\"N425LV\",\"N425UA\",\"N425US\",\"N426\",\"N426<0xE4E2>\",\"N426AA\",\"N426UA\",\"N426US\",\"N426WN\",\"N427\",\"N427<0xE4E2>\",\"N427UA\",\"N427US\",\"N427WN\",\"N428\",\"N428<0xE4E2>\",\"N428AA\",\"N428UA\",\"N428US\",\"N428WN\",\"N429\",\"N429<0xE4E2>\",\"N429AA\",\"N429UA\",\"N429US\",\"N429WN\",\"N430\",\"N430<0xE4E2>\",\"N430AA\",\"N430UA\",\"N430US\",\"N430WN\",\"N431\",\"N431<0xE4E2>\",\"N431AA\",\"N431UA\",\"N431US\",\"N431WN\",\"N432\",\"N432<0xE4E2>\",\"N432UA\",\"N432US\",\"N432WN\",\"N433\",\"N433<0xE4E2>\",\"N433LV\",\"N433UA\",\"N433US\",\"N434\",\"N434<0xE4E2>\",\"N434AA\",\"N434UA\",\"N434US\",\"N434WN\",\"N435\",\"N435<0xE4E2>\",\"N435AA\",\"N435UA\",\"N435US\",\"N435WN\",\"N436\",\"N436<0xE4E2>\",\"N436UA\",\"N436US\",\"N436WN\",\"N437\",\"N437<0xE4E2>\",\"N437UA\",\"N437US\",\"N437WN\",\"N438\",\"N438<0xE4E2>\",\"N438UA\",\"N438US\",\"N438WN\",\"N439\",\"N439<0xE4E2>\",\"N439UA\",\"N439US\",\"N439WN\",\"N440\",\"N440<0xE4E2>\",\"N440AA\",\"N440LV\",\"N440UA\",\"N440US\",\"N441\",\"N441<0xE4E2>\",\"N441AA\",\"N441UA\",\"N441US\",\"N441WN\",\"N442\",\"N442<0xE4E2>\",\"N442UA\",\"N442US\",\"N442WN\",\"N443\",\"N443<0xE4E2>\",\"N443AA\",\"N443UA\",\"N443US\",\"N443WN\",\"N444\",\"N444<0xE4E2>\",\"N444AA\",\"N444UA\",\"N444US\",\"N444WN\",\"N445\",\"N445<0xE4E2>\",\"N445AA\",\"N445UA\",\"N445US\",\"N445WN\",\"N446\",\"N446<0xE4E2>\",\"N446AA\",\"N446UA\",\"N446US\",\"N446WN\",\"N447\",\"N447<0xE4E2>\",\"N447AA\",\"N447UA\",\"N447US\",\"N447WN\",\"N448\",\"N448<0xE4E2>\",\"N448AA\",\"N448UA\",\"N448US\",\"N448WN\",\"N449\",\"N449<0xE4E2>\",\"N449AA\",\"N449UA\",\"N449US\",\"N449WN\",\"N450\",\"N450AA\",\"N450UA\",\"N450WN\",\"N451\",\"N451AA\",\"N451UA\",\"N451WN\",\"N452\",\"N452AA\",\"N452UA\",\"N452WN\",\"N453AA\",\"N453UA\",\"N453WN\",\"N454\",\"N454UA\",\"N454WN\",\"N455\",\"N455AA\",\"N455UA\",\"N455WN\",\"N456\",\"N456AA\",\"N456UA\",\"N456WN\",\"N457\",\"N457AA\",\"N457UA\",\"N457WN\",\"N458\",\"N458AA\",\"N458UA\",\"N458WN\",\"N459\",\"N459AA\",\"N459UA\",\"N459WN\",\"N460\",\"N460AA\",\"N460UA\",\"N460WN\",\"N461\",\"N461AA\",\"N461UA\",\"N461WN\",\"N462\",\"N462AA\",\"N462UA\",\"N462WN\",\"N463AA\",\"N463UA\",\"N463WN\",\"N464\",\"N464AA\",\"N464UA\",\"N464WN\",\"N465\",\"N465UA\",\"N465WN\",\"N466\",\"N46625\",\"N466UA\",\"N466WN\",\"N467\",\"N467AA\",\"N467UA\",\"N467WN\",\"N468\",\"N468AA\",\"N468DA\",\"N468UA\",\"N468WN\",\"N469\",\"N469AA\",\"N469DA\",\"N469UA\",\"N469WN\",\"N470\",\"N470AA\",\"N470DA\",\"N470UA\",\"N470WN\",\"N471AA\",\"N471UA\",\"N472\",\"N472AA\",\"N472UA\",\"N472WN\",\"N473\",\"N47332\",\"N473AA\",\"N473UA\",\"N473WN\",\"N474\",\"N474AA\",\"N474UA\",\"N474WN\",\"N475\",\"N475AA\",\"N475DA\",\"N475UA\",\"N475WN\",\"N476\",\"N476AA\",\"N476DA\",\"N476UA\",\"N476WN\",\"N477\",\"N477AA\",\"N477DA\",\"N477UA\",\"N477WN\",\"N478\",\"N478AA\",\"N478DA\",\"N478UA\",\"N478WN\",\"N479\",\"N479AA\",\"N479UA\",\"N479WN\",\"N480\",\"N480AA\",\"N480UA\",\"N480WN\",\"N481AA\",\"N481UA\",\"N481WN\",\"N482\",\"N482AA\",\"N482DA\",\"N482UA\",\"N482WN\",\"N483\",\"N483AA\",\"N483DA\",\"N483UA\",\"N483WN\",\"N484\",\"N484AA\",\"N484DA\",\"N484UA\",\"N484WN\",\"N485\",\"N485AA\",\"N485DA\",\"N485UA\",\"N485WN\",\"N486\",\"N486AA\",\"N486UA\",\"N486WN\",\"N487\",\"N487AA\",\"N487UA\",\"N487WN\",\"N488\",\"N488AA\",\"N488UA\",\"N488WN\",\"N489\",\"N489AA\",\"N489DA\",\"N489UA\",\"N489WN\",\"N490\",\"N490DA\",\"N490UA\",\"N490WN\",\"N491\",\"N491AA\",\"N491SA\",\"N491UA\",\"N491WN\",\"N492\",\"N492AA\",\"N492DA\",\"N492UA\",\"N492WN\",\"N493\",\"N493DA\",\"N493UA\",\"N493WN\",\"N494\",\"N494AA\",\"N494DA\",\"N494UA\",\"N494WN\",\"N495\",\"N495AA\",\"N495DA\",\"N495UA\",\"N495WN\",\"N496\",\"N496AA\",\"N496UA\",\"N496WN\",\"N497\",\"N497AA\",\"N497DA\",\"N497UA\",\"N497WN\",\"N498\",\"N498AA\",\"N498DA\",\"N498UA\",\"N498WN\",\"N499\",\"N499AA\",\"N499DA\",\"N499WN\",\"N50\",\"N501\",\"N501AA\",\"N501AU\",\"N501DA\",\"N501SW\",\"N501UA\",\"N502\",\"N502AU\",\"N502SW\",\"N502UA\",\"N503\",\"N503AA\",\"N503AU\",\"N503SW\",\"N503UA\",\"N504\",\"N504A<0xE4>\",\"N504AA\",\"N504AU\",\"N504DA\",\"N504SW\",\"N504UA\",\"N505\",\"N505A<0xE4>\",\"N505AA\",\"N505AU\",\"N505DA\",\"N505UA\",\"N506\",\"N506A<0xE4>\",\"N506AA\",\"N506AU\",\"N506DA\",\"N506SW\",\"N506UA\",\"N507\",\"N507A<0xE4>\",\"N507AA\",\"N507AU\",\"N507DA\",\"N507SW\",\"N507UA\",\"N508\",\"N508A<0xE4>\",\"N508AA\",\"N508AU\",\"N508DA\",\"N508UA\",\"N509\",\"N509AA\",\"N509AU\",\"N509DA\",\"N509DC\",\"N509SW\",\"N509UA\",\"N51\",\"N510\",\"N510A<0xE4>\",\"N510AA\",\"N510AU\",\"N510DA\",\"N510UA\",\"N511\",\"N511A<0xE4>\",\"N511AA\",\"N511AU\",\"N511DA\",\"N511SW\",\"N511UA\",\"N512\",\"N512A<0xE4>\",\"N512AU\",\"N512DA\",\"N512SW\",\"N512UA\",\"N513\",\"N513DA\",\"N513SW\",\"N513UA\",\"N514\",\"N514A<0xE4>\",\"N514AA\",\"N514AU\",\"N514DA\",\"N514SW\",\"N514UA\",\"N515\",\"N515A<0xE4>\",\"N515AA\",\"N515AU\",\"N515DA\",\"N515SW\",\"N515UA\",\"N516A<0xE4>\",\"N516AA\",\"N516AU\",\"N516DA\",\"N516UA\",\"N517A<0xE4>\",\"N517AA\",\"N517AU\",\"N517DA\",\"N517UA\",\"N518A<0xE4>\",\"N518AU\",\"N518DA\",\"N518UA\",\"N519\",\"N519A<0xE4>\",\"N519AA\",\"N519AU\",\"N519DA\",\"N519SW\",\"N519UA\",\"N52\",\"N520\",\"N520A<0xE4>\",\"N520AA\",\"N520AU\",\"N520DA\",\"N520SW\",\"N520UA\",\"N521\",\"N521A<0xE4>\",\"N521AA\",\"N521AU\",\"N521DA\",\"N521SW\",\"N521UA\",\"N522\",\"N522A<0xE4>\",\"N522AA\",\"N522AU\",\"N522DA\",\"N522SW\",\"N522UA\",\"N523\",\"N52312\",\"N52313\",\"N523A<0xE4>\",\"N523AA\",\"N523AU\",\"N523DA\",\"N523SW\",\"N523UA\",\"N524\",\"N524A<0xE4>\",\"N524AA\",\"N524AU\",\"N524UA\",\"N525\",\"N525A<0xE4>\",\"N525AA\",\"N525AU\",\"N525DA\",\"N525SW\",\"N525UA\",\"N526\",\"N52616\",\"N526A<0xE4>\",\"N526AU\",\"N526DA\",\"N526UA\",\"N527\",\"N527A<0xE4>\",\"N527AA\",\"N527AU\",\"N527DA\",\"N527SW\",\"N527UA\",\"N528\",\"N528A<0xE4>\",\"N528AA\",\"N528AU\",\"N528DA\",\"N528SW\",\"N528UA\",\"N529A<0xE4>\",\"N529AA\",\"N529AU\",\"N529DA\",\"N529UA\",\"N53\",\"N530A<0xE4>\",\"N530AA\",\"N530AU\",\"N530UA\",\"N531A<0xE4>\",\"N531AA\",\"N531AU\",\"N531DA\",\"N531UA\",\"N532A<0xE4>\",\"N532AA\",\"N532AU\",\"N532DA\",\"N532UA\",\"N533A<0xE4>\",\"N533AA\",\"N533AU\",\"N533DA\",\"N533UA\",\"N534A<0xE4>\",\"N534AA\",\"N534AU\",\"N534DA\",\"N534UA\",\"N535AA\",\"N535DA\",\"N535UA\",\"N536AA\",\"N536DA\",\"N536UA\",\"N537AA\",\"N537DA\",\"N537UA\",\"N538AA\",\"N538DA\",\"N538UA\",\"N539AA\",\"N539DA\",\"N539UA\",\"N54\",\"N540AA\",\"N540DA\",\"N540UA\",\"N541AA\",\"N541DA\",\"N541UA\",\"N542AA\",\"N542DA\",\"N542UA\",\"N54325\",\"N54326\",\"N54327\",\"N54329\",\"N54333\",\"N54334\",\"N54335\",\"N54336\",\"N54338\",\"N54340\",\"N54341\",\"N54342\",\"N54344\",\"N54348\",\"N54349\",\"N54350\",\"N54351\",\"N54353\",\"N54354\",\"N543AA\",\"N543DA\",\"N543UA\",\"N544AA\",\"N544DA\",\"N545AA\",\"N545DA\",\"N545UA\",\"N546AA\",\"N546DA\",\"N546UA\",\"N54711\",\"N547AA\",\"N547UA\",\"N548AA\",\"N548UA\",\"N549AA\",\"N55\",\"N550AA\",\"N550UA\",\"N550WN\",\"N551AA\",\"N551UA\",\"N551WN\",\"N552AA\",\"N552UA\",\"N553AA\",\"N553UA\",\"N554UA\",\"N555AA\",\"N555UA\",\"N556AA\",\"N556UA\",\"N557AA\",\"N557UA\",\"N558A<0xE4>\",\"N558AA\",\"N558AU\",\"N558UA\",\"N559A<0xE4>\",\"N559AA\",\"N559AU\",\"N559UA\",\"N56\",\"N560A<0xE4>\",\"N560AU\",\"N560UA\",\"N561UA\",\"N562A<0xE4>\",\"N562AA\",\"N562AU\",\"N562UA\",\"N563<0xE4E2>\",\"N563UA\",\"N563US\",\"N564UA\",\"N565UA\",\"N566UA\",\"N567AA\",\"N567UA\",\"N568AA\",\"N568UA\",\"N569AA\",\"N569UA\",\"N57\",\"N570AA\",\"N570UA\",\"N571UA\",\"N572UA\",\"N573<0xE4E2>\",\"N573AA\",\"N573UA\",\"N573US\",\"N574<0xE4E2>\",\"N574AA\",\"N574UA\",\"N574US\",\"N575<0xE4E2>\",\"N575UA\",\"N575US\",\"N576<0xE4E2>\",\"N576AA\",\"N576UA\",\"N576US\",\"N577<0xE4E2>\",\"N577AA\",\"N577UA\",\"N577US\",\"N578UA\",\"N578US\",\"N579AA\",\"N579UA\",\"N579US\",\"N580AA\",\"N580UA\",\"N581AA\",\"N581UA\",\"N581US\",\"N582AA\",\"N582UA\",\"N582US\",\"N583UA\",\"N583US\",\"N584<0xE4E2>\",\"N584AA\",\"N584UA\",\"N584US\",\"N585<0xE4E2>\",\"N585AA\",\"N585UA\",\"N585US\",\"N586<0xE4E2>\",\"N586AA\",\"N586UA\",\"N586US\",\"N587<0xE4E2>\",\"N587AA\",\"N587UA\",\"N587US\",\"N588<0xE4E2>\",\"N588UA\",\"N588US\",\"N589<0xE4E2>\",\"N589UA\",\"N589US\",\"N59\",\"N590<0xE4E2>\",\"N590AA\",\"N590UA\",\"N590US\",\"N591<0xE4E2>\",\"N591US\",\"N592<0xE4E2>\",\"N592UA\",\"N592US\",\"N59338\",\"N593AA\",\"N593UA\",\"N594AA\",\"N594UA\",\"N595AA\",\"N595UA\",\"N596AA\",\"N596UA\",\"N597AA\",\"N599AA\",\"N5BRAA\",\"N5BSAA\",\"N5BTAA\",\"N5BVAA\",\"N5BWAA\",\"N5CAAA\",\"N5CCAA\",\"N5CDAA\",\"N5CFAA\",\"N5CGAA\",\"N5CHAA\",\"N5CKAA\",\"N5CLAA\",\"N5CMAA\",\"N5CXAA\",\"N5DEAA\",\"N5DHAA\",\"N5DJAA\",\"N5DMAA\",\"N5DNAA\",\"N5DRAA\",\"N5DSAA\",\"N5DTAA\",\"N5DVAA\",\"N5DXAA\",\"N5DYAA\",\"N5EAAA\",\"N5EDAA\",\"N5EFAA\",\"N5EGAA\",\"N5EHAA\",\"N5ELAA\",\"N60\",\"N600\",\"N600A<0xE4>\",\"N600AU\",\"N600WN\",\"N601\",\"N601A<0xE4>\",\"N601AU\",\"N601AW\",\"N601DL\",\"N601WN\",\"N602\",\"N602A<0xE4>\",\"N602AU\",\"N602SW\",\"N603\",\"N60312\",\"N603A<0xE4>\",\"N603AU\",\"N603AW\",\"N603DL\",\"N603SW\",\"N604\",\"N604A<0xE4>\",\"N604AU\",\"N604AW\",\"N604DL\",\"N604SW\",\"N605\",\"N605A<0xE4>\",\"N605AU\",\"N605AW\",\"N605DL\",\"N605SW\",\"N606\",\"N606A<0xE4>\",\"N606AU\",\"N606DL\",\"N606SW\",\"N607\",\"N607A<0xE4>\",\"N607AU\",\"N607DL\",\"N607SW\",\"N608\",\"N608A<0xE4>\",\"N608AU\",\"N608DA\",\"N608SW\",\"N609\",\"N609A<0xE4>\",\"N609AU\",\"N609DL\",\"N609SW\",\"N61\",\"N610\",\"N610A<0xE4>\",\"N610AU\",\"N610DL\",\"N610SW\",\"N610WN\",\"N611\",\"N611A<0xE4>\",\"N611AA\",\"N611AU\",\"N611DL\",\"N611SW\",\"N612\",\"N612A<0xE4>\",\"N612AU\",\"N612DL\",\"N612SW\",\"N613\",\"N613A<0xE4>\",\"N613AA\",\"N613AU\",\"N613DL\",\"N613SW\",\"N613UA\",\"N614\",\"N614A<0xE4>\",\"N614AA\",\"N614AU\",\"N614DL\",\"N614SW\",\"N615\",\"N615A<0xE4>\",\"N615AU\",\"N615DL\",\"N615SW\",\"N616\",\"N616A<0xE4>\",\"N616AA\",\"N616AU\",\"N616AW\",\"N616DL\",\"N616SW\",\"N617\",\"N617A<0xE4>\",\"N617AU\",\"N617DL\",\"N617SW\",\"N618\",\"N618A<0xE4>\",\"N618AU\",\"N618AW\",\"N618DL\",\"N618WN\",\"N619\",\"N619A<0xE4>\",\"N619AU\",\"N619AW\",\"N619DL\",\"N619SW\",\"N62\",\"N620\",\"N620A<0xE4>\",\"N620AU\",\"N620AW\",\"N620DL\",\"N620SW\",\"N621\",\"N621A<0xE4>\",\"N621AA\",\"N621AU\",\"N621AW\",\"N621DL\",\"N621SW\",\"N622\",\"N622A<0xE4>\",\"N622AA\",\"N622AU\",\"N622AW\",\"N622DL\",\"N622SW\",\"N623\",\"N623A<0xE4>\",\"N623AA\",\"N623AU\",\"N623DL\",\"N623SW\",\"N624\",\"N624A<0xE4>\",\"N624AU\",\"N624AW\",\"N624DL\",\"N624SW\",\"N625\",\"N625A<0xE4>\",\"N625AU\",\"N625AW\",\"N625DL\",\"N625SW\",\"N626\",\"N626A<0xE4>\",\"N626AU\",\"N626AW\",\"N626DL\",\"N626SW\",\"N627\",\"N627A<0xE4>\",\"N627AA\",\"N627AU\",\"N627AW\",\"N627DL\",\"N627SW\",\"N628\",\"N628A<0xE4>\",\"N628AU\",\"N628AW\",\"N628DL\",\"N628SW\",\"N629\",\"N629A<0xE4>\",\"N629AU\",\"N629AW\",\"N629DL\",\"N629SW\",\"N63\",\"N630\",\"N630A<0xE4>\",\"N630AA\",\"N630AU\",\"N630DL\",\"N630WN\",\"N631\",\"N631A<0xE4>\",\"N631AU\",\"N631AW\",\"N631DL\",\"N631SW\",\"N632\",\"N632A<0xE4>\",\"N632AU\",\"N632AW\",\"N632DL\",\"N632SW\",\"N633\",\"N63305\",\"N633A<0xE4>\",\"N633AU\",\"N633AW\",\"N633DL\",\"N633SW\",\"N634\",\"N634AW\",\"N634DL\",\"N634SW\",\"N635\",\"N635AW\",\"N635DL\",\"N635SW\",\"N636\",\"N636AW\",\"N636DL\",\"N636WN\",\"N637\",\"N637AW\",\"N637DL\",\"N637SW\",\"N638\",\"N638AW\",\"N638DL\",\"N638SW\",\"N639\",\"N639AW\",\"N639DL\",\"N639SW\",\"N64\",\"N640\",\"N640AW\",\"N640DL\",\"N640SW\",\"N641\",\"N641AA\",\"N641AW\",\"N641DL\",\"N641SW\",\"N642\",\"N642AW\",\"N642DL\",\"N642UA\",\"N642WN\",\"N643\",\"N64315\",\"N64319\",\"N64320\",\"N64322\",\"N64347\",\"N643AW\",\"N643SW\",\"N644\",\"N644AW\",\"N644DL\",\"N645\",\"N645AW\",\"N645DL\",\"N645SW\",\"N645US\",\"N646\",\"N646AW\",\"N646DL\",\"N646SW\",\"N646US\",\"N647\",\"N647AW\",\"N647DL\",\"N647SW\",\"N648\",\"N648AW\",\"N648DL\",\"N648SW\",\"N648UA\",\"N648US\",\"N649\",\"N649AW\",\"N649DL\",\"N649SW\",\"N649US\",\"N650\",\"N650AW\",\"N650DL\",\"N650SW\",\"N651\",\"N651AW\",\"N651DL\",\"N651SW\",\"N651US\",\"N652\",\"N652AW\",\"N652DL\",\"N652SW\",\"N652US\",\"N653\",\"N653AW\",\"N653DL\",\"N653SW\",\"N654\",\"N654AW\",\"N654DL\",\"N654SW\",\"N655\",\"N655AW\",\"N655DL\",\"N655US\",\"N655WN\",\"N656AW\",\"N656DL\",\"N656SW\",\"N656US\",\"N657AW\",\"N657DL\",\"N657SW\",\"N658\",\"N658AW\",\"N658DL\",\"N658SW\",\"N659\",\"N659AW\",\"N659DL\",\"N659SW\",\"N660\",\"N660AW\",\"N660DL\",\"N660SW\",\"N661\",\"N661AW\",\"N661SW\",\"N662\",\"N662AW\",\"N662DN\",\"N662SW\",\"N662UA\",\"N663\",\"N663AW\",\"N663DN\",\"N663SW\",\"N664\",\"N664DN\",\"N664UA\",\"N664WN\",\"N665\",\"N665AW\",\"N665DN\",\"N665WN\",\"N666DN\",\"N667\",\"N667AW\",\"N667DN\",\"N667SW\",\"N668\",\"N668AW\",\"N668DN\",\"N669\",\"N669AW\",\"N669DN\",\"N669SW\",\"N67\",\"N670\",\"N6700\",\"N6702\",\"N670DN\",\"N670SW\",\"N670UA\",\"N671\",\"N671DN\",\"N671SW\",\"N672\",\"N672AW\",\"N672DL\",\"N672SW\",\"N672UA\",\"N673\",\"N673AA\",\"N673AW\",\"N673DL\",\"N673UA\",\"N674\",\"N674AA\",\"N674AW\",\"N674DL\",\"N674UA\",\"N675\",\"N675AA\",\"N675AW\",\"N675DL\",\"N676\",\"N676AW\",\"N676DL\",\"N676SW\",\"N677\",\"N677AA\",\"N677AW\",\"N677DL\",\"N678\",\"N678AA\",\"N678AW\",\"N678DL\",\"N679\",\"N679AA\",\"N679AW\",\"N679DA\",\"N68\",\"N680\",\"N680AA\",\"N680AW\",\"N680DA\",\"N681DA\",\"N682\",\"N682DA\",\"N682SW\",\"N683\",\"N683DA\",\"N683SW\",\"N684\",\"N684DA\",\"N684WN\",\"N685\",\"N685DA\",\"N685SW\",\"N686\",\"N686DA\",\"N686SW\",\"N687\",\"N687DL\",\"N687SW\",\"N688\",\"N688DL\",\"N688SW\",\"N689\",\"N689SW\",\"N690\",\"N690DL\",\"N690SW\",\"N691\",\"N691WN\",\"N692\",\"N692DL\",\"N692SW\",\"N693\",\"N69311\",\"N693DL\",\"N693SW\",\"N694\",\"N694DA\",\"N694SW\",\"N695\",\"N695SW\",\"N696\",\"N696SW\",\"N697\",\"N697DL\",\"N697SW\",\"N698\",\"N698DL\",\"N698SW\",\"N699\",\"N699SW\",\"N700\",\"N700<0xE4E6>\",\"N700GS\",\"N700UW\",\"N701\",\"N701<0xE4E6>\",\"N701AA\",\"N701GS\",\"N701UW\",\"N702\",\"N702<0xE4E6>\",\"N702AA\",\"N702UW\",\"N703\",\"N703<0xE4E6>\",\"N703AA\",\"N703SW\",\"N703UW\",\"N704\",\"N704<0xE4E6>\",\"N704SW\",\"N704UW\",\"N705\",\"N705<0xE4E6>\",\"N705AA\",\"N705SW\",\"N705UW\",\"N706\",\"N706<0xE4E6>\",\"N706AA\",\"N706SW\",\"N706UW\",\"N707\",\"N707<0xE4E6>\",\"N707AA\",\"N707SA\",\"N707UW\",\"N708\",\"N708<0xE4E6>\",\"N708AA\",\"N708SA\",\"N708UW\",\"N709\",\"N709<0xE4E6>\",\"N709AA\",\"N709SW\",\"N709UW\",\"N71\",\"N710\",\"N710<0xE4E6>\",\"N710AA\",\"N710SW\",\"N710UW\",\"N711\",\"N711<0xE4E6>\",\"N711HK\",\"N711UW\",\"N712\",\"N712<0xE4E6>\",\"N712AA\",\"N712SW\",\"N712UW\",\"N713\",\"N713<0xE4E6>\",\"N713AA\",\"N713SW\",\"N713UW\",\"N714\",\"N714<0xE4E6>\",\"N714CB\",\"N714UW\",\"N715\",\"N715<0xE4E6>\",\"N715AA\",\"N715SW\",\"N715UW\",\"N716\",\"N716<0xE4E6>\",\"N716SW\",\"N716UW\",\"N717\",\"N717<0xE4E6>\",\"N717SA\",\"N717UW\",\"N718\",\"N718<0xE4E6>\",\"N718SW\",\"N718UW\",\"N719\",\"N719<0xE4E6>\",\"N719SW\",\"N719UW\",\"N720\",\"N720<0xE4E6>\",\"N720WN\",\"N721\",\"N721<0xE4E6>\",\"N721UW\",\"N722\",\"N722<0xE4E6>\",\"N722UW\",\"N723\",\"N723<0xE4E6>\",\"N723AA\",\"N723SW\",\"N723UW\",\"N724\",\"N724<0xE4E6>\",\"N724SW\",\"N724UW\",\"N725\",\"N7251U\",\"N7252U\",\"N7253U\",\"N7254U\",\"N7255U\",\"N7256U\",\"N7257U\",\"N7258U\",\"N7259U\",\"N725<0xE4E6>\",\"N725SW\",\"N725UW\",\"N726\",\"N7260U\",\"N7261U\",\"N7262U\",\"N7263U\",\"N7264U\",\"N7265U\",\"N7266U\",\"N7267U\",\"N7268U\",\"N7269U\",\"N726<0xE4E6>\",\"N726SW\",\"N727\",\"N7270U\",\"N7271U\",\"N7272U\",\"N7273U\",\"N7274U\",\"N7275U\",\"N7276U\",\"N7277U\",\"N7278U\",\"N7279U\",\"N727<0xE4E6>\",\"N727SW\",\"N728\",\"N7280U\",\"N7281U\",\"N7282U\",\"N7283U\",\"N7284U\",\"N7285U\",\"N7286U\",\"N7287U\",\"N7288U\",\"N7289U\",\"N728<0xE4E6>\",\"N728SW\",\"N728UW\",\"N729\",\"N7290U\",\"N7291U\",\"N7292U\",\"N7293U\",\"N7294U\",\"N7295U\",\"N7297U\",\"N7298U\",\"N7299U\",\"N729<0xE4E6>\",\"N729SW\",\"N73\",\"N730\",\"N730<0xE4E6>\",\"N730AA\",\"N730MA\",\"N730SW\",\"N730UW\",\"N731\",\"N731AA\",\"N731SA\",\"N732\",\"N732<0xE4E6>\",\"N732SW\",\"N732UW\",\"N733\",\"N73380\",\"N733<0xE4E6>\",\"N733SA\",\"N733SW\",\"N733UW\",\"N734\",\"N734SA\",\"N734SW\",\"N735\",\"N735SA\",\"N736\",\"N736<0xE4E6>\",\"N736SA\",\"N737\",\"N737<0xE4E6>\",\"N737JW\",\"N737UW\",\"N738\",\"N738<0xE4E6>\",\"N738CB\",\"N738UW\",\"N739\",\"N739<0xE4E6>\",\"N739GB\",\"N74\",\"N740\",\"N740<0xE4E6>\",\"N740SW\",\"N740UW\",\"N741\",\"N741<0xE4E6>\",\"N741SA\",\"N741UW\",\"N742\",\"N742<0xE4E6>\",\"N742SW\",\"N742UW\",\"N743\",\"N743<0xE4E6>\",\"N743SW\",\"N744\",\"N7441U\",\"N7442U\",\"N7443U\",\"N7444U\",\"N7445U\",\"N7446U\",\"N7447U\",\"N7448U\",\"N7449U\",\"N744<0xE4E6>\",\"N744SW\",\"N744UW\",\"N745\",\"N7450U\",\"N7451U\",\"N7452U\",\"N7453U\",\"N7454U\",\"N7455U\",\"N7456U\",\"N7458U\",\"N7459U\",\"N745<0xE4E6>\",\"N745SW\",\"N745UW\",\"N746\",\"N7460U\",\"N7461U\",\"N7462U\",\"N7463U\",\"N7464U\",\"N7465U\",\"N7466U\",\"N7467U\",\"N746<0xE4E6>\",\"N746SW\",\"N746UW\",\"N747\",\"N747<0xE4E6>\",\"N747SA\",\"N747UW\",\"N748\",\"N748<0xE4E6>\",\"N748SW\",\"N748UW\",\"N749\",\"N749<0xE4E6>\",\"N749SW\",\"N749UW\",\"N750\",\"N750AT\",\"N750SA\",\"N750UW\",\"N751\",\"N751AT\",\"N751SW\",\"N751UW\",\"N752\",\"N752SW\",\"N752UW\",\"N753\",\"N753SW\",\"N753UW\",\"N754\",\"N754SW\",\"N754UW\",\"N755\",\"N755SA\",\"N755UW\",\"N756\",\"N756SA\",\"N756UW\",\"N757\",\"N757AT\",\"N757LV\",\"N757UW\",\"N758\",\"N758<0xE4E6>\",\"N758SW\",\"N758UW\",\"N759\",\"N759GS\",\"N760\",\"N760<0xE4E6>\",\"N760UW\",\"N761\",\"N761RR\",\"N762\",\"N762<0xE4E6>\",\"N762SW\",\"N762UW\",\"N763\",\"N763<0xE4E6>\",\"N763SW\",\"N763UW\",\"N764<0xE4E6>\",\"N764SW\",\"N764UW\",\"N765\",\"N765<0xE4E6>\",\"N765SW\",\"N765UW\",\"N766\",\"N766<0xE4E6>\",\"N766SW\",\"N766UW\",\"N767\",\"N767<0xE4E6>\",\"N767SW\",\"N767UW\",\"N768\",\"N768<0xE4E6>\",\"N768SW\",\"N768UW\",\"N769\",\"N769<0xE4E6>\",\"N769SW\",\"N769UW\",\"N770\",\"N770<0xE4E6>\",\"N770SA\",\"N770UW\",\"N771\",\"N771SA\",\"N772\",\"N772SW\",\"N772UA\",\"N773\",\"N77303\",\"N773SA\",\"N774\",\"N774SW\",\"N774UA\",\"N775\",\"N775A<0xE4>\",\"N775AU\",\"N775SW\",\"N776\",\"N776A<0xE4>\",\"N776AU\",\"N776WN\",\"N777\",\"N777A<0xE4>\",\"N777AU\",\"N777QC\",\"N778\",\"N778A<0xE4>\",\"N778AU\",\"N778SW\",\"N779\",\"N779A<0xE4>\",\"N779AU\",\"N779SW\",\"N780\",\"N780A<0xE4>\",\"N780AU\",\"N780SW\",\"N781\",\"N781A<0xE4>\",\"N781AU\",\"N781WN\",\"N782\",\"N782A<0xE4>\",\"N782AU\",\"N782SA\",\"N783\",\"N783A<0xE4>\",\"N783AU\",\"N783SW\",\"N784\",\"N784A<0xE4>\",\"N784AU\",\"N784SW\",\"N785\",\"N785A<0xE4>\",\"N785AU\",\"N785SW\",\"N786\",\"N786SW\",\"N787\",\"N787SA\",\"N787UA\",\"N788\",\"N788SA\",\"N789\",\"N789SW\",\"N790\",\"N790SW\",\"N791SW\",\"N792\",\"N792SW\",\"N792UA\",\"N793\",\"N793SA\",\"N793UA\",\"N794\",\"N794SW\",\"N795\",\"N795SW\",\"N796\",\"N796SW\",\"N797\",\"N797MX\",\"N798\",\"N798SW\",\"N799\",\"N799SW\",\"N80\",\"N800<0xE4E2>\",\"N800US\",\"N801<0xE4E2>\",\"N801AW\",\"N801MA\",\"N801UA\",\"N801US\",\"N802<0xE4E2>\",\"N802AW\",\"N802MD\",\"N802UA\",\"N802US\",\"N803<0xE4E2>\",\"N803AW\",\"N803UA\",\"N803US\",\"N804<0xE4E2>\",\"N804AW\",\"N804MD\",\"N804UA\",\"N804US\",\"N805<0xE4E2>\",\"N805AW\",\"N805EA\",\"N805UA\",\"N805US\",\"N806<0xE4E2>\",\"N806AW\",\"N806UA\",\"N806US\",\"N807AW\",\"N807MD\",\"N807UA\",\"N807US\",\"N808<0xE4E2>\",\"N808AW\",\"N808MD\",\"N808UA\",\"N808US\",\"N809<0xE4E2>\",\"N809AW\",\"N809UA\",\"N809US\",\"N81\",\"N810<0xE4E2>\",\"N810AW\",\"N810UA\",\"N810US\",\"N811<0xE4E2>\",\"N811MD\",\"N811UA\",\"N811US\",\"N812<0xE4E2>\",\"N812AW\",\"N812MD\",\"N812UA\",\"N812US\",\"N813<0xE4E2>\",\"N813AW\",\"N813MA\",\"N813UA\",\"N813US\",\"N814<0xE4E2>\",\"N814AW\",\"N814MD\",\"N814UA\",\"N814US\",\"N815<0xE4E2>\",\"N815AW\",\"N815UA\",\"N815US\",\"N816<0xE4E2>\",\"N816MA\",\"N816UA\",\"N817<0xE4E2>\",\"N817AW\",\"N817MD\",\"N817UA\",\"N817US\",\"N818<0xE4E2>\",\"N818AA\",\"N818AW\",\"N818MD\",\"N818UA\",\"N818US\",\"N819<0xE4E2>\",\"N819AW\",\"N819MD\",\"N819UA\",\"N819US\",\"N82\",\"N820<0xE4E2>\",\"N820AW\",\"N820MD\",\"N820UA\",\"N820US\",\"N821<0xE4E2>\",\"N821AW\",\"N821MD\",\"N821UA\",\"N821US\",\"N822<0xE4E2>\",\"N822AW\",\"N822MD\",\"N822UA\",\"N822US\",\"N823<0xE4E2>\",\"N823AW\",\"N823UA\",\"N823US\",\"N824<0xE4E2>\",\"N824AW\",\"N824UA\",\"N824US\",\"N825<0xE4E2>\",\"N825AW\",\"N825UA\",\"N825US\",\"N826<0xE4E2>\",\"N826AW\",\"N826MD\",\"N826UA\",\"N826US\",\"N827<0xE4E2>\",\"N827AW\",\"N827UA\",\"N827US\",\"N828<0xE4E2>\",\"N828AW\",\"N828UA\",\"N828US\",\"N829<0xE4E2>\",\"N829AW\",\"N829UA\",\"N829US\",\"N830<0xE4E2>\",\"N830AW\",\"N830UA\",\"N830US\",\"N830WA\",\"N831AW\",\"N831L\",\"N831UA\",\"N831WA\",\"N832AW\",\"N832UA\",\"N833AW\",\"N833UA\",\"N834AW\",\"N834UA\",\"N835AW\",\"N835UA\",\"N836UA\",\"N837AW\",\"N837UA\",\"N838UA\",\"N839UA\",\"N840UA\",\"N841UA\",\"N842UA\",\"N84355\",\"N843UA\",\"N844UA\",\"N845UA\",\"N846UA\",\"N847UA\",\"N848UA\",\"N849UA\",\"N85\",\"N850<0xE4E2>\",\"N850UA\",\"N850US\",\"N851<0xE4E2>\",\"N851UA\",\"N851US\",\"N852<0xE4E2>\",\"N852UA\",\"N852US\",\"N853<0xE4E2>\",\"N853UA\",\"N853US\",\"N854<0xE4E2>\",\"N854UA\",\"N854US\",\"N855<0xE4E2>\",\"N855UA\",\"N855US\",\"N856<0xE4E2>\",\"N856US\",\"N857<0xE4E2>\",\"N857US\",\"N858<0xE4E2>\",\"N858US\",\"N859<0xE4E2>\",\"N859US\",\"N86\",\"N860<0xE4E2>\",\"N860US\",\"N861<0xE4E2>\",\"N861US\",\"N862<0xE4E2>\",\"N862AA\",\"N862US\",\"N863<0xE4E2>\",\"N863US\",\"N864<0xE4E2>\",\"N864US\",\"N865<0xE4E2>\",\"N865US\",\"N866<0xE4E2>\",\"N866US\",\"N867<0xE4E2>\",\"N867AA\",\"N867US\",\"N868<0xE4E2>\",\"N868AA\",\"N868US\",\"N869<0xE4E2>\",\"N869AA\",\"N869US\",\"N87\",\"N873AA\",\"N877AA\",\"N878AA\",\"N880<0xE4E2>\",\"N880AA\",\"N880US\",\"N881<0xE4E2>\",\"N881US\",\"N882<0xE4E2>\",\"N882US\",\"N883<0xE4E2>\",\"N883US\",\"N884<0xE4E2>\",\"N884US\",\"N885<0xE4E2>\",\"N885AA\",\"N885US\",\"N886<0xE4E2>\",\"N886US\",\"N8873Z\",\"N8875Z\",\"N887<0xE4E2>\",\"N887US\",\"N8882Z\",\"N8889Z\",\"N888A<0xE4>\",\"N888AU\",\"N8891Z\",\"N889<0xE4E2>\",\"N889US\",\"N89\",\"N890<0xE4E2>\",\"N890AA\",\"N890US\",\"N891<0xE4E2>\",\"N891AA\",\"N891US\",\"N892<0xE4E2>\",\"N892AA\",\"N892US\",\"N893<0xE4E2>\",\"N893AA\",\"N893US\",\"N894<0xE4E2>\",\"N894AA\",\"N894US\",\"N895<0xE4E2>\",\"N895AA\",\"N895US\",\"N896<0xE4E2>\",\"N896AA\",\"N896US\",\"N897<0xE4E2>\",\"N897AA\",\"N897US\",\"N898<0xE4E2>\",\"N898AA\",\"N898US\",\"N899<0xE4E2>\",\"N899AA\",\"N899US\",\"N90\",\"N9003U\",\"N9007U\",\"N9009U\",\"N900DE\",\"N900PC\",\"N900WN\",\"N9010U\",\"N9013U\",\"N901AW\",\"N901DL\",\"N901TW\",\"N901UA\",\"N901WN\",\"N9022U\",\"N9024U\",\"N9027U\",\"N902AW\",\"N902DL\",\"N902TW\",\"N902UA\",\"N902WN\",\"N9030U\",\"N9032U\",\"N9039U\",\"N903AW\",\"N903DE\",\"N903TW\",\"N903UA\",\"N9040U\",\"N904AW\",\"N904DE\",\"N904TW\",\"N904UA\",\"N9051U\",\"N9053U\",\"N905AW\",\"N905DE\",\"N905DL\",\"N905TW\",\"N905UA\",\"N9060U\",\"N9063U\",\"N9065U\",\"N9067U\",\"N9068U\",\"N9069U\",\"N906AW\",\"N906DL\",\"N906TW\",\"N906UA\",\"N9072U\",\"N907AW\",\"N907TW\",\"N907UA\",\"N908AW\",\"N908DE\",\"N908DL\",\"N908TW\",\"N908UA\",\"N909AW\",\"N909DE\",\"N909TW\",\"N909UA\",\"N91\",\"N910AW\",\"N910DE\",\"N910DL\",\"N910UA\",\"N911DE\",\"N911DL\",\"N911TW\",\"N911UA\",\"N912DE\",\"N912TW\",\"N912UA\",\"N912VJ\",\"N913AW\",\"N913DE\",\"N913DL\",\"N913TW\",\"N913UA\",\"N913VJ\",\"N914AW\",\"N914DE\",\"N914DL\",\"N914TW\",\"N914UA\",\"N914VJ\",\"N915AW\",\"N915DE\",\"N915DL\",\"N915TW\",\"N915UA\",\"N916AW\",\"N916DE\",\"N916DL\",\"N916TW\",\"N916UA\",\"N916VJ\",\"N917DE\",\"N917DL\",\"N917TW\",\"N917UA\",\"N918DE\",\"N918DL\",\"N918TW\",\"N918UA\",\"N918VJ\",\"N919DE\",\"N919DL\",\"N919TW\",\"N919UA\",\"N919VJ\",\"N92\",\"N920DL\",\"N920TW\",\"N920UA\",\"N920VJ\",\"N921DL\",\"N921L\",\"N921UA\",\"N921VJ\",\"N922L\",\"N922TW\",\"N922UA\",\"N922VJ\",\"N923DL\",\"N923L\",\"N923TW\",\"N923UA\",\"N923VJ\",\"N924DL\",\"N924UA\",\"N924VJ\",\"N925DL\",\"N925L\",\"N925TW\",\"N925UA\",\"N925VJ\",\"N926TW\",\"N926UA\",\"N926VJ\",\"N927DA\",\"N927L\",\"N927TW\",\"N927UA\",\"N927VJ\",\"N928DL\",\"N928L\",\"N928TW\",\"N928UA\",\"N928VJ\",\"N929DL\",\"N929L\",\"N929TW\",\"N929UA\",\"N929VJ\",\"N93\",\"N9302B\",\"N9303K\",\"N9304C\",\"N9305N\",\"N9306T\",\"N9307R\",\"N930DL\",\"N930UA\",\"N930VJ\",\"N931DL\",\"N931L\",\"N931UA\",\"N931VJ\",\"N932DL\",\"N932UA\",\"N932VJ\",\"N933L\",\"N933UA\",\"N933VJ\",\"N934L\",\"N934UA\",\"N934VJ\",\"N935DL\",\"N935UA\",\"N935VJ\",\"N936DL\",\"N936L\",\"N936UA\",\"N936VJ\",\"N937DL\",\"N937F\",\"N937UA\",\"N937VJ\",\"N938DL\",\"N938UA\",\"N938VJ\",\"N939DL\",\"N939UA\",\"N939VJ\",\"N94\",\"N9401W\",\"N9402W\",\"N9403W\",\"N9404V\",\"N9405T\",\"N9406W\",\"N9407R\",\"N9409F\",\"N940AS\",\"N940DL\",\"N940UA\",\"N9412W\",\"N9413T\",\"N9414W\",\"N941DL\",\"N941UA\",\"N9420D\",\"N942DL\",\"N942UA\",\"N942VJ\",\"N94314\",\"N943DL\",\"N943UA\",\"N943VJ\",\"N944DL\",\"N944UA\",\"N945UA\",\"N945VJ\",\"N946UA\",\"N947DL\",\"N947UA\",\"N948DL\",\"N948UA\",\"N949DL\",\"N949UA\",\"N95\",\"N950DL\",\"N950UA\",\"N951DL\",\"N951U\",\"N951UA\",\"N951VJ\",\"N952DL\",\"N952U\",\"N952UA\",\"N952VJ\",\"N953DL\",\"N953U\",\"N953UA\",\"N953VJ\",\"N954DL\",\"N954U\",\"N954UA\",\"N955DL\",\"N955U\",\"N955UA\",\"N955VJ\",\"N956DL\",\"N956U\",\"N956UA\",\"N957DL\",\"N957U\",\"N957UA\",\"N958DL\",\"N958U\",\"N958VJ\",\"N959DL\",\"N959U\",\"N959VJ\",\"N96\",\"N960TW\",\"N960VJ\",\"N9615W\",\"N9617R\",\"N9618A\",\"N9619V\",\"N9620D\",\"N9622A\",\"N9624T\",\"N9626F\",\"N9627R\",\"N962DL\",\"N9630A\",\"N963DL\",\"N963VJ\",\"N964DL\",\"N965DL\",\"N965VJ\",\"N966DL\",\"N966VJ\",\"N967DL\",\"N967VJ\",\"N968DL\",\"N968VJ\",\"N969DL\",\"N969VJ\",\"N970DL\",\"N970VJ\",\"N971VJ\",\"N972VJ\",\"N973DL\",\"N973VJ\",\"N974DL\",\"N974UA\",\"N974VJ\",\"N975DL\",\"N975VJ\",\"N976DL\",\"N976VJ\",\"N976Z\",\"N977DL\",\"N977UA\",\"N977VJ\",\"N978AS\",\"N978DL\",\"N978UA\",\"N978VJ\",\"N978Z\",\"N979DL\",\"N979UA\",\"N979VJ\",\"N979Z\",\"N980UA\",\"N980VJ\",\"N980Z\",\"N981DL\",\"N981UA\",\"N981US\",\"N981Z\",\"N982DL\",\"N982PS\",\"N982UA\",\"N982VJ\",\"N983DL\",\"N983UA\",\"N983VJ\",\"N983Z\",\"N984DL\",\"N984UA\",\"N984VJ\",\"N984Z\",\"N985DL\",\"N985VJ\",\"N985Z\",\"N986DL\",\"N987UA\",\"N987VJ\",\"N988DL\",\"N989DL\",\"N989UA\",\"N989VJ\",\"N989Z\",\"N990DL\",\"N990Z\",\"N991DL\",\"N991VJ\",\"N991Z\",\"N992DL\",\"N992Z\",\"N993DL\",\"N993UA\",\"N993VJ\",\"N994DL\",\"N994UA\",\"N995DL\",\"N995UA\",\"N995VJ\",\"N996DL\",\"N996VJ\",\"N996Z\",\"N997DL\",\"N997UA\",\"N997VJ\",\"N998DL\",\"N998UA\",\"N999DN\",\"NA\",\"UNKNOW\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ ActualElapsedTime :  num 91 94 97 78 84 91 84 82 89 98\n",
      "$ CRSElapsedTime    :  num 79 79 79 79 79 79 79 79 79 90\n",
      "$ AirTime           :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ ArrDelay          :  num 23 14 29 -2 3 13 19 2 15 24\n",
      "$ DepDelay          :  num 11 -1 11 -1 -2 1 14 -1 5 16\n",
      "$ Origin            :  Factor w/ 132 level(s) \"ABE\",\"ABQ\",\"ACY\",\"ALB\",\"AMA\",\"ANC\",\"ATL\",\"AUS\",\"AVP\",\"BDL\",\"BGM\",\"BHM\",\"BIL\",\"BNA\",\"BOI\",\"BOS\",\"BTV\",\"BUF\",\"BUR\",\"BWI\",\"CAE\",\"CHO\",\"CHS\",\"CLE\",\"CLT\",\"CMH\",\"COS\",\"CRP\",\"CRW\",\"CVG\",\"DAL\",\"DAY\",\"DCA\",\"DEN\",\"DFW\",\"DSM\",\"DTW\",\"EGE\",\"ELP\",\"ERI\",\"EWR\",\"EYW\",\"FLL\",\"GEG\",\"GNV\",\"GRR\",\"GSO\",\"HNL\",\"HOU\",\"HPN\",\"HRL\",\"IAD\",\"IAH\",\"ICT\",\"IND\",\"ISP\",\"JAN\",\"JAX\",\"JFK\",\"KOA\",\"LAN\",\"LAS\",\"LAX\",\"LBB\",\"LEX\",\"LGA\",\"LIH\",\"LIT\",\"LYH\",\"MAF\",\"MCI\",\"MCO\",\"MDT\",\"MDW\",\"MEM\",\"MFR\",\"MHT\",\"MIA\",\"MKE\",\"MLB\",\"MRY\",\"MSP\",\"MSY\",\"MYR\",\"OAK\",\"OGG\",\"OKC\",\"OMA\",\"ONT\",\"ORD\",\"ORF\",\"PBI\",\"PDX\",\"PHF\",\"PHL\",\"PHX\",\"PIT\",\"PSP\",\"PVD\",\"PWM\",\"RDU\",\"RIC\",\"RNO\",\"ROA\",\"ROC\",\"RSW\",\"SAN\",\"SAT\",\"SAV\",\"SBN\",\"SCK\",\"SDF\",\"SEA\",\"SFO\",\"SJC\",\"SJU\",\"SLC\",\"SMF\",\"SNA\",\"SRQ\",\"STL\",\"STT\",\"STX\",\"SWF\",\"SYR\",\"TLH\",\"TPA\",\"TRI\",\"TUL\",\"TUS\",\"TYS\",\"UCA\" \n",
      "$ Dest              :  Factor w/ 134 level(s) \"ABE\",\"ABQ\",\"ACY\",\"ALB\",\"AMA\",\"ANC\",\"ATL\",\"AUS\",\"AVL\",\"AVP\",\"BDL\",\"BGM\",\"BHM\",\"BNA\",\"BOI\",\"BOS\",\"BTV\",\"BUF\",\"BUR\",\"BWI\",\"CAE\",\"CAK\",\"CHA\",\"CHO\",\"CHS\",\"CLE\",\"CLT\",\"CMH\",\"COS\",\"CRP\",\"CVG\",\"DAL\",\"DAY\",\"DCA\",\"DEN\",\"DFW\",\"DSM\",\"DTW\",\"ELM\",\"ELP\",\"ERI\",\"EUG\",\"EWR\",\"EYW\",\"FAT\",\"FAY\",\"FLL\",\"FNT\",\"GEG\",\"GRR\",\"GSO\",\"GSP\",\"HNL\",\"HOU\",\"HPN\",\"HRL\",\"HTS\",\"IAD\",\"IAH\",\"ICT\",\"ILM\",\"IND\",\"ISP\",\"JAN\",\"JAX\",\"JFK\",\"KOA\",\"LAS\",\"LAX\",\"LBB\",\"LEX\",\"LGA\",\"LIH\",\"LIT\",\"LYH\",\"MAF\",\"MCI\",\"MCO\",\"MDT\",\"MDW\",\"MHT\",\"MIA\",\"MKE\",\"MRY\",\"MSP\",\"MSY\",\"MYR\",\"OAJ\",\"OAK\",\"OGG\",\"OKC\",\"OMA\",\"ONT\",\"ORD\",\"ORF\",\"ORH\",\"PBI\",\"PDX\",\"PHF\",\"PHL\",\"PHX\",\"PIT\",\"PNS\",\"PSP\",\"PVD\",\"PWM\",\"RDU\",\"RIC\",\"RNO\",\"ROA\",\"ROC\",\"RSW\",\"SAN\",\"SAT\",\"SBN\",\"SCK\",\"SDF\",\"SEA\",\"SFO\",\"SJC\",\"SJU\",\"SLC\",\"SMF\",\"SNA\",\"SRQ\",\"STL\",\"STT\",\"SWF\",\"SYR\",\"TOL\",\"TPA\",\"TUL\",\"TUS\",\"UCA\" \n",
      "$ Distance          :  num 447 447 447 447 447 447 447 447 447 447\n",
      "$ TaxiIn            :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ TaxiOut           :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ Cancelled         :  num 0 0 0 0 0 0 0 0 0 0\n",
      "$ CancellationCode  :  Factor w/ 4 level(s) \"A\",\"B\",\"C\",\"NA\" \n",
      "$ Diverted          :  num 0 0 0 0 0 0 0 0 0 0\n",
      "$ CarrierDelay      :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ WeatherDelay      :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ NASDelay          :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ SecurityDelay     :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ LateAircraftDelay :  num nan nan nan nan nan nan nan nan nan nan\n",
      "$ IsArrDelayed      :  Factor w/ 2 level(s) \"NO\",\"YES\" \n",
      "$ IsDepDelayed      :  Factor w/ 2 level(s) \"NO\",\"YES\" \n"
     ]
    }
   ],
   "source": [
    "train.structure() #tailnum has 3501 levels , Origin and Destination with 132 levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove Tailnum which is not carrying much information. So, lets remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models without that high cardinality column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=list(filter(lambda v: v != 'TailNum' , xAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 306 ms, sys: 51.1 ms, total: 357 ms\n",
      "Wall time: 18.5 s\n"
     ]
    }
   ],
   "source": [
    "m2_def= H2ODeepLearningEstimator()\n",
    "%time m2_def.train(x2,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 553 ms, sys: 69 ms, total: 622 ms\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "m2_200_epochs= H2ODeepLearningEstimator(epochs=200,stopping_rounds=5,stopping_tolerance=0,stopping_metric=\"logloss\")\n",
    "%time m2_200_epochs.train(x2,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 757 ms, sys: 90.3 ms, total: 847 ms\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "m2_200x200x200= H2ODeepLearningEstimator(epochs=200,\n",
    "                                       #Same early stopping as it is default\n",
    "                                       hidden=[200,200,200])\n",
    "%time m2_200x200x200.train(x2,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "CPU times: user 1.16 s, sys: 132 ms, total: 1.29 s\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "m2_400x400= H2ODeepLearningEstimator(epochs=200,\n",
    "                                       #Same early stopping as it is default\n",
    "                                       hidden=[400,400])\n",
    "%time m2_400x400.train(x2,y,train,validation_frame=valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvement in model building time but have we lost any performance ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m2_400x400 is our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " defaults: 0.2288 --> 0.2598\n",
      " 200 epochs : 0.1020 --> 0.1275\n",
      " 200x200x200: 0.1835 --> 0.1384\n",
      " 400x400: 0.1886 --> 0.1931 \n",
      " \n",
      " defaults: 0.0717 --> 0.0843\n",
      " 200 epochs : 0.0302 --> 0.0378\n",
      " 200x200x200: 0.0563 --> 0.0419\n",
      " 400x400: 0.0596 --> 0.0599  \n"
     ]
    }
   ],
   "source": [
    "all_models=[m_def,m2_def,m_200_epochs,m2_200_epochs,m_200x200x200,m2_200x200x200,m_400x400,m2_400x400]\n",
    "#low log loss is better\n",
    "loglosses= map(lambda x : x.logloss(),all_models)\n",
    "\n",
    "print(\" defaults: %.4f --> %.4f\\n 200 epochs : %.4f --> %.4f\\n 200x200x200: %.4f --> %.4f\\n 400x400: %.4f --> %.4f \\n \" % tuple(list(loglosses)))\n",
    "\n",
    "mse= map(lambda x: x.mse(),all_models)\n",
    "print(\" defaults: %.4f --> %.4f\\n 200 epochs : %.4f --> %.4f\\n 200x200x200: %.4f --> %.4f\\n 400x400: %.4f --> %.4f  \" % tuple(list(mse)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 200x200x200: 0.1835 --> 0.1384 # this could be a random variation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Neuron Layers: predicting IsArrDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 1,682,402 weights/biases, 19.3 MB, 2,535,255 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>3802</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>400</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5280311</td>\n",
       "<td>0.4748262</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000408</td>\n",
       "<td>0.0253470</td>\n",
       "<td>-0.3096682</td>\n",
       "<td>0.1888503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>400</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3318304</td>\n",
       "<td>0.3663535</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0096166</td>\n",
       "<td>0.0630659</td>\n",
       "<td>-0.0590029</td>\n",
       "<td>0.2950772</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0317337</td>\n",
       "<td>0.0718888</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0094838</td>\n",
       "<td>0.2417504</td>\n",
       "<td>-0.0119784</td>\n",
       "<td>0.7799013</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type       dropout    l1    l2    mean_rate            rate_rms             momentum    mean_weight             weight_rms            mean_bias              bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  -------------------  -------------------  ----------  ----------------------  --------------------  ---------------------  -------------------\n",
       "    1        3802     Input      0.0\n",
       "    2        400      Rectifier  0.0        0.0   0.0   0.5280310529511237   0.47482621669769287  0.0         4.0824215879885746e-05  0.025347024202346802  -0.3096682044242364    0.18885034322738647\n",
       "    3        400      Rectifier  0.0        0.0   0.0   0.33183044645178034  0.36635351181030273  0.0         -0.009616552563387932   0.06306594610214233   -0.059002876565644125  0.29507720470428467\n",
       "    4        2        Softmax               0.0   0.0   0.03173366237429036  0.07188877463340759  0.0         -0.009483803426774103   0.24175035953521729   -0.011978395589267943  0.7799012660980225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_400x400.summary() # original weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tailnum created so many input neurons due to one Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of Neuron Layers: predicting IsArrDelayed, 2-class classification, bernoulli distribution, CrossEntropy loss, 281,602 weights/biases, 3.2 MB, 2,594,545 training samples, mini-batch size 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>layer</b></td>\n",
       "<td><b>units</b></td>\n",
       "<td><b>type</b></td>\n",
       "<td><b>dropout</b></td>\n",
       "<td><b>l1</b></td>\n",
       "<td><b>l2</b></td>\n",
       "<td><b>mean_rate</b></td>\n",
       "<td><b>rate_rms</b></td>\n",
       "<td><b>momentum</b></td>\n",
       "<td><b>mean_weight</b></td>\n",
       "<td><b>weight_rms</b></td>\n",
       "<td><b>mean_bias</b></td>\n",
       "<td><b>bias_rms</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>300</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>400</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0629650</td>\n",
       "<td>0.2154071</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0016148</td>\n",
       "<td>0.0721211</td>\n",
       "<td>-0.0442138</td>\n",
       "<td>0.1569303</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>400</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3576252</td>\n",
       "<td>0.3466033</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0326578</td>\n",
       "<td>0.0722853</td>\n",
       "<td>0.4459622</td>\n",
       "<td>0.2833396</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0153497</td>\n",
       "<td>0.0105454</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0187411</td>\n",
       "<td>0.2255940</td>\n",
       "<td>-0.0137217</td>\n",
       "<td>0.3258145</td></tr></table></div>"
      ],
      "text/plain": [
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight             weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  -------------------  ----------  ----------------------  -------------------  ---------------------  -------------------\n",
       "    1        300      Input      0.0\n",
       "    2        400      Rectifier  0.0        0.0   0.0   0.06296501131634868   0.21540707349777222  0.0         -0.0016148394214150017  0.07212108373641968  -0.04421382286623702   0.15693026781082153\n",
       "    3        400      Rectifier  0.0        0.0   0.0   0.35762519484743027   0.34660327434539795  0.0         -0.03265778862641558    0.07228532433509827  0.4459621627622283     0.28333961963653564\n",
       "    4        2        Softmax               0.0   0.0   0.015349668789976931  0.01054537296295166  0.0         0.018741081156513247    0.22559398412704468  -0.013721720451295105  0.32581448554992676"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2_400x400.summary() # 280 thousand weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
